{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRCScndnbpZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba431fb-65cb-430c-deac-d6539d8003d8"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import os,sys,gzip,requests,zipfile,tarfile\r\n",
        "from tqdm import tqdm\r\n",
        "from six.moves import urllib\r\n",
        "import time\r\n",
        "\r\n",
        "'''\r\n",
        "This script is mainly used in cooperation with codes from https://github.com/zsdonghao/text-to-image\r\n",
        "download flower dataset from : http://www.robots.ox.ac.uk/~vgg/data/flowers/102/\r\n",
        "download caption dataset from : https://drive.google.com/uc?export=download&confirm=l7Ld&id=0B0ywwgffWnLLcms2WWJQRFNSWXM\r\n",
        "'''\r\n",
        "\r\n",
        "\r\n",
        "def get_confirm_token(response):\r\n",
        "\tfor key, value in response.cookies.items():\r\n",
        "\t\tif key.startswith('download_warning'):\r\n",
        "\t\t\treturn value\r\n",
        "\treturn None\r\n",
        "\r\n",
        "def save_response_content(response, destination, chunk_size=32*1024):\r\n",
        "\ttotal_size = int(response.headers.get('content-length', 0))\r\n",
        "\twith open(destination, \"wb\") as f:\r\n",
        "\t\tfor chunk in tqdm(response.iter_content(chunk_size), total=total_size,\r\n",
        "\t\t\t\tunit='B', unit_scale=True, desc=destination):\r\n",
        "\t\t\tif chunk: # filter out keep-alive new chunks\r\n",
        "\t\t\t\tf.write(chunk)\r\n",
        "\r\n",
        "def download_file_from_google_drive(id, destination):    \r\n",
        "\tURL = \"https://docs.google.com/uc?export=download\"\r\n",
        "\tsession = requests.Session()\r\n",
        "\r\n",
        "\tresponse = session.get(URL, params={ 'id': id }, stream=True)\r\n",
        "\ttoken = get_confirm_token(response)\r\n",
        "\r\n",
        "\tif token:\r\n",
        "\t\tparams = { 'id' : id, 'confirm' : token }\r\n",
        "\t\tresponse = session.get(URL, params=params, stream=True)\r\n",
        "\tsave_response_content(response, destination)\r\n",
        "\r\n",
        "def download_caption(dirpath):\r\n",
        "\tdata_dir = 'cvpr2016_flowers.tar.gz'\r\n",
        "\tif os.path.exists(os.path.join(dirpath, data_dir)):\r\n",
        "\t\tprint('Found cvpr2016_flowers.tar.gz - skip')\r\n",
        "\t\treturn\r\n",
        "\r\n",
        "\tfilename, drive_id  = \"cvpr2016_flowers.tar.gz\", \"0B0ywwgffWnLLcms2WWJQRFNSWXM\"\r\n",
        "\tsave_path = os.path.join(dirpath, filename)\r\n",
        "\r\n",
        "\tif os.path.exists(save_path):\r\n",
        "\t\tprint('[*] {} already exists'.format(save_path))\r\n",
        "\telse:\r\n",
        "\t\tdownload_file_from_google_drive(drive_id, save_path)\r\n",
        "\r\n",
        "\r\n",
        "def download(url, dirpath):\r\n",
        "\tfilepath = dirpath\r\n",
        "\tu = urllib.request.urlopen(url)\r\n",
        "\tf = open(filepath, 'wb')\r\n",
        "\tfilesize = int(u.headers[\"Content-Length\"])\r\n",
        "\tprint(\"Downloading: %s Bytes: %s\" % (\"102flowers\", filesize))\r\n",
        "\r\n",
        "\tdownloaded = 0\r\n",
        "\tblock_sz = 8192\r\n",
        "\tstatus_width = 70\r\n",
        "\twhile True:\r\n",
        "\t\tbuf = u.read(block_sz)\r\n",
        "\t\tif not buf:\r\n",
        "\t\t\tprint('')\r\n",
        "\t\t\tbreak\r\n",
        "\t\telse:\r\n",
        "\t\t\tprint('', end='\\r')\r\n",
        "\t\tdownloaded += len(buf)\r\n",
        "\t\tf.write(buf)\r\n",
        "\r\n",
        "\t\tstatus = ((\"[{}  \" + \" ***progress: {:03.1f}% ]\").format('=' * int(float(downloaded) / \r\n",
        "\t\t\tfilesize * status_width) + '>', downloaded * 100. / filesize))\r\n",
        "\t\tprint(status, end='')\r\n",
        "\r\n",
        "\t\tsys.stdout.flush()\r\n",
        "\tf.close()\r\n",
        "\treturn filepath\r\n",
        "\r\n",
        "def unzip(src_dir,new_name = None):\r\n",
        "\t# extract to current directory\r\n",
        "\tdirpath = '.'\r\n",
        "\ttry:\r\n",
        "\t\tif src_dir.endswith('.zip'):\r\n",
        "\t\t\tprint('unzipping ' + src_dir)\r\n",
        "\t\t\twith zipfile.ZipFile(src_dir) as zf:\r\n",
        "\t\t\t\tzip_dir = zf.namelist()[0]\r\n",
        "\t\t\t\tzf.extractall(dirpath)\r\n",
        "\t\telif src_dir.endswith('.tgz') or src_dir.endswith('tar.gz'):\r\n",
        "\t\t\tprint('unzipping ' + src_dir)\r\n",
        "\t\t\ttar = tarfile.open(src_dir)\r\n",
        "\t\t\ttar.extractall()\r\n",
        "\t\t\ttar.close()\r\n",
        "\t\t# os.remove(save_path)\r\n",
        "\t\tif new_name is None:\r\n",
        "\t\t\tpass\r\n",
        "\t\telse:\r\n",
        "\t\t\tos.rename('jpg', os.path.join(dirpath, new_name))\r\n",
        "\texcept:\r\n",
        "\t\traise('wrong format')\r\n",
        "\r\n",
        "def main():\r\n",
        "\turl = \"http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\r\n",
        "\tcur_dir = os.getcwd()\r\n",
        "\timage_dir = os.path.join(cur_dir,\"102flowers.tgz\")\r\n",
        "\tif os.path.exists(image_dir):\r\n",
        "\t\tprint('dataset already exists')\r\n",
        "\telse:\r\n",
        "\t\tdownload(url,image_dir)\r\n",
        "\tunzip(image_dir,'102flowers')\r\n",
        "\r\n",
        "\tcaption_dir = os.path.join(cur_dir,\"cvpr2016_flowers.tar.gz\")\r\n",
        "\tif os.path.exists(caption_dir):\r\n",
        "\t\tprint('dataset already exists')\r\n",
        "\telse:\r\n",
        "\t\tdownload_caption(cur_dir)\r\n",
        "\tunzip(caption_dir)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "\tmain()\r\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: 102flowers Bytes: 344862509\n",
            "[=================================================================>   ***progress: 93.6% ]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/cvpr2016_flowers.tar.gz: 17.9kB [00:08, 2.15kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "unzipping /content/cvpr2016_flowers.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWHld6UouDkc",
        "outputId": "b4c0e36f-9b6c-43db-990d-11350b79b83a"
      },
      "source": [
        "!pip install tensorlayer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorlayer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/e3/79a81c75da0ca18b797d56d42958f0be92e10bd185fa2c17aad3efb23c6a/tensorlayer-2.2.3-py2.py3-none-any.whl (363kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 16.6MB/s \n",
            "\u001b[?25hCollecting imageio>=2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (0.22.2.post1)\n",
            "Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (2.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (0.16.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.12.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorlayer) (1.4.1)\n",
            "Collecting progressbar2>=3.39.3\n",
            "  Downloading https://files.pythonhosted.org/packages/25/8c/d28cd70b6e0b870a2d2a151bdbecf4c678199d31731edb44fc8035d3bb6d/progressbar2-3.53.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.5.0->tensorlayer) (7.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->tensorlayer) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9->tensorlayer) (1.15.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15.0->tensorlayer) (2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->tensorlayer) (1.24.3)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2>=3.39.3->tensorlayer) (2.5.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15.0->tensorlayer) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.15.0->tensorlayer) (4.4.2)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio, progressbar2, tensorlayer\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "Successfully installed imageio-2.9.0 progressbar2-3.53.1 tensorlayer-2.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOswbSxTb23D"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import time\r\n",
        "import nltk\r\n",
        "import re\r\n",
        "import string\r\n",
        "import tensorlayer as tl\r\n",
        "from utils import *\r\n",
        "\r\n",
        "\r\n",
        "dataset = '102flowers' #\r\n",
        "need_256 = True # set to True for stackGAN\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "if dataset == '102flowers':\r\n",
        "    \"\"\"\r\n",
        "    images.shape = [8000, 64, 64, 3]\r\n",
        "    captions_ids = [80000, any]\r\n",
        "    \"\"\"\r\n",
        "    cwd = os.getcwd()\r\n",
        "    img_dir = os.path.join(cwd, '102flowers')\r\n",
        "    caption_dir = os.path.join(cwd, 'text_c10')\r\n",
        "    VOC_FIR = cwd + '/vocab.txt'\r\n",
        "\r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "r_RYcRSCUEzK",
        "outputId": "35a53d55-5f92-4acb-a96b-de681495f5cb"
      },
      "source": [
        " ## load captions\r\n",
        "    caption_sub_dir = load_folder_list( caption_dir )\r\n",
        "    captions_dict = {}\r\n",
        "    processed_capts = []\r\n",
        "    for sub_dir in caption_sub_dir: # get caption file list\r\n",
        "        with tl.ops.suppress_stdout():\r\n",
        "            files = tl.files.load_file_list(path=sub_dir, regx='^image_[0-9]+\\.txt')\r\n",
        "            for i, f in enumerate(files):\r\n",
        "                file_dir = os.path.join(sub_dir, f)\r\n",
        "                key = int(re.findall('\\d+', f)[0])\r\n",
        "                t = open(file_dir,'r')\r\n",
        "                lines = []\r\n",
        "                for line in t:\r\n",
        "                    line = preprocess_caption(line)\r\n",
        "                    lines.append(line)\r\n",
        "                    processed_capts.append(tl.nlp.process_sentence(line, start_word=\"<S>\", end_word=\"</S>\"))\r\n",
        "                assert len(lines) == 10, \"Every flower image have 10 captions\"\r\n",
        "                captions_dict[key] = lines\r\n",
        "    print(\" * %d x %d captions found \" % (len(captions_dict), len(lines)))\r\n",
        "\r\n",
        "    ## build vocab\r\n",
        "    if not os.path.isfile('vocab.txt'):\r\n",
        "        _ = tl.nlp.create_vocab(processed_capts, word_counts_output_file=VOC_FIR, min_word_count=1)\r\n",
        "    else:\r\n",
        "        print(\"WARNING: vocab.txt already exists\")\r\n",
        "    vocab = tl.nlp.Vocabulary(VOC_FIR, start_word=\"<S>\", end_word=\"</S>\", unk_word=\"<UNK>\")\r\n",
        "\r\n",
        "    ## store all captions ids in list\r\n",
        "    captions_ids = []\r\n",
        "    try: # python3\r\n",
        "        tmp = captions_dict.items()\r\n",
        "    except: # python3\r\n",
        "        tmp = captions_dict.iteritems()\r\n",
        "    for key, value in tmp:\r\n",
        "        for v in value:\r\n",
        "            captions_ids.append( [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(v)] + [vocab.end_id])  # add END_ID\r\n",
        "            # print(v)              # prominent purple stigma,petals are white inc olor\r\n",
        "            # print(captions_ids)   # [[152, 19, 33, 15, 3, 8, 14, 719, 723]]\r\n",
        "            # exit()\r\n",
        "    captions_ids = np.asarray(captions_ids)\r\n",
        "    print(\" * tokenized %d captions\" % len(captions_ids))\r\n",
        "\r\n",
        "    ## check\r\n",
        "    img_capt = captions_dict[1][1]\r\n",
        "    print(\"img_capt: %s\" % img_capt)\r\n",
        "    print(\"nltk.tokenize.word_tokenize(img_capt): %s\" % nltk.tokenize.word_tokenize(img_capt))\r\n",
        "    img_capt_ids = [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(img_capt)]#img_capt.split(' ')]\r\n",
        "    print(\"img_capt_ids: %s\" % img_capt_ids)\r\n",
        "    print(\"id_to_word: %s\" % [vocab.id_to_word(id) for id in img_capt_ids])\r\n",
        "\r\n",
        "    ## load images\r\n",
        "    with tl.ops.suppress_stdout():  # get image files list\r\n",
        "        imgs_title_list = sorted(tl.files.load_file_list(path=img_dir, regx='^image_[0-9]+\\.jpg'))\r\n",
        "    print(\" * %d images found, start loading and resizing ...\" % len(imgs_title_list))\r\n",
        "    s = time.time()\r\n",
        "\r\n",
        "    # time.sleep(10)\r\n",
        "    # def get_resize_image(name):   # fail\r\n",
        "    #         img = scipy.misc.imread( os.path.join(img_dir, name) )\r\n",
        "    #         img = tl.prepro.imresize(img, size=[64, 64])    # (64, 64, 3)\r\n",
        "    #         img = img.astype(np.float32)\r\n",
        "    #         return img\r\n",
        "    # images = tl.prepro.threading_data(imgs_title_list, fn=get_resize_image)\r\n",
        "    images = []\r\n",
        "    images_256 = []\r\n",
        "    for name in imgs_title_list:\r\n",
        "        # print(name)\r\n",
        "        img_raw = scipy.misc.imread( os.path.join(img_dir, name) )\r\n",
        "        img = tl.prepro.imresize(img_raw, size=[64, 64])    # (64, 64, 3)\r\n",
        "        img = img.astype(np.float32)\r\n",
        "        images.append(img)\r\n",
        "        if need_256:\r\n",
        "            img = tl.prepro.imresize(img_raw, size=[256, 256]) # (256, 256, 3)\r\n",
        "            img = img.astype(np.float32)\r\n",
        "\r\n",
        "            images_256.append(img)\r\n",
        "    # images = np.array(images)\r\n",
        "    # images_256 = np.array(images_256)\r\n",
        "    print(\" * loading and resizing took %ss\" % (time.time()-s))\r\n",
        "\r\n",
        "    n_images = len(captions_dict)\r\n",
        "    n_captions = len(captions_ids)\r\n",
        "    n_captions_per_image = len(lines) # 10\r\n",
        "\r\n",
        "    print(\"n_captions: %d n_images: %d n_captions_per_image: %d\" % (n_captions, n_images, n_captions_per_image))\r\n",
        "\r\n",
        "    captions_ids_train, captions_ids_test = captions_ids[: 8000*n_captions_per_image], captions_ids[8000*n_captions_per_image :]\r\n",
        "    images_train, images_test = images[:8000], images[8000:]\r\n",
        "    if need_256:\r\n",
        "        images_train_256, images_test_256 = images_256[:8000], images_256[8000:]\r\n",
        "    n_images_train = len(images_train)\r\n",
        "    n_images_test = len(images_test)\r\n",
        "    n_captions_train = len(captions_ids_train)\r\n",
        "    n_captions_test = len(captions_ids_test)\r\n",
        "    print(\"n_images_train:%d n_captions_train:%d\" % (n_images_train, n_captions_train))\r\n",
        "    print(\"n_images_test:%d  n_captions_test:%d\" % (n_images_test, n_captions_test))\r\n",
        "\r\n",
        "    ## check test image\r\n",
        "    # idexs = get_random_int(min=0, max=n_captions_test-1, number=64)\r\n",
        "    # temp_test_capt = captions_ids_test[idexs]\r\n",
        "    # for idx, ids in enumerate(temp_test_capt):\r\n",
        "    #     print(\"%d %s\" % (idx, [vocab.id_to_word(id) for id in ids]))\r\n",
        "    # temp_test_img = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "    # save_images(temp_test_img, [8, 8], 'temp_test_img.png')\r\n",
        "    # exit()\r\n",
        "\r\n",
        "    # ## check the first example\r\n",
        "    # tl.visualize.frame(I=images[0], second=5, saveable=True, name='temp', cmap=None)\r\n",
        "    # for cap in captions_dict[1]:\r\n",
        "    #     print(cap)\r\n",
        "    # print(captions_ids[0:10])\r\n",
        "    # for ids in captions_ids[0:10]:\r\n",
        "    #     print([vocab.id_to_word(id) for id in ids])\r\n",
        "    # print_dict(captions_dict)\r\n",
        "\r\n",
        "    # ## generate a random batch\r\n",
        "    # batch_size = 64\r\n",
        "    # idexs = get_random_int(0, n_captions_test, batch_size)\r\n",
        "    # # idexs = [i for i in range(0,100)]\r\n",
        "    # print(idexs)\r\n",
        "    # b_seqs = captions_ids_test[idexs]\r\n",
        "    # b_images = images_test[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "    # print(\"before padding %s\" % b_seqs)\r\n",
        "    # b_seqs = tl.prepro.pad_sequences(b_seqs, padding='post')\r\n",
        "    # print(\"after padding %s\" % b_seqs)\r\n",
        "    # # print(input_images.shape)   # (64, 64, 64, 3)\r\n",
        "    # for ids in b_seqs:\r\n",
        "    #     print([vocab.id_to_word(id) for id in ids])\r\n",
        "    # print(np.max(b_images), np.min(b_images), b_images.shape)\r\n",
        "    # from utils import *\r\n",
        "    # save_images(b_images, [8, 8], 'temp2.png')\r\n",
        "    # # tl.visualize.images2d(b_images, second=5, saveable=True, name='temp2')\r\n",
        "    # exit()\r\n",
        "\r\n",
        "import pickle\r\n",
        "def save_all(targets, file):\r\n",
        "    with open(file, 'wb') as f:\r\n",
        "        pickle.dump(targets, f)\r\n",
        "\r\n",
        "save_all(vocab, '_vocab.pickle')\r\n",
        "save_all((images_train_256, images_train), '_image_train.pickle')\r\n",
        "save_all((images_test_256, images_test), '_image_test.pickle')\r\n",
        "save_all((n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test), '_n.pickle')\r\n",
        "save_all((captions_ids_train, captions_ids_test), '_caption.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-74c5a3ad0929>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    caption_dir = os.path.join(cwd, 'text_c10')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dQC0PSP89c",
        "outputId": "0dd214bf-a6df-4e8f-86bf-1a3f6d6069ac"
      },
      "source": [
        "!pip install utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKffhzpqb_s0"
      },
      "source": [
        "#! /usr/bin/python\r\n",
        "# -*- coding: utf8 -*-\r\n",
        "\r\n",
        "\"\"\" GAN-CLS \"\"\"\r\n",
        "import tensorflow as tf\r\n",
        "import tensorlayer as tl\r\n",
        "from tensorlayer.layers import *\r\n",
        "from tensorlayer.prepro import *\r\n",
        "from tensorlayer.cost import *\r\n",
        "import numpy as np\r\n",
        "import scipy\r\n",
        "from scipy.io import loadmat\r\n",
        "import time, os, re, nltk\r\n",
        "\r\n",
        "from utils import *\r\n",
        "from model import *\r\n",
        "import model\r\n",
        "\r\n",
        "###======================== PREPARE DATA ====================================###\r\n",
        "print(\"Loading data from pickle ...\")\r\n",
        "import pickle\r\n",
        "with open(\"_vocab.pickle\", 'rb') as f:\r\n",
        "    vocab = pickle.load(f)\r\n",
        "with open(\"_image_train.pickle\", 'rb') as f:\r\n",
        "    _, images_train = pickle.load(f)\r\n",
        "with open(\"_image_test.pickle\", 'rb') as f:\r\n",
        "    _, images_test = pickle.load(f)\r\n",
        "with open(\"_n.pickle\", 'rb') as f:\r\n",
        "    n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test = pickle.load(f)\r\n",
        "with open(\"_caption.pickle\", 'rb') as f:\r\n",
        "    captions_ids_train, captions_ids_test = pickle.load(f)\r\n",
        "# images_train_256 = np.array(images_train_256)\r\n",
        "# images_test_256 = np.array(images_test_256)\r\n",
        "images_train = np.array(images_train)\r\n",
        "images_test = np.array(images_test)\r\n",
        "\r\n",
        "# print(n_captions_train, n_captions_test)\r\n",
        "# exit()\r\n",
        "\r\n",
        "ni = int(np.ceil(np.sqrt(batch_size)))\r\n",
        "# os.system(\"mkdir samples\")\r\n",
        "# os.system(\"mkdir samples/step1_gan-cls\")\r\n",
        "# os.system(\"mkdir checkpoint\")\r\n",
        "tl.files.exists_or_mkdir(\"samples/step1_gan-cls\")\r\n",
        "tl.files.exists_or_mkdir(\"samples/step_pretrain_encoder\")\r\n",
        "tl.files.exists_or_mkdir(\"checkpoint\")\r\n",
        "save_dir = \"checkpoint\"\r\n",
        "\r\n",
        "\r\n",
        "def main_train():\r\n",
        "    ###======================== DEFIINE MODEL ===================================###\r\n",
        "    t_real_image = tf.placeholder('float32', [batch_size, image_size, image_size, 3], name = 'real_image')\r\n",
        "    t_wrong_image = tf.placeholder('float32', [batch_size ,image_size, image_size, 3], name = 'wrong_image')\r\n",
        "    t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\r\n",
        "    t_wrong_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='wrong_caption_input')\r\n",
        "    t_z = tf.placeholder(tf.float32, [batch_size, z_dim], name='z_noise')\r\n",
        "\r\n",
        "    ## training inference for text-to-image mapping\r\n",
        "    net_cnn = cnn_encoder(t_real_image, is_train=True, reuse=False)\r\n",
        "    x = net_cnn.outputs\r\n",
        "    v = rnn_embed(t_real_caption, is_train=True, reuse=False).outputs\r\n",
        "    x_w = cnn_encoder(t_wrong_image, is_train=True, reuse=True).outputs\r\n",
        "    v_w = rnn_embed(t_wrong_caption, is_train=True, reuse=True).outputs\r\n",
        "\r\n",
        "    alpha = 0.2 # margin alpha\r\n",
        "    rnn_loss = tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x, v_w))) + \\\r\n",
        "                tf.reduce_mean(tf.maximum(0., alpha - cosine_similarity(x, v) + cosine_similarity(x_w, v)))\r\n",
        "\r\n",
        "    ## training inference for txt2img\r\n",
        "    generator_txt2img = model.generator_txt2img_resnet\r\n",
        "    discriminator_txt2img = model.discriminator_txt2img_resnet\r\n",
        "\r\n",
        "    net_rnn = rnn_embed(t_real_caption, is_train=False, reuse=True)\r\n",
        "    net_fake_image, _ = generator_txt2img(t_z,\r\n",
        "                    net_rnn.outputs,\r\n",
        "                    is_train=True, reuse=False, batch_size=batch_size)\r\n",
        "                    #+ tf.random_normal(shape=net_rnn.outputs.get_shape(), mean=0, stddev=0.02), # NOISE ON RNN\r\n",
        "    net_d, disc_fake_image_logits = discriminator_txt2img(\r\n",
        "                    net_fake_image.outputs, net_rnn.outputs, is_train=True, reuse=False)\r\n",
        "    _, disc_real_image_logits = discriminator_txt2img(\r\n",
        "                    t_real_image, net_rnn.outputs, is_train=True, reuse=True)\r\n",
        "    _, disc_mismatch_logits = discriminator_txt2img(\r\n",
        "                    # t_wrong_image,\r\n",
        "                    t_real_image,\r\n",
        "                    # net_rnn.outputs,\r\n",
        "                    rnn_embed(t_wrong_caption, is_train=False, reuse=True).outputs,\r\n",
        "                    is_train=True, reuse=True)\r\n",
        "\r\n",
        "    ## testing inference for txt2img\r\n",
        "    net_g, _ = generator_txt2img(t_z,\r\n",
        "                    rnn_embed(t_real_caption, is_train=False, reuse=True).outputs,\r\n",
        "                    is_train=False, reuse=True, batch_size=batch_size)\r\n",
        "\r\n",
        "    d_loss1 = tl.cost.sigmoid_cross_entropy(disc_real_image_logits, tf.ones_like(disc_real_image_logits), name='d1')\r\n",
        "    d_loss2 = tl.cost.sigmoid_cross_entropy(disc_mismatch_logits,  tf.zeros_like(disc_mismatch_logits), name='d2')\r\n",
        "    d_loss3 = tl.cost.sigmoid_cross_entropy(disc_fake_image_logits, tf.zeros_like(disc_fake_image_logits), name='d3')\r\n",
        "    d_loss = d_loss1 + (d_loss2 + d_loss3) * 0.5\r\n",
        "    g_loss = tl.cost.sigmoid_cross_entropy(disc_fake_image_logits, tf.ones_like(disc_fake_image_logits), name='g')\r\n",
        "\r\n",
        "    ####======================== DEFINE TRAIN OPTS ==============================###\r\n",
        "    lr = 0.0002\r\n",
        "    lr_decay = 0.5      # decay factor for adam, https://github.com/reedscot/icml2016/blob/master/main_cls_int.lua  https://github.com/reedscot/icml2016/blob/master/scripts/train_flowers.sh\r\n",
        "    decay_every = 100   # https://github.com/reedscot/icml2016/blob/master/main_cls.lua\r\n",
        "    beta1 = 0.5\r\n",
        "\r\n",
        "    cnn_vars = tl.layers.get_variables_with_name('cnn', True, True)\r\n",
        "    rnn_vars = tl.layers.get_variables_with_name('rnn', True, True)\r\n",
        "    d_vars = tl.layers.get_variables_with_name('discriminator', True, True)\r\n",
        "    g_vars = tl.layers.get_variables_with_name('generator', True, True)\r\n",
        "\r\n",
        "    with tf.variable_scope('learning_rate'):\r\n",
        "        lr_v = tf.Variable(lr, trainable=False)\r\n",
        "    d_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(d_loss, var_list=d_vars )\r\n",
        "    g_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(g_loss, var_list=g_vars )\r\n",
        "    # e_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(e_loss, var_list=e_vars + c_vars)\r\n",
        "    grads, _ = tf.clip_by_global_norm(tf.gradients(rnn_loss, rnn_vars + cnn_vars), 10)\r\n",
        "    optimizer = tf.train.AdamOptimizer(lr_v, beta1=beta1)# optimizer = tf.train.GradientDescentOptimizer(lre)\r\n",
        "    rnn_optim = optimizer.apply_gradients(zip(grads, rnn_vars + cnn_vars))\r\n",
        "\r\n",
        "    # adam_vars = tl.layers.get_variables_with_name('Adam', False, True)\r\n",
        "\r\n",
        "    ###============================ TRAINING ====================================###\r\n",
        "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\r\n",
        "    tl.layers.initialize_global_variables(sess)\r\n",
        "\r\n",
        "    # load the latest checkpoints\r\n",
        "    net_rnn_name = os.path.join(save_dir, 'net_rnn.npz')\r\n",
        "    net_cnn_name = os.path.join(save_dir, 'net_cnn.npz')\r\n",
        "    net_g_name = os.path.join(save_dir, 'net_g.npz')\r\n",
        "    net_d_name = os.path.join(save_dir, 'net_d.npz')\r\n",
        "\r\n",
        "    load_and_assign_npz(sess=sess, name=net_rnn_name, model=net_rnn)\r\n",
        "    load_and_assign_npz(sess=sess, name=net_cnn_name, model=net_cnn)\r\n",
        "    load_and_assign_npz(sess=sess, name=net_g_name, model=net_g)\r\n",
        "    load_and_assign_npz(sess=sess, name=net_d_name, model=net_d)\r\n",
        "\r\n",
        "    ## seed for generation, z and sentence ids\r\n",
        "    sample_size = batch_size\r\n",
        "    sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\r\n",
        "        # sample_seed = np.random.uniform(low=-1, high=1, size=(sample_size, z_dim)).astype(np.float32)]\r\n",
        "    n = int(sample_size / ni)\r\n",
        "    sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"] * n + \\\r\n",
        "                      [\"this flower has petals that are yellow, white and purple and has dark lines\"] * n + \\\r\n",
        "                      [\"the petals on this flower are white with a yellow center\"] * n + \\\r\n",
        "                      [\"this flower has a lot of small round pink petals.\"] * n + \\\r\n",
        "                      [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * n + \\\r\n",
        "                      [\"the flower has yellow petals and the center of it is brown.\"] * n + \\\r\n",
        "                      [\"this flower has petals that are blue and white.\"] * n +\\\r\n",
        "                      [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * n\r\n",
        "\r\n",
        "    # sample_sentence = captions_ids_test[0:sample_size]\r\n",
        "    for i, sentence in enumerate(sample_sentence):\r\n",
        "        print(\"seed: %s\" % sentence)\r\n",
        "        sentence = preprocess_caption(sentence)\r\n",
        "        sample_sentence[i] = [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(sentence)] + [vocab.end_id]    # add END_ID\r\n",
        "        # sample_sentence[i] = [vocab.word_to_id(word) for word in sentence]\r\n",
        "        # print(sample_sentence[i])\r\n",
        "    sample_sentence = tl.prepro.pad_sequences(sample_sentence, padding='post')\r\n",
        "\r\n",
        "    n_epoch = 100 # 600\r\n",
        "    print_freq = 1\r\n",
        "    n_batch_epoch = int(n_images_train / batch_size)\r\n",
        "    # exit()\r\n",
        "    for epoch in range(0, n_epoch+1):\r\n",
        "        start_time = time.time()\r\n",
        "\r\n",
        "        if epoch !=0 and (epoch % decay_every == 0):\r\n",
        "            new_lr_decay = lr_decay ** (epoch // decay_every)\r\n",
        "            sess.run(tf.assign(lr_v, lr * new_lr_decay))\r\n",
        "            log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\r\n",
        "            print(log)\r\n",
        "            # logging.debug(log)\r\n",
        "        elif epoch == 0:\r\n",
        "            log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\r\n",
        "            print(log)\r\n",
        "\r\n",
        "        for step in range(n_batch_epoch):\r\n",
        "            step_time = time.time()\r\n",
        "            ## get matched text\r\n",
        "            idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\r\n",
        "            b_real_caption = captions_ids_train[idexs]\r\n",
        "            b_real_caption = tl.prepro.pad_sequences(b_real_caption, padding='post')\r\n",
        "            ## get real image\r\n",
        "            b_real_images = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "            # save_images(b_real_images, [ni, ni], 'samples/step1_gan-cls/train_00.png')\r\n",
        "            ## get wrong caption\r\n",
        "            idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\r\n",
        "            b_wrong_caption = captions_ids_train[idexs]\r\n",
        "            b_wrong_caption = tl.prepro.pad_sequences(b_wrong_caption, padding='post')\r\n",
        "            ## get wrong image\r\n",
        "            idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\r\n",
        "            b_wrong_images = images_train[idexs2]\r\n",
        "            ## get noise\r\n",
        "            b_z = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\r\n",
        "                # b_z = np.random.uniform(low=-1, high=1, size=[batch_size, z_dim]).astype(np.float32)\r\n",
        "\r\n",
        "            b_real_images = threading_data(b_real_images, prepro_img, mode='train')   # [0, 255] --> [-1, 1] + augmentation\r\n",
        "            b_wrong_images = threading_data(b_wrong_images, prepro_img, mode='train')\r\n",
        "            ## updates text-to-image mapping\r\n",
        "            if epoch < 50:\r\n",
        "                errRNN, _ = sess.run([rnn_loss, rnn_optim], feed_dict={\r\n",
        "                                                t_real_image : b_real_images,\r\n",
        "                                                t_wrong_image : b_wrong_images,\r\n",
        "                                                t_real_caption : b_real_caption,\r\n",
        "                                                t_wrong_caption : b_wrong_caption})\r\n",
        "            else:\r\n",
        "                errRNN = 0\r\n",
        "\r\n",
        "            ## updates D\r\n",
        "            errD, _ = sess.run([d_loss, d_optim], feed_dict={\r\n",
        "                            t_real_image : b_real_images,\r\n",
        "                            # t_wrong_image : b_wrong_images,\r\n",
        "                            t_wrong_caption : b_wrong_caption,\r\n",
        "                            t_real_caption : b_real_caption,\r\n",
        "                            t_z : b_z})\r\n",
        "            ## updates G\r\n",
        "            errG, _ = sess.run([g_loss, g_optim], feed_dict={\r\n",
        "                            t_real_caption : b_real_caption,\r\n",
        "                            t_z : b_z})\r\n",
        "\r\n",
        "            print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, d_loss: %.8f, g_loss: %.8f, rnn_loss: %.8f\" \\\r\n",
        "                        % (epoch, n_epoch, step, n_batch_epoch, time.time() - step_time, errD, errG, errRNN))\r\n",
        "\r\n",
        "        if (epoch + 1) % print_freq == 0:\r\n",
        "            print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\r\n",
        "            img_gen, rnn_out = sess.run([net_g.outputs, net_rnn.outputs], feed_dict={\r\n",
        "                                        t_real_caption : sample_sentence,\r\n",
        "                                        t_z : sample_seed})\r\n",
        "\r\n",
        "            # img_gen = threading_data(img_gen, prepro_img, mode='rescale')\r\n",
        "            save_images(img_gen, [ni, ni], 'samples/step1_gan-cls/train_{:02d}.png'.format(epoch))\r\n",
        "\r\n",
        "        ## save model\r\n",
        "        if (epoch != 0) and (epoch % 10) == 0:\r\n",
        "            tl.files.save_npz(net_cnn.all_params, name=net_cnn_name, sess=sess)\r\n",
        "            tl.files.save_npz(net_rnn.all_params, name=net_rnn_name, sess=sess)\r\n",
        "            tl.files.save_npz(net_g.all_params, name=net_g_name, sess=sess)\r\n",
        "            tl.files.save_npz(net_d.all_params, name=net_d_name, sess=sess)\r\n",
        "            print(\"[*] Save checkpoints SUCCESS!\")\r\n",
        "\r\n",
        "        if (epoch != 0) and (epoch % 100) == 0:\r\n",
        "            tl.files.save_npz(net_cnn.all_params, name=net_cnn_name+str(epoch), sess=sess)\r\n",
        "            tl.files.save_npz(net_rnn.all_params, name=net_rnn_name+str(epoch), sess=sess)\r\n",
        "            tl.files.save_npz(net_g.all_params, name=net_g_name+str(epoch), sess=sess)\r\n",
        "            tl.files.save_npz(net_d.all_params, name=net_d_name+str(epoch), sess=sess)\r\n",
        "\r\n",
        "        # if (epoch != 0) and (epoch % 200) == 0:\r\n",
        "        #     sess.run(tf.initialize_variables(adam_vars))\r\n",
        "        #     print(\"Re-initialize Adam\")\r\n",
        "\r\n",
        "#\r\n",
        "# def main_train_encoder():\r\n",
        "#     \"\"\" for Style Transfer \"\"\"\r\n",
        "#     generator_txt2img = model.generator_txt2img_resnet\r\n",
        "#\r\n",
        "#     ## for training\r\n",
        "#     t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\r\n",
        "#     t_z = tf.placeholder(tf.float32, [batch_size, z_dim], name='z_noise')\r\n",
        "#\r\n",
        "#     net_rnn = rnn_embed(t_real_caption, is_train=False, reuse=False)\r\n",
        "#     net_fake_image, _ = generator_txt2img(t_z,\r\n",
        "#                     net_rnn.outputs + tf.random_normal(shape=net_rnn.outputs.get_shape(), mean=0, stddev=0.02), # NOISE ON RNN\r\n",
        "#                     is_train=True, reuse=False, batch_size=batch_size)\r\n",
        "#     net_encoder = z_encoder(net_fake_image.outputs, is_train=True, reuse=False)\r\n",
        "#\r\n",
        "#     ## for evaluation\r\n",
        "#     t_real_image = tf.placeholder('float32', [batch_size, image_size, image_size, 3], name = 'real_image')\r\n",
        "#     net_z = z_encoder(t_real_image, is_train=False, reuse=True)\r\n",
        "#     net_g2, _ = generator_txt2img(net_z.outputs, net_rnn.outputs, is_train=False, reuse=True, batch_size=batch_size)\r\n",
        "#\r\n",
        "#     loss = tf.reduce_mean( tf.square( tf.sub( net_encoder.outputs, t_z) ))\r\n",
        "#     e_vars = tl.layers.get_variables_with_name('z_encoder', True, True)\r\n",
        "#\r\n",
        "#     lr = 0.0002\r\n",
        "#     lr_decay = 0.5      # decay factor for adam, https://github.com/reedscot/icml2016/blob/master/main_cls_int.lua  https://github.com/reedscot/icml2016/blob/master/scripts/train_flowers.sh\r\n",
        "#     decay_every = 100   # https://github.com/reedscot/icml2016/blob/master/main_cls.lua\r\n",
        "#     beta1 = 0.5\r\n",
        "#\r\n",
        "#     with tf.variable_scope('learning_rate'):\r\n",
        "#         lr_v = tf.Variable(lr, trainable=False)\r\n",
        "#\r\n",
        "#     e_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(loss, var_list=e_vars )\r\n",
        "#\r\n",
        "#\r\n",
        "#     ###============================ TRAINING ====================================###\r\n",
        "#     sess = tf.InteractiveSession()\r\n",
        "#     tl.layers.initialize_global_variables(sess)\r\n",
        "#\r\n",
        "#     net_g_name = os.path.join(save_dir, 'net_g.npz')\r\n",
        "#     net_encoder_name = os.path.join(save_dir, 'net_encoder.npz')\r\n",
        "#\r\n",
        "#     if load_and_assign_npz(sess=sess, name=net_g_name, model=net_fake_image) is False:\r\n",
        "#         raise Exception(\"Cannot find net_g.npz\")\r\n",
        "#     load_and_assign_npz(sess=sess, name=net_encoder_name, model=net_encoder)\r\n",
        "#\r\n",
        "#     sample_size = batch_size\r\n",
        "#     idexs = get_random_int(min=0, max=n_captions_train-1, number=sample_size, seed=100)\r\n",
        "#     sample_sentence = captions_ids_train[idexs]\r\n",
        "#     sample_sentence = tl.prepro.pad_sequences(sample_sentence, padding='post')\r\n",
        "#     sample_image = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "#     # print(sample_image.shape, np.min(sample_image), np.max(sample_image), image_size)\r\n",
        "#     # exit()\r\n",
        "#     sample_image = threading_data(sample_image, prepro_img, mode='translation')    # central crop first\r\n",
        "#     save_images(sample_image, [ni, ni], 'samples/step_pretrain_encoder/train__x.png')\r\n",
        "#\r\n",
        "#\r\n",
        "#     n_epoch = 160 * 100\r\n",
        "#     print_freq = 1\r\n",
        "#     n_batch_epoch = int(n_images_train / batch_size)\r\n",
        "#\r\n",
        "#     for epoch in range(0, n_epoch+1):\r\n",
        "#         start_time = time.time()\r\n",
        "#\r\n",
        "#         if epoch !=0 and (epoch % decay_every == 0):\r\n",
        "#             new_lr_decay = lr_decay ** (epoch // decay_every)\r\n",
        "#             sess.run(tf.assign(lr_v, lr * new_lr_decay))\r\n",
        "#             log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\r\n",
        "#             print(log)\r\n",
        "#             # logging.debug(log)\r\n",
        "#         elif epoch == 0:\r\n",
        "#             log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\r\n",
        "#             print(log)\r\n",
        "#\r\n",
        "#         for step in range(n_batch_epoch):\r\n",
        "#             step_time = time.time()\r\n",
        "#             ## get matched text\r\n",
        "#             idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\r\n",
        "#             b_real_caption = captions_ids_train[idexs]\r\n",
        "#             b_real_caption = tl.prepro.pad_sequences(b_real_caption, padding='post')\r\n",
        "#             # ## get real image\r\n",
        "#             # b_real_images = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "#             # ## get wrong caption\r\n",
        "#             # idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size)\r\n",
        "#             # b_wrong_caption = captions_ids_train[idexs]\r\n",
        "#             # b_wrong_caption = tl.prepro.pad_sequences(b_wrong_caption, padding='post')\r\n",
        "#             # ## get wrong image\r\n",
        "#             # idexs2 = get_random_int(min=0, max=n_images_train-1, number=batch_size)\r\n",
        "#             # b_wrong_images = images_train[idexs2]\r\n",
        "#             # ## get noise\r\n",
        "#             b_z = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, z_dim)).astype(np.float32)\r\n",
        "#                 # b_z = np.random.uniform(low=-1, high=1, size=[batch_size, z_dim]).astype(np.float32)\r\n",
        "#\r\n",
        "#             ## update E\r\n",
        "#             errE, _ = sess.run([loss, e_optim], feed_dict={\r\n",
        "#                             t_real_caption : b_real_caption,\r\n",
        "#                             t_z : b_z})\r\n",
        "#                             # t_real_image : b_real_images,})\r\n",
        "#\r\n",
        "#             print(\"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4fs, e_loss: %8f\" \\\r\n",
        "#                         % (epoch, n_epoch, step, n_batch_epoch, time.time() - step_time, errE))\r\n",
        "#\r\n",
        "#         if (epoch + 1) % 10 == 0:\r\n",
        "#             print(\" ** Epoch %d took %fs\" % (epoch, time.time()-start_time))\r\n",
        "#             # print(sample_image.shape, t_real_image)\r\n",
        "#             img_gen = sess.run(net_g2.outputs, feed_dict={\r\n",
        "#                                         t_real_caption : sample_sentence,\r\n",
        "#                                         t_real_image : sample_image,})\r\n",
        "#             img_gen = threading_data(img_gen, imresize, size=[64, 64], interp='bilinear')\r\n",
        "#             save_images(img_gen, [ni, ni], 'samples/step_pretrain_encoder/train_{:02d}_g(e(x))).png'.format(epoch))\r\n",
        "#\r\n",
        "#         if (epoch != 0) and (epoch % 5) == 0:\r\n",
        "#             tl.files.save_npz(net_encoder.all_params, name=net_encoder_name, sess=sess)\r\n",
        "#             print(\"[*] Save checkpoints SUCCESS!\")\r\n",
        "#\r\n",
        "#\r\n",
        "# def main_transaltion():\r\n",
        "#     generator_txt2img = model.generator_txt2img_resnet\r\n",
        "#\r\n",
        "#     t_real_caption = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name='real_caption_input')\r\n",
        "#     t_real_image = tf.placeholder('float32', [batch_size, image_size, image_size, 3], name = 'real_image')\r\n",
        "#\r\n",
        "#     net_rnn = rnn_embed(t_real_caption, is_train=False, reuse=False)\r\n",
        "#     net_z = z_encoder(t_real_image, is_train=False, reuse=False)\r\n",
        "#     net_g, _ = generator_txt2img(net_z.outputs, net_rnn.outputs, is_train=False, reuse=False)\r\n",
        "#\r\n",
        "#     sess = tf.InteractiveSession()\r\n",
        "#     tl.layers.initialize_global_variables(sess)\r\n",
        "#\r\n",
        "#     net_rnn_name = os.path.join(save_dir, 'net_rnn.npz')\r\n",
        "#     net_g_name = os.path.join(save_dir, 'net_g.npz')\r\n",
        "#     net_e_name = os.path.join(save_dir, 'net_encoder.npz')\r\n",
        "#\r\n",
        "#     load_and_assign_npz(sess=sess, name=net_rnn_name, model=net_rnn)\r\n",
        "#     load_and_assign_npz(sess=sess, name=net_g_name, model=net_g)\r\n",
        "#     load_and_assign_npz(sess=sess, name=net_e_name, model=net_z)\r\n",
        "#\r\n",
        "#     ## random images\r\n",
        "#     # idexs = get_random_int(min=0, max=n_captions_train-1, number=batch_size, seed=100)  # train set\r\n",
        "#     # images = images_train[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "#     # sample_sentence = captions_ids_train[idexs]\r\n",
        "#     idexs = get_random_int(min=0, max=n_captions_test-1, number=batch_size, seed=100) # test set\r\n",
        "#     images = images_test[np.floor(np.asarray(idexs).astype('float')/n_captions_per_image).astype('int')]\r\n",
        "#     for i in [0,8,16,24,32,40,48,56]:\r\n",
        "#         images[i] = images_test[1834]     # DONE easy 226\r\n",
        "#         images[i+1] = images_test[620]    # stand on big staff\r\n",
        "#         images[i+2] = images_test[653]    # 653\r\n",
        "#         images[i+3] = images_test[77]   # DONE flying 16 20 2166big 2303ok 2306ok 2311good 2313soso 2317soso  2311(want to change)\r\n",
        "#         images[i+4] = images_test[2167]   # brunch 275 559 2101\r\n",
        "#\r\n",
        "#         images[i+5] = images_test[235]\r\n",
        "#         images[i+6] = images_test[1455]  # 717 402\r\n",
        "#         images[i+7] = images_test[159]  # fat 300  125  159  612\r\n",
        "#         # # train set\r\n",
        "#         # images[i] = images_train[620]\r\n",
        "#         # images[i+1] = images_train[653]\r\n",
        "#         # images[i+2] = images_train[300]\r\n",
        "#         # images[i+3] = images_train[350]\r\n",
        "#         # images[i+4] = images_train[550]\r\n",
        "#         # images[i+5] = images_train[700]\r\n",
        "#         # images[i+6] = images_train[717]\r\n",
        "#         # images[i+7] = images_train[275]\r\n",
        "#     # sample_sentence = captions_ids_test[idexs]\r\n",
        "#     images = threading_data(images, prepro_img, mode='translation')\r\n",
        "#     save_images(images, [ni, ni], 'samples/translation/_reed_method_ori.png')\r\n",
        "#\r\n",
        "#     # all done\r\n",
        "#     sample_sentence = [\"This small bird has a blue crown and white belly.\"] * ni + \\\r\n",
        "#                       [\"This small yellow bird has grey wings, and a black bill.\"] * ni + \\\r\n",
        "#                       [\"This particular bird with a red head and breast and features grey wings.\"] * ni + \\\r\n",
        "#                       [\"This black bird has no other colors with a short bill.\"] * ni + \\\r\n",
        "#                       [\"An orange bird with green wings and blue head.\"] * ni + \\\r\n",
        "#                       [\"A black bird with a red head.\"] * ni + \\\r\n",
        "#                       [\"A red body bird with black wings and a gray beak.\"] * ni + \\\r\n",
        "#                       [\"A small brown bird with a brown crown has a white belly.\"] * ni\r\n",
        "#\r\n",
        "#     for i, sentence in enumerate(sample_sentence):\r\n",
        "#         print(\"seed: %s\" % sentence)\r\n",
        "#         sentence = preprocess_caption(sentence)\r\n",
        "#         sample_sentence[i] = [vocab.word_to_id(word) for word in nltk.tokenize.word_tokenize(sentence)] #+ [vocab.end_id]    # add END_ID\r\n",
        "#         # sample_sentence[i] = [vocab.word_to_id(word) for word in sentence]\r\n",
        "#         # print(sample_sentence[i])\r\n",
        "#     sample_sentence = tl.prepro.pad_sequences(sample_sentence, padding='post')\r\n",
        "#\r\n",
        "#     for i in range(1):\r\n",
        "#         img_trans = sess.run(net_g.outputs, feed_dict={\r\n",
        "#                                     t_real_caption : sample_sentence,\r\n",
        "#                                     t_real_image : images,\r\n",
        "#                                     })\r\n",
        "#\r\n",
        "#         save_images(img_trans, [ni, ni], 'samples/translation/_reed_method_tran%d.png' % i)\r\n",
        "#         print(\"completed %s\" % i)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    import argparse\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    parser.add_argument('--mode', type=str, default=\"train\",\r\n",
        "                       help='train, train_encoder, translation')\r\n",
        "\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    if args.mode == \"train\":\r\n",
        "        main_train()\r\n",
        "\r\n",
        "    ## you would not use this part, unless you want to try style transfer on GAN-CLS paper\r\n",
        "    # elif args.mode == \"train_encoder\":\r\n",
        "    #     main_train_encoder()\r\n",
        "    #\r\n",
        "    # elif args.mode == \"translation\":\r\n",
        "    #     main_transaltion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysqV1muScRHx"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import random\r\n",
        "import scipy\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import string\r\n",
        "\r\n",
        "\"\"\" The functions here will be merged into TensorLayer after finishing this project.\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def load_and_assign_npz(sess=None, name=\"\", model=None):\r\n",
        "    assert model is not None\r\n",
        "    assert sess is not None\r\n",
        "    if not os.path.exists(name):\r\n",
        "        print(\"[!] Loading {} model failed!\".format(name))\r\n",
        "        return False\r\n",
        "    else:\r\n",
        "        params = tl.files.load_npz(name=name)\r\n",
        "        tl.files.assign_params(sess, params, model)\r\n",
        "        print(\"[*] Loading {} model SUCCESS!\".format(name))\r\n",
        "        return model\r\n",
        "\r\n",
        "\r\n",
        "#files\r\n",
        "def load_folder_list(path=\"\"):\r\n",
        "    \"\"\"Return a folder list in a folder by given a folder path.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string or None\r\n",
        "        A folder path.\r\n",
        "    \"\"\"\r\n",
        "    return [os.path.join(path,o) for o in os.listdir(path) if os.path.isdir(os.path.join(path,o))]\r\n",
        "\r\n",
        "#utils\r\n",
        "def print_dict(dictionary={}):\r\n",
        "    \"\"\"Print all keys and items in a dictionary.\r\n",
        "    \"\"\"\r\n",
        "    for key, value in dictionary.iteritems():\r\n",
        "        print(\"key: %s  value: %s\" % (str(key), str(value)))\r\n",
        "\r\n",
        "#prepro ?\r\n",
        "def get_random_int(min=0, max=10, number=5):\r\n",
        "    \"\"\"Return a list of random integer by the given range and quantity.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> r = get_random_int(min=0, max=10, number=5)\r\n",
        "    ... [10, 2, 3, 3, 7]\r\n",
        "    \"\"\"\r\n",
        "    return [random.randint(min,max) for p in range(0,number)]\r\n",
        "\r\n",
        "def preprocess_caption(line):\r\n",
        "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\r\n",
        "    prep_line = prep_line.replace('-', ' ')\r\n",
        "    return prep_line\r\n",
        "\r\n",
        "\r\n",
        "## Save images\r\n",
        "def merge(images, size):\r\n",
        "    h, w = images.shape[1], images.shape[2]\r\n",
        "    img = np.zeros((h * size[0], w * size[1], 3))\r\n",
        "    for idx, image in enumerate(images):\r\n",
        "        i = idx % size[1]\r\n",
        "        j = idx // size[1]\r\n",
        "        img[j*h:j*h+h, i*w:i*w+w, :] = image\r\n",
        "    return img\r\n",
        "\r\n",
        "def imsave(images, size, path):\r\n",
        "    return scipy.misc.imsave(path, merge(images, size))\r\n",
        "\r\n",
        "def save_images(images, size, image_path):\r\n",
        "    return imsave(images, size, image_path)\r\n",
        "\r\n",
        "from tensorlayer.prepro import *\r\n",
        "def prepro_img(x, mode=None):\r\n",
        "    if mode=='train':\r\n",
        "    # rescale [0, 255] --> (-1, 1), random flip, crop, rotate\r\n",
        "    #   paper 5.1: During mini-batch selection for training we randomly pick\r\n",
        "    #   an image view (e.g. crop, flip) of the image and one of the captions\r\n",
        "    # flip, rotate, crop, resize : https://github.com/reedscot/icml2016/blob/master/data/donkey_folder_coco.lua\r\n",
        "    # flip : https://github.com/paarthneekhara/text-to-image/blob/master/Utils/image_processing.py\r\n",
        "        x = flip_axis(x, axis=1, is_random=True)\r\n",
        "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\r\n",
        "            # x = crop(x, wrg=50, hrg=50, is_random=True)\r\n",
        "            # x = imresize(x, size=[64, 64], interp='bilinear', mode=None)\r\n",
        "        x = imresize(x, size=[64+15, 64+15], interp='bilinear', mode=None)\r\n",
        "        x = crop(x, wrg=64, hrg=64, is_random=True)\r\n",
        "        x = x / (255. / 2.)\r\n",
        "        x = x - 1.\r\n",
        "        # x = x * 0.9999\r\n",
        "    elif mode=='train_stackGAN':\r\n",
        "        x = flip_axis(x, axis=1, is_random=True)\r\n",
        "        x = rotation(x, rg=16, is_random=True, fill_mode='nearest')\r\n",
        "            # x = crop(x, wrg=50, hrg=50, is_random=True)\r\n",
        "            # x = imresize(x, size=[64, 64], interp='bilinear', mode=None)\r\n",
        "        x = imresize(x, size=[316, 316], interp='bilinear', mode=None)\r\n",
        "        x = crop(x, wrg=256, hrg=256, is_random=True)\r\n",
        "        x = x / (255. / 2.)\r\n",
        "        x = x - 1.\r\n",
        "        # x = x * 0.9999\r\n",
        "    elif mode=='rescale':\r\n",
        "    # rescale (-1, 1) --> (0, 1) for display\r\n",
        "        x = (x + 1.) / 2.\r\n",
        "    elif mode=='debug':\r\n",
        "        x = flip_axis(x, axis=1, is_random=False)\r\n",
        "        # x = rotation(x, rg=16, is_random=False, fill_mode='nearest')\r\n",
        "        # x = crop(x, wrg=50, hrg=50, is_random=True)\r\n",
        "        # x = imresize(x, size=[64, 64], interp='bilinear', mode=None)\r\n",
        "        x = x / 255.\r\n",
        "    elif mode=='translation':\r\n",
        "        x = x / (255. / 2.)\r\n",
        "        x = x - 1.\r\n",
        "        # from skimage.filters import gaussian\r\n",
        "        # print(x.shape, np.min(x), np.max(x))\r\n",
        "        # x = x * 0.9999\r\n",
        "        # x = gaussian(x, sigma=0.6, multichannel=True)\r\n",
        "    else:\r\n",
        "        raise Exception(\"Not support : %s\" % mode)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def combine_and_save_image_sets(image_sets, directory):\r\n",
        "    for i in range(len(image_sets[0])):\r\n",
        "        combined_image = []\r\n",
        "        for set_no in range(len(image_sets)):\r\n",
        "            combined_image.append( image_sets[set_no][i] )\r\n",
        "            combined_image.append( np.zeros((image_sets[set_no][i].shape[0], 5, 3)) )\r\n",
        "        combined_image = np.concatenate( combined_image, axis = 1 )\r\n",
        "\r\n",
        "        scipy.misc.imsave( os.path.join( directory,  'combined_{}.jpg'.format(i) ), combined_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GBoNDzMcllZ"
      },
      "source": [
        "#! /usr/bin/python\r\n",
        "# -*- coding: utf8 -*-\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorlayer as tl\r\n",
        "from tensorlayer.layers import *\r\n",
        "import os\r\n",
        "\r\n",
        "\"\"\"Adversarially Learned Inference\r\n",
        "Page 14: CelebA model hyperparameters\r\n",
        "Optimizer Adam (α = 10−4, β1 = 0.5)\r\n",
        "Batch size 100 Epochs 123\r\n",
        "Leaky ReLU slope 0.02\r\n",
        "Weight, bias initialization Isotropic gaussian (µ = 0, σ = 0.01), Constant(0)\r\n",
        "\"\"\"\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "z_dim = 512         # Noise dimension\r\n",
        "image_size = 64     # 64 x 64\r\n",
        "c_dim = 3           # for rgb\r\n",
        "\r\n",
        "\r\n",
        "def generator(input_z, input_txt=None, is_train=True, reuse=False, batch_size=batch_size):\r\n",
        "    \"\"\" G(z) or G(z, RNN(txt)) / output (64, 64, 3) \"\"\"\r\n",
        "    s = image_size\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "    gf_dim = 128\r\n",
        "\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.02)\r\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"generator\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_z, name='g_inputz')\r\n",
        "\r\n",
        "        if input_txt is not None:\r\n",
        "            net_txt = InputLayer(input_txt, name='g_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "                    act=lrelu,\r\n",
        "                    W_init = w_init, b_init=None, name='g_reduce_text/dense')\r\n",
        "            net_in = ConcatLayer([net_in, net_txt], concat_dim=1, name='g_concat_z_txt')\r\n",
        "\r\n",
        "        net_h0 = DenseLayer(net_in, gf_dim*8*s16*s16, act=tf.identity,\r\n",
        "                W_init=w_init, b_init=None, name='g_h0/dense')\r\n",
        "        net_h0 = BatchNormLayer(net_h0, #act=tf.identity,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h0/batch_norm')\r\n",
        "        net_h0 = ReshapeLayer(net_h0, [-1, s16, s16, gf_dim*8], name='g_h0/reshape')\r\n",
        "\r\n",
        "        net = Conv2d(net_h0, gf_dim*2, (1, 1), (1, 1),\r\n",
        "                padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h1_res/batch_norm')\r\n",
        "        net = Conv2d(net, gf_dim*2, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h1_res/batch_norm2')\r\n",
        "        net = Conv2d(net, gf_dim*8, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, # act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h1_res/batch_norm3')\r\n",
        "        net_h1 = ElementwiseLayer(layer=[net_h0, net], combine_fn=tf.add, name='g_h1_res/add')\r\n",
        "        net_h1.outputs = lrelu(net_h1.outputs)\r\n",
        "\r\n",
        "        net_h2 = DeConv2d(net_h1, gf_dim*4, (4, 4), out_size=(s8, s8), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h2/decon2d')\r\n",
        "        # net_h2 = UpSampling2dLayer(net_h1, size=[s8, s8], is_scale=False, method=1,\r\n",
        "        #         align_corners=False, name='g_h2/upsample2d')\r\n",
        "        # net_h2 = Conv2d(net_h2, gf_dim*4, (3, 3), (1, 1),\r\n",
        "        #         padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2,# act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h2/batch_norm')\r\n",
        "\r\n",
        "        net = Conv2d(net_h2, gf_dim, (1, 1), (1, 1),\r\n",
        "                padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h3_res/batch_norm')\r\n",
        "        net = Conv2d(net, gf_dim, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h3_res/batch_norm2')\r\n",
        "        net = Conv2d(net, gf_dim*4, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, #act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h3_res/batch_norm3')\r\n",
        "        net_h3 = ElementwiseLayer(layer=[net_h2, net], combine_fn=tf.add, name='g_h3_res/add')\r\n",
        "        net_h3.outputs = lrelu(net_h3.outputs)\r\n",
        "\r\n",
        "        net_h4 = DeConv2d(net_h3, gf_dim*2, (4, 4), out_size=(s4, s4), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h4/decon2d')\r\n",
        "        # net_h4 = UpSampling2dLayer(net_h3, size=[s4, s4], is_scale=False, method=1,\r\n",
        "        #         align_corners=False, name='g_h4/upsample2d')\r\n",
        "        # net_h4 = Conv2d(net_h4, gf_dim*2, (3, 3), (1, 1),\r\n",
        "        #         padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h4/conv2d')\r\n",
        "        net_h4 = BatchNormLayer(net_h4, act=lrelu,#tf.nn.relu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h4/batch_norm')\r\n",
        "\r\n",
        "        net_h5 = DeConv2d(net_h4, gf_dim, (4, 4), out_size=(s2, s2), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h5/decon2d')\r\n",
        "        # net_h5 = UpSampling2dLayer(net_h4, size=[s2, s2], is_scale=False, method=1,\r\n",
        "        #         align_corners=False, name='g_h5/upsample2d')\r\n",
        "        # net_h5 = Conv2d(net_h5, gf_dim, (3, 3), (1, 1),\r\n",
        "        #         padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h5/conv2d')\r\n",
        "        net_h5 = BatchNormLayer(net_h5, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h5/batch_norm')\r\n",
        "\r\n",
        "        net_ho = DeConv2d(net_h5, c_dim, (4, 4), out_size=(s, s), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, name='g_ho/decon2d')\r\n",
        "        # net_ho = UpSampling2dLayer(net_h9, size=[s, s], is_scale=False, method=1,\r\n",
        "        #         align_corners=False, name='g_ho/upsample2d')\r\n",
        "        # net_ho = Conv2d(net_ho, c_dim, (3, 3), (1, 1),\r\n",
        "        #         padding='SAME', act=None, W_init=w_init, name='g_ho/conv2d')\r\n",
        "        logits = net_ho.outputs\r\n",
        "        net_ho.outputs = tf.nn.tanh(net_ho.outputs)\r\n",
        "    return net_ho, logits\r\n",
        "\r\n",
        "def encoder_simple(input_images, input_txt=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" E(x) input (64, 64, 3), output z \"\"\"\r\n",
        "    s = image_size\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "    # 32 16 8 4\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.01)\r\n",
        "    df_dim = 64\r\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"encoder\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_images, name='ig_inputz')\r\n",
        "        # print(net_in.outputs)\r\n",
        "        # exit()\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (2, 2), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h0/conv2d')\r\n",
        "        net_h0 = BatchNormLayer(net_h0, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h0/batchnorm')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (7, 7), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1/batchnorm')\r\n",
        "\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (5, 5), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h2/batchnorm')\r\n",
        "\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*4, (7, 7), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h3/batchnorm')\r\n",
        "\r\n",
        "        net_h4 = Conv2d(net_h3, df_dim*8, (4, 4), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h4/conv2d')\r\n",
        "        net_h4 = BatchNormLayer(net_h4, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h4/batchnorm')\r\n",
        "\r\n",
        "        if input_txt is not None:\r\n",
        "            net_txt = InputLayer(input_txt, name='ig_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   W_init=w_init, b_init=None, name='ig_reduce_txt/dense')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim1')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim2')\r\n",
        "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='ig_txt/tile')\r\n",
        "            net_h4_concat = ConcatLayer([net_h4, net_txt], concat_dim=3, name='ig_txt/concat')\r\n",
        "            net_h4 = Conv2d(net_h4_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "                   padding='SAME', W_init=w_init, b_init=None, name='ig_txt/conv2d_2')\r\n",
        "            net_h4 = BatchNormLayer(net_h4, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   is_train=is_train, gamma_init=gamma_init, name='ig_txt/batch_norm_2')\r\n",
        "        # print(net_h4.outputs) # (100, 8, 8, 512)\r\n",
        "        # exit()\r\n",
        "        # net_ho = Conv2d(net_h4, df_dim*8, (1, 1), (1, 1), act=None,\r\n",
        "        #         padding='VALID', W_init=w_init, b_init=None, name='ig_ho/conv2d')  # DH\r\n",
        "        # print(net_h4.outputs) # (100, 1, 1, 512)\r\n",
        "        # exit()\r\n",
        "        net_ho = FlattenLayer(net_h4, name='ig_ho/flatten')\r\n",
        "        net_ho = DenseLayer(net_ho, n_units=z_dim, name='ig_ho/dense')\r\n",
        "        # print(net_ho.outputs)\r\n",
        "        # exit()\r\n",
        "        return net_ho\r\n",
        "\r\n",
        "# def encoder(input_images, is_train=True, reuse=False):\r\n",
        "#     \"\"\" E(x) input (64, 64, 3), output z \"\"\"\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "#     gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "#     df_dim = 128#64\r\n",
        "#     with tf.variable_scope(\"encoder\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         # (nc) x 64 x 64\r\n",
        "#         net_in = InputLayer(input_images, name='ig_input/images')\r\n",
        "#         net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 padding='SAME', W_init=w_init, name='p_h0/conv2d')\r\n",
        "#\r\n",
        "#         net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig_h1/conv2d')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h1/batchnorm')\r\n",
        "#         net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig_h2/conv2d')\r\n",
        "#         net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h2/batchnorm')\r\n",
        "#         net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig_h3/conv2d')\r\n",
        "#         net_h3 = BatchNormLayer(net_h3, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h3/batchnorm')\r\n",
        "#\r\n",
        "#         net_h = Conv2d(net_h3, df_dim*2, (1, 1), (1, 1), act=None,\r\n",
        "#                 padding='VALID', W_init=w_init, b_init=None, name='ig_h3/conv2d2')\r\n",
        "#         net_h = BatchNormLayer(net_h, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h3/batchnorm2')\r\n",
        "#         net_h = Conv2d(net_h, df_dim*2, (3, 3), (1, 1), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig_h3/conv2d3')\r\n",
        "#         net_h = BatchNormLayer(net_h, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h3/batchnorm3')\r\n",
        "#         net_h = Conv2d(net_h, df_dim*8, (3, 3), (1, 1), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig_h3/conv2d4')\r\n",
        "#         net_h = BatchNormLayer(net_h, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig_h3/batchnorm4')\r\n",
        "#         net_h3 = ElementwiseLayer(layer=[net_h3, net_h], combine_fn=tf.add, name='ig_h3/add')\r\n",
        "#         net_h3.outputs = tl.act.lrelu(net_h3.outputs, 0.2)\r\n",
        "#\r\n",
        "#         net_h4 = Conv2d(net_h3, df_dim*2, (4, 4), (1, 1), padding='SAME',\r\n",
        "#                 W_init=w_init, name='ig_h4/conv2d_2')\r\n",
        "#         # print(net_h4.outputs)   # (100, 4, 4, 256)\r\n",
        "#         # exit()\r\n",
        "#         # 1 x 1 x 1\r\n",
        "#         net_h4 = FlattenLayer(net_h4, name='ig_h4/flatten')\r\n",
        "#         net_h4 = DenseLayer(net_h4, n_units=z_dim,\r\n",
        "#                 act=tf.identity, W_init=w_init, b_init = None, name='ig/h4/embed')\r\n",
        "#     return net_h4\r\n",
        "\r\n",
        "def encoder_resnet(input_images, input_txt=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" E(x) 64x64 --> z \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "\r\n",
        "    df_dim = 128#64\r\n",
        "    with tf.variable_scope(\"encoder\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        # (nc) x 64 x 64\r\n",
        "        net_in = InputLayer(input_images, name='ig_input/images')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lrelu,\r\n",
        "                padding='SAME', W_init=w_init, name='p_h0/conv2d')\r\n",
        "        # print(net_h0.outputs) # (100, 32, 32, 128)\r\n",
        "        # exit()\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1/batchnorm')\r\n",
        "        net_h1 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h1/conv2d2')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, #act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1/batchnorm2')\r\n",
        "        # print(net_h1.outputs) # (100, 8, 8, 512)\r\n",
        "        # exit()\r\n",
        "        net = Conv2d(net_h1, df_dim*1, (1, 1), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h1_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1_res/batchnorm')\r\n",
        "        net = Conv2d(net, df_dim*1, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h1_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1_res/batchnorm2')\r\n",
        "        net = Conv2d(net, df_dim*4, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h1_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h1_res/batchnorm3')\r\n",
        "        net_h1 = ElementwiseLayer(layer=[net_h1, net], combine_fn=tf.add, name='ig_h1_res/add')\r\n",
        "        net_h1.outputs = lrelu(net_h1.outputs)\r\n",
        "\r\n",
        "        # print(net_h1.outputs) # (100, 8, 8, 512)\r\n",
        "        # exit()\r\n",
        "\r\n",
        "        # net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "        #         padding='SAME', W_init=w_init, b_init=None, name='ig_h2/conv2d')\r\n",
        "        # net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "        #         is_train=is_train, gamma_init=gamma_init, name='ig_h2/batchnorm')\r\n",
        "        # print(net_h2.outputs)\r\n",
        "        # exit()\r\n",
        "\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h2/batchnorm')\r\n",
        "        # print(net_h3.outputs)\r\n",
        "        # exit()\r\n",
        "\r\n",
        "        net = Conv2d(net_h2, df_dim*2, (1, 1), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='ig_h3_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h3_res/batchnorm2')\r\n",
        "        net = Conv2d(net, df_dim*2, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h3_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h3_res/batchnorm3')\r\n",
        "        net = Conv2d(net, df_dim*8, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='ig_h3_res/conv2d4')\r\n",
        "        net = BatchNormLayer(net, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='ig_h3_res/batchnorm4')\r\n",
        "        net_h3 = ElementwiseLayer(layer=[net_h2, net], combine_fn=tf.add, name='ig_h3_res/add')\r\n",
        "        net_h3.outputs = lrelu(net_h3.outputs)\r\n",
        "        # print(net_h3.outputs)\r\n",
        "        # exit()\r\n",
        "        if input_txt is not None:\r\n",
        "            net_txt = InputLayer(input_txt, name='ig_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   W_init=w_init, b_init=None, name='ig_reduce_txt/dense')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim1')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim2')\r\n",
        "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='ig_txt/tile')\r\n",
        "            net_h3_concat = ConcatLayer([net_h3, net_txt], concat_dim=3, name='ig_txt/concat')\r\n",
        "            net_h3 = Conv2d(net_h3_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "                   padding='SAME', W_init=w_init, b_init=None, name='ig_txt/conv2d_2')\r\n",
        "            net_h3 = BatchNormLayer(net_h3, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   is_train=is_train, gamma_init=gamma_init, name='ig_txt/batch_norm_2')\r\n",
        "\r\n",
        "        net_h3 = Conv2d(net_h3, df_dim*4, (4, 4), (1, 1), padding='SAME',\r\n",
        "                W_init=w_init, name='ig_h3/conv2d_2')\r\n",
        "        # print(net_h3.outputs)\r\n",
        "        # exit()\r\n",
        "        net_ho = FlattenLayer(net_h3, name='ig_ho/flatten')\r\n",
        "        net_ho = DenseLayer(net_ho, n_units=z_dim, act=tf.identity,\r\n",
        "                W_init=w_init, b_init = None, name='ig/ho/embed')\r\n",
        "    return net_ho\r\n",
        "\r\n",
        "def discriminator_x(input_images, input_txt=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" D(x) input (64, 64, 3) \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "    # w_init1 = tf.random_normal_initializer(stddev=0.01 * 2 * 2)\r\n",
        "    # w_init2 = tf.random_normal_initializer(stddev=0.01 * 7 * 7)\r\n",
        "    # w_init3 = tf.random_normal_initializer(stddev=0.01 * 5 * 5)\r\n",
        "    # w_init4 = tf.random_normal_initializer(stddev=0.01 * 7 * 7)\r\n",
        "    # w_init5 = tf.random_normal_initializer(stddev=0.01 * 4 * 4)\r\n",
        "    gamma_init=tf.random_normal_initializer(1., 0.01)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"discriminator_x\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "\r\n",
        "        net_in = InputLayer(input_images, name='dx_input/images')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (2, 2), (1, 1), act=lrelu,\r\n",
        "                padding='VALID', W_init=w_init, name='dx_h0/conv2d')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (7, 7), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='dx_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='dx_h1/batchnorm')\r\n",
        "\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (5, 5), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='dx_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='dx_h2/batchnorm')\r\n",
        "\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*4, (7, 7), (2, 2), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='dx_h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='dx_h3/batchnorm')\r\n",
        "\r\n",
        "        net_h4 = Conv2d(net_h3, df_dim*8, (4, 4), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='dx_h4/conv2d')\r\n",
        "        net_h4 = BatchNormLayer(net_h4, act=lrelu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='dx_h4/batchnorm')\r\n",
        "\r\n",
        "        if input_txt is not None:\r\n",
        "            net_txt = InputLayer(input_txt, name='dx_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   W_init=w_init, b_init=None, name='dx_reduce_txt/dense')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim1')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim2')\r\n",
        "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\r\n",
        "            net_h4_concat = ConcatLayer([net_h4, net_txt], concat_dim=3, name='dx_txt/concat')\r\n",
        "            net_h4 = Conv2d(net_h4_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "                   padding='SAME', W_init=w_init, b_init=None, name='dx_txt/conv2d_2')\r\n",
        "            net_h4 = BatchNormLayer(net_h4, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   is_train=is_train, gamma_init=gamma_init, name='dx_txt/batch_norm_2')\r\n",
        "\r\n",
        "        # print(net_h4.outputs, df_dim*8)\r\n",
        "        # exit()\r\n",
        "        net_ho = FlattenLayer(net_h4, name='dx_ho/flatten')\r\n",
        "        # net_ho = DenseLayer(net_ho, n_units=z_dim, act=tf.identity,\r\n",
        "        #         W_init = w_init, name='dx_ho/dense') # 512\r\n",
        "        # print(net_ho.outputs)\r\n",
        "        # exit()\r\n",
        "        return net_ho\r\n",
        "\r\n",
        "# def discriminator_x(input_images, input_txt=None, is_train=True, reuse=False): # cnn_encoder_resnet\r\n",
        "#     \"\"\" D(x) or D(x, RNN(txt)) / x=(64, 64, 3), output z \"\"\"\r\n",
        "#     # https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py  d_encode_image\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "#     gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "#     lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "#\r\n",
        "#     df_dim = 64\r\n",
        "#     with tf.variable_scope(\"discriminator_x\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         # (nc) x 64 x 64\r\n",
        "#         net_in = InputLayer(input_images, name='dx_input/images')\r\n",
        "#\r\n",
        "#         # net_in = DropoutLayer(net_in, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_in')\r\n",
        "#         net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 padding='SAME', W_init=w_init, name='dx_h0/conv2d')\r\n",
        "#\r\n",
        "#         # net_h0 = DropoutLayer(net_h0, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_h0')\r\n",
        "#         net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h1/conv2d')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h1/batchnorm')\r\n",
        "#         # net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_h1')\r\n",
        "#         net_h1 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h1/conv2d2')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h1/batchnorm2')\r\n",
        "#         # net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_h2')\r\n",
        "#         net_h1 = Conv2d(net_h1, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h1/conv2d3')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h1/batchnorm3')\r\n",
        "#\r\n",
        "#         # net_h3 = DropoutLayer(net_h3, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_h3')\r\n",
        "#         net_h = Conv2d(net_h1, df_dim*2, (1, 1), (1, 1), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h_res/conv2d2')\r\n",
        "#         net_h = BatchNormLayer(net_h, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h_res/batchnorm2')\r\n",
        "#         # net_h = DropoutLayer(net_h, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_resh1')\r\n",
        "#         net_h = Conv2d(net_h, df_dim*2, (3, 3), (1, 1), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h_res/conv2d3')\r\n",
        "#         net_h = BatchNormLayer(net_h, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h_res/batchnorm3')\r\n",
        "#         # net_h = DropoutLayer(net_h, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_resh2')\r\n",
        "#         net_h = Conv2d(net_h, df_dim*8, (3, 3), (1, 1), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h_res/conv2d4')\r\n",
        "#         net_h = BatchNormLayer(net_h, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h_res/batchnorm4')\r\n",
        "#         net_h2 = ElementwiseLayer(layer=[net_h1, net_h], combine_fn=tf.add, name='dx_h_res/add')\r\n",
        "#         net_h2.outputs = tl.act.lrelu(net_h2.outputs, 0.2)\r\n",
        "#\r\n",
        "#         if input_txt is not None:\r\n",
        "#             net_txt = InputLayer(input_txt, name='dx_input_txt')\r\n",
        "#             net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    W_init=w_init, b_init=None, name='dx_reduce_txt/dense')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim1')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim2')\r\n",
        "#             net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\r\n",
        "#             net_h2_concat = ConcatLayer([net_h2, net_txt], concat_dim=3, name='dx_txt/concat')\r\n",
        "#             net_h2 = Conv2d(net_h2_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "#                    padding='SAME', W_init=w_init, b_init=None, name='dx_txt/conv2d_2')\r\n",
        "#             net_h2 = BatchNormLayer(net_h2, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    is_train=is_train, gamma_init=gamma_init, name='dx_txt/batch_norm_2')\r\n",
        "#\r\n",
        "#         # net_h2 = DropoutLayer(net_h2, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_after_concat')\r\n",
        "#         net_ho = Conv2d(net_h2, df_dim*2, (4, 4), (1, 1), padding='SAME',\r\n",
        "#                 W_init=w_init, name='dx_ho/conv2d_2')\r\n",
        "#         # print(net_ho.outputs)   # (100, 4, 4, 128)\r\n",
        "#         # 1 x 1 x 1\r\n",
        "#         # net_ho = DropoutLayer(net_ho, keep=0.8, is_fix=True, is_train=is_train, name='dx_drop_ho')\r\n",
        "#         net_ho = FlattenLayer(net_ho, name='dx_ho/flatten')\r\n",
        "#         # exit()\r\n",
        "#         net_ho = DenseLayer(net_ho, n_units=z_dim, act=tf.identity,\r\n",
        "#                 W_init=w_init, b_init = None, name='dx/h4/embed')\r\n",
        "#     return net_ho\r\n",
        "\r\n",
        "def discriminator_z(input_z, is_train=True, reuse=False):\r\n",
        "    \"\"\" D(z) input z \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.02)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"discriminator_z\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_z, name='dz_input/z')\r\n",
        "        # net_in = ReshapeLayer(net_in, [-1, 1, 1, z_dim], name='dz_reshape')\r\n",
        "\r\n",
        "        net_in = DropoutLayer(net_in, keep=0.8, is_fix=True, is_train=is_train, name='dz_in/drop')\r\n",
        "            # net_h0 = Conv2d(net_in, 1024, (1, 1), (1, 1), act=lrelu,\r\n",
        "            #         padding='VALID', W_init=w_init, name='dz_h0/conv2d')\r\n",
        "        net_h0 = DenseLayer(net_in, n_units=1024, act=lrelu,\r\n",
        "                W_init=w_init, name='dz_h0/conv2d')\r\n",
        "\r\n",
        "        net_h0 = DropoutLayer(net_h0, keep=0.8, is_fix=True, is_train=is_train, name='dz_h0/drop')\r\n",
        "            # net_h1 = Conv2d(net_h0, 1024, (1, 1), (1, 1), act=lrelu,\r\n",
        "            #         padding='VALID', W_init=w_init, name='dz_h1/conv2d')\r\n",
        "        net_h1 = DenseLayer(net_h0, n_units=1024, act=lrelu,\r\n",
        "                W_init=w_init, name='dz_h1/conv2d')\r\n",
        "\r\n",
        "        # net_h1 = FlattenLayer(net_h1, name='dz_flatten')\r\n",
        "        # print(net_h1.outputs) # 1024\r\n",
        "        # exit()\r\n",
        "        return net_h1\r\n",
        "\r\n",
        "def discriminator_combine_xz(x, z, is_train=True, reuse=False):\r\n",
        "    \"\"\" combine D(x) or D(x, RNN(txt)) with D(z), output real/fake \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.02)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"discriminator_xz\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in_x = InputLayer(x, name='d_input/x')\r\n",
        "        net_in_z = InputLayer(z, name='d_input/z')\r\n",
        "        net_in = ConcatLayer([net_in_z, net_in_x], concat_dim=1, name='d/concat')\r\n",
        "        # print(net_in.outputs)\r\n",
        "        # exit()\r\n",
        "        # net_in = ExpandDimsLayer(net_in, 1 , name='d/expanddim1')\r\n",
        "        # net_in = ExpandDimsLayer(net_in, 1 , name='d/expanddim2')\r\n",
        "\r\n",
        "        net_in = DropoutLayer(net_in, keep=0.8, is_fix=True, is_train=is_train, name='d_in/drop')\r\n",
        "        # net_h0 = Conv2d(net_in, 2048, (1, 1), (1, 1), act=lrelu,\r\n",
        "        #         padding='VALID', W_init=w_init, name='d_h0/conv2d')\r\n",
        "        net_h0 = DenseLayer(net_in, n_units=1024,#2048,\r\n",
        "                act=lrelu,\r\n",
        "                W_init=w_init, name='d_h0/conv2d')\r\n",
        "\r\n",
        "        net_h0 = DropoutLayer(net_h0, keep=0.8, is_fix=True, is_train=is_train, name='d_h0/drop')\r\n",
        "        # net_h1 = Conv2d(net_h0, 2048, (1, 1), (1, 1), act=lrelu,\r\n",
        "        #         padding='VALID', W_init=w_init, name='d_h1/conv2d')\r\n",
        "        net_h1 = DenseLayer(net_h0, n_units=1024,#2048,\r\n",
        "                act=lrelu,\r\n",
        "                W_init=w_init, name='d_h1/conv2d')\r\n",
        "\r\n",
        "        net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, is_train=is_train, name='d_h1/drop')\r\n",
        "        # net_ho = Conv2d(net_h1, 1, (1, 1), (1, 1), act=None,\r\n",
        "        #         padding='VALID', W_init=w_init, name='d_ho/conv2d')\r\n",
        "        net_ho = DenseLayer(net_h1, n_units=1, act=tf.identity,\r\n",
        "                W_init=w_init, name='d_ho/conv2d')\r\n",
        "        # print(net_ho.outputs) # 1\r\n",
        "        # exit()\r\n",
        "        # net_ho = FlattenLayer(net_ho, name='d_ho/flatten')\r\n",
        "        # print(net_ho.outputs) # 1\r\n",
        "        # exit()\r\n",
        "        logits = net_ho.outputs\r\n",
        "        net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\r\n",
        "        return net_ho, logits\r\n",
        "\r\n",
        "def discriminator(x, z, input_txt=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" D(x, z) or D(x, z, text)\r\n",
        "    x=64x64\r\n",
        "    \"\"\"\r\n",
        "    net_z = discriminator_z(z, is_train=is_train, reuse=reuse)\r\n",
        "    net_x = discriminator_x(x, input_txt=input_txt, is_train=is_train, reuse=reuse)\r\n",
        "    net_d, logits = discriminator_combine_xz(net_x.outputs, net_z.outputs, is_train=is_train, reuse=reuse)\r\n",
        "    net_d.all_params.extend(net_x.all_params)\r\n",
        "    net_d.all_params.extend(net_z.all_params)\r\n",
        "    return net_d, logits\r\n",
        "\r\n",
        "## follow DCGAN architecture / WORK but no deep enough for flower dataset\r\n",
        "# def generator(input_z, input_txt=None, is_train=True, reuse=False, batch_size=batch_size):\r\n",
        "#     \"\"\" G(z) input z, output (64, 64, 3) \"\"\"\r\n",
        "#     s = image_size\r\n",
        "#     s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "#     # 32 16 8 4\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "#     gamma_init = tf.random_normal_initializer(1., 0.01)\r\n",
        "#     gf_dim = 128\r\n",
        "#\r\n",
        "#     with tf.variable_scope(\"generator\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         net_in = InputLayer(input_z, name='g_inputz')\r\n",
        "#\r\n",
        "#         if input_txt is not None:\r\n",
        "#             net_txt = InputLayer(input_txt, name='g_input_txt')\r\n",
        "#             net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "#                     act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                     W_init = w_init, b_init=None, name='g_reduce_text/dense')\r\n",
        "#             # paper 4.1 : and then concatenated to the noise vector z\r\n",
        "#             net_in = ConcatLayer([net_in, net_txt], concat_dim=1, name='g_concat_z_txt')\r\n",
        "#\r\n",
        "#         net_h0 = DenseLayer(net_in, gf_dim*8*s16*s16, act=tf.identity,\r\n",
        "#                 W_init=w_init, b_init=None, name='g_h0/dense')\r\n",
        "#         net_h0 = ReshapeLayer(net_h0, [-1, s16, s16, gf_dim*8], name='g_h0/reshape')\r\n",
        "#         net_h0 = BatchNormLayer(net_h0, act=tf.nn.relu, is_train=is_train,\r\n",
        "#                 gamma_init=gamma_init, name='g_h0/batch_norm')\r\n",
        "#\r\n",
        "#         net_h1 = DeConv2d(net_h0, gf_dim*4, (5, 5), out_size=(s8, s8), strides=(2, 2),\r\n",
        "#                 padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h1/decon2d')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=tf.nn.relu, is_train=is_train,\r\n",
        "#                 gamma_init=gamma_init, name='g_h1/batch_norm')\r\n",
        "#\r\n",
        "#         net_h2 = DeConv2d(net_h1, gf_dim*2, (5, 5), out_size=(s4, s4), strides=(2, 2),\r\n",
        "#                 padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h2/decon2d')\r\n",
        "#         net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu, is_train=is_train,\r\n",
        "#                 gamma_init=gamma_init, name='g_h2/batch_norm')\r\n",
        "#\r\n",
        "#         net_h3 = DeConv2d(net_h2, gf_dim, (5, 5), out_size=(s2, s2), strides=(2, 2),\r\n",
        "#                 padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=None, name='g_h3/decon2d')\r\n",
        "#         net_h3 = BatchNormLayer(net_h3, act=tf.nn.relu, is_train=is_train,\r\n",
        "#                 gamma_init=gamma_init, name='g_h3/batch_norm')\r\n",
        "#\r\n",
        "#         net_h4 = DeConv2d(net_h3, c_dim, (5, 5), out_size=(s, s), strides=(2, 2),\r\n",
        "#                 padding='SAME', batch_size=batch_size, act=None, W_init=w_init, name='g_h4/decon2d')\r\n",
        "#         logits = net_h4.outputs\r\n",
        "#         net_h4.outputs = tf.nn.tanh(net_h4.outputs)\r\n",
        "#     return net_h4, logits\r\n",
        "#\r\n",
        "# def encoder(input_images, input_txt=None, is_train=True, reuse=False):\r\n",
        "#     \"\"\" E(x) input (64, 64, 3), output z \"\"\"\r\n",
        "#     s = image_size\r\n",
        "#     s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "#     # 32 16 8 4\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "#     gamma_init = tf.random_normal_initializer(1., 0.01)\r\n",
        "#     df_dim = 128\r\n",
        "#\r\n",
        "#     with tf.variable_scope(\"encoder\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         net_in = InputLayer(input_images, name='ig_inputz')\r\n",
        "#\r\n",
        "#         net_h0 = Conv2d(net_in, df_dim, (5, 5), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 padding='SAME', W_init=w_init, name='ig/h0/conv2d')\r\n",
        "#\r\n",
        "#         net_h1 = Conv2d(net_h0, df_dim*2, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig/h1/conv2d')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig/h1/batch_norm')\r\n",
        "#\r\n",
        "#         # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "#         #     net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, name='p/h1/drop')\r\n",
        "#\r\n",
        "#         net_h2 = Conv2d(net_h1, df_dim*4, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig/h2/conv2d')\r\n",
        "#         net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig/h2/batch_norm')\r\n",
        "#\r\n",
        "#         # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "#         #     net_h2 = DropoutLayer(net_h2, keep=0.8, is_fix=True, name='p/h2/drop')\r\n",
        "#\r\n",
        "#         net_h3 = Conv2d(net_h2, df_dim*8, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='ig/h3/conv2d')\r\n",
        "#         net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='ig/h3/batch_norm')\r\n",
        "#\r\n",
        "#         # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "#         #     net_h3 = DropoutLayer(net_h3, keep=0.8, is_fix=True, name='p/h3/drop')\r\n",
        "#         # print(net_h3.outputs)\r\n",
        "#         # exit()\r\n",
        "#\r\n",
        "#         if input_txt is not None:\r\n",
        "#             net_txt = InputLayer(input_txt, name='ig_input_txt')\r\n",
        "#             net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    W_init=w_init, b_init=None, name='ig_reduce_txt/dense')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim1')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='ig_txt/expanddim2')\r\n",
        "#             net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='ig_txt/tile')\r\n",
        "#             net_h3_concat = ConcatLayer([net_h3, net_txt], concat_dim=3, name='ig_txt/concat')\r\n",
        "#             net_h3 = Conv2d(net_h3_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "#                    padding='SAME', W_init=w_init, b_init=None, name='ig_txt/conv2d_2')\r\n",
        "#             net_h3 = BatchNormLayer(net_h3, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    is_train=is_train, gamma_init=gamma_init, name='ig_txt/batch_norm_2')\r\n",
        "#\r\n",
        "#         net_h4 = FlattenLayer(net_h3, name='ig/h4/flatten')\r\n",
        "#         net_h4 = DenseLayer(net_h4, n_units=z_dim, act=tf.identity,\r\n",
        "#                 W_init = w_init, b_init = None, name='ig/h4/embed')\r\n",
        "#\r\n",
        "#         ## DH add\r\n",
        "#         # print(\"WARNING: FORCE ENCODER OUTPUT GAUSSIAN DISTRIBUTION !\")\r\n",
        "#         # mean, var = tf.nn.moments(net_h4.outputs, axes=[1])\r\n",
        "#         # mean = tf.expand_dims(mean, 1)\r\n",
        "#         # var = tf.expand_dims(var, 1)\r\n",
        "#         # net_h4.outputs = (net_h4.outputs - mean) / tf.sqrt(var)\r\n",
        "#     return net_h4\r\n",
        "#\r\n",
        "# def discriminator_x(input_images, input_txt=None, is_train=True, reuse=False):\r\n",
        "#     \"\"\" D(x) input (64, 64, 3) \"\"\"\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "#     gamma_init=tf.random_normal_initializer(1., 0.01)\r\n",
        "#     df_dim = 64\r\n",
        "#\r\n",
        "#     with tf.variable_scope(\"discriminator_x\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#\r\n",
        "#         net_in = InputLayer(input_images, name='dx_input/images')\r\n",
        "#         net_h0 = Conv2d(net_in, df_dim, (5, 5), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 padding='SAME', W_init=w_init, name='dx_h0/conv2d')  # (64, 32, 32, 64)\r\n",
        "#\r\n",
        "#         net_h1 = Conv2d(net_h0, df_dim*2, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h1/conv2d')\r\n",
        "#         net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h1/batchnorm') # (64, 16, 16, 128)\r\n",
        "#\r\n",
        "#         net_h2 = Conv2d(net_h1, df_dim*4, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h2/conv2d')\r\n",
        "#         net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h2/batchnorm')    # (64, 8, 8, 256)\r\n",
        "#\r\n",
        "#         net_h3 = Conv2d(net_h2, df_dim*8, (5, 5), (2, 2), act=None,\r\n",
        "#                 padding='SAME', W_init=w_init, b_init=None, name='dx_h3/conv2d')\r\n",
        "#         net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                 is_train=is_train, gamma_init=gamma_init, name='dx_h3/batchnorm') # (64, 4, 4, 512)  paper 4.1: when the spatial dim of the D is 4x4, we replicate the description embedding spatially and perform a depth concatenation\r\n",
        "#\r\n",
        "#         if input_txt is not None:\r\n",
        "#             net_txt = InputLayer(input_txt, name='dx_input_txt')\r\n",
        "#             net_txt = DenseLayer(net_txt, n_units=t_dim, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    W_init=w_init, b_init=None, name='dx_reduce_txt/dense')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim1')\r\n",
        "#             net_txt = ExpandDimsLayer(net_txt, 1, name='dx_txt/expanddim2')\r\n",
        "#             net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\r\n",
        "#             net_h3_concat = ConcatLayer([net_h3, net_txt], concat_dim=3, name='dx_txt/concat')\r\n",
        "#             net_h3 = Conv2d(net_h3_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "#                    padding='SAME', W_init=w_init, b_init=None, name='dx_txt/conv2d_2')\r\n",
        "#             net_h3 = BatchNormLayer(net_h3, act=lrelu,#lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "#                    is_train=is_train, gamma_init=gamma_init, name='dx_txt/batch_norm_2')\r\n",
        "#\r\n",
        "#         net_h4 = FlattenLayer(net_h3, name='dx_h4/flatten')          # (64, 8192)\r\n",
        "#\r\n",
        "#         net_h4 = DenseLayer(net_h4, n_units=512, act=tf.identity,\r\n",
        "#                 W_init = w_init, name='dx_h4/dense')\r\n",
        "#         # print(net_h4.outputs)\r\n",
        "#         # exit()\r\n",
        "#         # net_h4 = DenseLayer(net_h4, n_units=1, act=tf.identity,\r\n",
        "#         #         W_init = w_init, name='d_h4/dense')\r\n",
        "#         # logits = net_h4.outputs\r\n",
        "#         # net_h4.outputs = tf.nn.sigmoid(net_h4.outputs)  # (64, 1)\r\n",
        "#     return net_h4\r\n",
        "#\r\n",
        "# def discriminator_z(input_z, is_train=True, reuse=False):\r\n",
        "#     \"\"\" D(z) input z \"\"\"\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "#     lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "#     with tf.variable_scope(\"discriminator_z\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         net_in = InputLayer(input_z, name='dz_input/z')\r\n",
        "#         # net_in = ReshapeLayer(net_in, [-1, 1, 1, z_dim], name='dz_reshape')\r\n",
        "#\r\n",
        "#         # if is_train:\r\n",
        "#         #     net_in = DropoutLayer(net_in, keep=0.8, is_fix=True, name='dz_in/drop')\r\n",
        "#         # net_h0 = Conv2d(net_in, 1024, (1, 1), (1, 1), act=lrelu,\r\n",
        "#         #         padding='VALID', W_init=w_init, name='dz_h0/conv2d')\r\n",
        "#         net_h0 = DenseLayer(net_in, n_units=512, act=lrelu, W_init=w_init, name='dz_h0/conv2d')\r\n",
        "#\r\n",
        "#         # if is_train:\r\n",
        "#         #     net_h0 = DropoutLayer(net_h0, keep=0.8, is_fix=True, name='dz_h0/drop')\r\n",
        "#         # net_h1 = Conv2d(net_h0, 1024, (1, 1), (1, 1), act=lrelu,\r\n",
        "#         #         padding='VALID', W_init=w_init, name='dz_h1/conv2d')\r\n",
        "#         net_h1 = DenseLayer(net_h0, n_units=512, act=lrelu, W_init=w_init, name='dz_h1/conv2d')\r\n",
        "#\r\n",
        "#         # net_h1 = FlattenLayer(net_h1, name='dz_flatten')\r\n",
        "#         # print(net_h1.outputs) # 512\r\n",
        "#         # exit()\r\n",
        "#         return net_h1\r\n",
        "#\r\n",
        "# def discriminator_combine_xz(x, z, is_train=True, reuse=False):\r\n",
        "#     \"\"\" input D(x), D(z), output real/fake \"\"\"\r\n",
        "#     w_init = tf.random_normal_initializer(stddev=0.01)\r\n",
        "#     lrelu = lambda x: tl.act.lrelu(x, 0.2)\r\n",
        "#\r\n",
        "#     with tf.variable_scope(\"discriminator\", reuse=reuse):\r\n",
        "#         tl.layers.set_name_reuse(reuse)\r\n",
        "#         net_in_x = InputLayer(x, name='d_input/x')\r\n",
        "#         net_in_z = InputLayer(z, name='d_input/z')\r\n",
        "#         net_in = ConcatLayer([net_in_z, net_in_x], concat_dim=1, name='d/concat')\r\n",
        "#         # print(net_in.outputs)\r\n",
        "#         # exit()\r\n",
        "#         # net_in = ExpandDimsLayer(net_in, 1 , name='d/expanddim1')\r\n",
        "#         # net_in = ExpandDimsLayer(net_in, 1 , name='d/expanddim2')\r\n",
        "#\r\n",
        "#         # if is_train:\r\n",
        "#         #     net_in = DropoutLayer(net_in, keep=0.8, is_fix=True, name='d_in/drop')\r\n",
        "#         # net_h0 = Conv2d(net_in, 2048, (1, 1), (1, 1), act=lrelu,\r\n",
        "#         #         padding='VALID', W_init=w_init, name='d_h0/conv2d')\r\n",
        "#         net_h0 = DenseLayer(net_in, n_units=1024, act=lrelu, W_init=w_init, name='d_h0/conv2d')\r\n",
        "#\r\n",
        "#         # if is_train:\r\n",
        "#         #     net_h0 = DropoutLayer(net_h0, keep=0.8, is_fix=True, name='d_h0/drop')\r\n",
        "#         # net_h1 = Conv2d(net_h0, 2048, (1, 1), (1, 1), act=lrelu,\r\n",
        "#         #         padding='VALID', W_init=w_init, name='d_h1/conv2d')\r\n",
        "#         net_h1 = DenseLayer(net_h0, n_units=1024, act=lrelu, W_init=w_init, name='d_h1/conv2d')\r\n",
        "#\r\n",
        "#         # if is_train:\r\n",
        "#         #     net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, name='d_h1/drop')\r\n",
        "#         # net_ho = Conv2d(net_h1, 1, (1, 1), (1, 1), act=None,\r\n",
        "#         #         padding='VALID', W_init=w_init, name='d_ho/conv2d')\r\n",
        "#         net_ho = DenseLayer(net_h1, n_units=1, act=tf.identity,#lrelu,\r\n",
        "#                 W_init=w_init, name='d_ho/conv2d')\r\n",
        "#         # print(net_ho.outputs) # 1\r\n",
        "#         # exit()\r\n",
        "#         # net_ho = FlattenLayer(net_ho, name='d_ho/flatten')\r\n",
        "#         # print(net_ho.outputs) # 1\r\n",
        "#         # exit()\r\n",
        "#         logits = net_ho.outputs\r\n",
        "#         net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\r\n",
        "#         return net_ho, logits\r\n",
        "#\r\n",
        "# def discriminator(x, z, is_train=True, reuse=False):\r\n",
        "#     \"\"\" D(x, z) \"\"\"\r\n",
        "#     net_z = discriminator_z(z, is_train=is_train, reuse=reuse)\r\n",
        "#     net_x = discriminator_x(x, is_train=is_train, reuse=reuse)\r\n",
        "#     net_d, logits = discriminator_combine_xz(net_x.outputs, net_z.outputs, is_train=is_train, reuse=reuse)\r\n",
        "#     net_d.all_params.extend(net_x.all_params)\r\n",
        "#     net_d.all_params.extend(net_z.all_params)\r\n",
        "#     return net_d, logits\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "## for text-to-image mapping ===================================================\r\n",
        "t_dim = 128         # text feature dimension\r\n",
        "rnn_hidden_size = t_dim\r\n",
        "vocab_size = 8000\r\n",
        "word_embedding_size = 256\r\n",
        "keep_prob = 1.0\r\n",
        "\r\n",
        "def rnn_embed(input_seqs, is_train=True, reuse=False, return_embed=False):\r\n",
        "    \"\"\" txt --> t_dim \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    if tf.__version__ <= '0.12.1':\r\n",
        "        LSTMCell = tf.nn.rnn_cell.LSTMCell\r\n",
        "    else:\r\n",
        "        LSTMCell = tf.contrib.rnn.BasicLSTMCell\r\n",
        "    with tf.variable_scope(\"rnnftxt\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        network = EmbeddingInputlayer(\r\n",
        "                     inputs = input_seqs,\r\n",
        "                     vocabulary_size = vocab_size,\r\n",
        "                     embedding_size = word_embedding_size,\r\n",
        "                     E_init = w_init,\r\n",
        "                     name = 'rnn/wordembed')\r\n",
        "        network = DynamicRNNLayer(network,\r\n",
        "                     cell_fn = LSTMCell,\r\n",
        "                     cell_init_args = {'state_is_tuple' : True, 'reuse': reuse},  # for TF1.1, TF1.2 dont need to set reuse\r\n",
        "                     n_hidden = rnn_hidden_size,\r\n",
        "                     dropout = (keep_prob if is_train else None),\r\n",
        "                     initializer = w_init,\r\n",
        "                     sequence_length = tl.layers.retrieve_seq_length_op2(input_seqs),\r\n",
        "                     return_last = True,\r\n",
        "                     name = 'rnn/dynamic')\r\n",
        "        return network\r\n",
        "\r\n",
        "def cnn_encoder(inputs, is_train=True, reuse=False, name='cnnftxt', return_h3=False):\r\n",
        "    \"\"\" 64x64 --> t_dim, for text-image mapping \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.02)\r\n",
        "    df_dim = 64\r\n",
        "\r\n",
        "    with tf.variable_scope(name, reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(True)\r\n",
        "\r\n",
        "        net_in = InputLayer(inputs, name='/in')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                padding='SAME', W_init=w_init, name='cnnf/h0/conv2d')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h1/batch_norm')\r\n",
        "\r\n",
        "        # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "        #     net_h1 = DropoutLayer(net_h1, keep=0.8, is_fix=True, name='p/h1/drop')\r\n",
        "\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h2/batch_norm')\r\n",
        "\r\n",
        "        # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "        #     net_h2 = DropoutLayer(net_h2, keep=0.8, is_fix=True, name='p/h2/drop')\r\n",
        "\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='cnnf/h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='cnnf/h3/batch_norm')\r\n",
        "\r\n",
        "        # if name != 'cnn': # debug for training image encoder in step 2\r\n",
        "        #     net_h3 = DropoutLayer(net_h3, keep=0.8, is_fix=True, name='p/h3/drop')\r\n",
        "\r\n",
        "        net_h4 = FlattenLayer(net_h3, name='cnnf/h4/flatten')\r\n",
        "        net_h4 = DenseLayer(net_h4, n_units= (z_dim if name == 'z_encoder' else t_dim),\r\n",
        "                act=tf.identity,\r\n",
        "                W_init = w_init, b_init = None, name='cnnf/h4/embed')\r\n",
        "    if return_h3:\r\n",
        "        return net_h4, net_h3\r\n",
        "    else:\r\n",
        "        return net_h4\r\n",
        "\r\n",
        "\r\n",
        "## simple g1, d1 ===============================================================\r\n",
        "def generator_txt2img_simple(input_z, input_rnn_embed=None, is_train=True, reuse=False, batch_size=64):\r\n",
        "    \"\"\" z + (txt) --> 64x64 \"\"\"\r\n",
        "    s = image_size\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    b_init = None # tf.constant_initializer(value=0.0)\r\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.02)\r\n",
        "    gf_dim = 128\r\n",
        "\r\n",
        "    with tf.variable_scope(\"generator\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_z, name='g_inputz')\r\n",
        "\r\n",
        "        if input_rnn_embed is not None:\r\n",
        "            net_txt = InputLayer(input_rnn_embed, name='g_rnn_embed_input')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "                    act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                    W_init = w_init, b_init=None, name='g_reduce_text/dense')\r\n",
        "            net_in = ConcatLayer([net_in, net_txt], concat_dim=1, name='g_concat_z_seq')\r\n",
        "        else:\r\n",
        "            print(\"No text info will be used, i.e. normal DCGAN\")\r\n",
        "\r\n",
        "        net_h0 = DenseLayer(net_in, gf_dim*8*s16*s16, act=tf.identity,\r\n",
        "                W_init=w_init, b_init=b_init, name='g_h0/dense')\r\n",
        "        net_h0 = ReshapeLayer(net_h0, [-1, s16, s16, gf_dim*8], name='g_h0/reshape')\r\n",
        "        net_h0 = BatchNormLayer(net_h0, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h0/batch_norm')\r\n",
        "\r\n",
        "        net_h1 = DeConv2d(net_h0, gf_dim*4, (4, 4), out_size=(s8, s8), strides=(2, 2), # stackGI use (4, 4) https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h1/decon2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h1/batch_norm')\r\n",
        "\r\n",
        "        net_h2 = DeConv2d(net_h1, gf_dim*2, (4, 4), out_size=(s4, s4), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h2/decon2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h2/batch_norm')\r\n",
        "\r\n",
        "        net_h3 = DeConv2d(net_h2, gf_dim, (4, 4), out_size=(s2, s2), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h3/decon2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h3/batch_norm')\r\n",
        "\r\n",
        "        net_h4 = DeConv2d(net_h3, c_dim, (4, 4), out_size=(s, s), strides=(2, 2),\r\n",
        "                padding='SAME', batch_size=batch_size, act=None, W_init=w_init, name='g_h4/decon2d')\r\n",
        "        logits = net_h4.outputs\r\n",
        "        net_h4.outputs = tf.nn.tanh(net_h4.outputs)\r\n",
        "    return net_h4, logits\r\n",
        "\r\n",
        "def discriminator_txt2img_simple(input_images, input_rnn_embed=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" 64x64 + (txt) --> real/fake \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    b_init = None # tf.constant_initializer(value=0.0)\r\n",
        "    gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "    df_dim = 64\r\n",
        "\r\n",
        "    with tf.variable_scope(\"discriminator\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "\r\n",
        "        net_in = InputLayer(input_images, name='d_input/images')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                padding='SAME', W_init=w_init, name='d_h0/conv2d')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=b_init, name='d_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h1/batchnorm')\r\n",
        "\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=b_init, name='d_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h2/batchnorm')\r\n",
        "\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=b_init, name='d_h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h3/batchnorm')\r\n",
        "\r\n",
        "        if input_rnn_embed is not None:\r\n",
        "            net_txt = InputLayer(input_rnn_embed, name='d_rnn_embed_input')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "                   act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   W_init=w_init, b_init=None, name='d_reduce_txt/dense')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim1')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim2')\r\n",
        "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\r\n",
        "            net_h3_concat = ConcatLayer([net_h3, net_txt], concat_dim=3, name='d_h3_concat')\r\n",
        "            # net_h3_concat = net_h3 # no text info\r\n",
        "            net_h3 = Conv2d(net_h3_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "                   padding='SAME', W_init=w_init, b_init=b_init, name='d_h3/conv2d_2')\r\n",
        "            net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   is_train=is_train, gamma_init=gamma_init, name='d_h3/batch_norm_2')\r\n",
        "        else:\r\n",
        "            print(\"No text info will be used, i.e. normal DCGAN\")\r\n",
        "\r\n",
        "        net_h4 = FlattenLayer(net_h3, name='d_h4/flatten')\r\n",
        "        net_h4 = DenseLayer(net_h4, n_units=1, act=tf.identity,\r\n",
        "                W_init = w_init, name='d_h4/dense')\r\n",
        "        logits = net_h4.outputs\r\n",
        "        net_h4.outputs = tf.nn.sigmoid(net_h4.outputs)\r\n",
        "    return net_h4, logits\r\n",
        "\r\n",
        "\r\n",
        "## default g1, d1 ==============================================================\r\n",
        "def generator_txt2img_resnet(input_z, t_txt=None, is_train=True, reuse=False, batch_size=batch_size):\r\n",
        "    \"\"\" z + (txt) --> 64x64 \"\"\"\r\n",
        "    # https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py\r\n",
        "    s = image_size # output image size [64]\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "    gf_dim = 128\r\n",
        "\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.02)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"generator\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_z, name='g_inputz')\r\n",
        "\r\n",
        "        if t_txt is not None:\r\n",
        "            net_txt = InputLayer(t_txt, name='g_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "                act=lambda x: tl.act.lrelu(x, 0.2), W_init=w_init, name='g_reduce_text/dense')\r\n",
        "            net_in = ConcatLayer([net_in, net_txt], concat_dim=1, name='g_concat_z_txt')\r\n",
        "\r\n",
        "        net_h0 = DenseLayer(net_in, gf_dim*8*s16*s16, act=tf.identity,\r\n",
        "                W_init=w_init, b_init=None, name='g_h0/dense')\r\n",
        "        net_h0 = BatchNormLayer(net_h0,  #act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h0/batch_norm')\r\n",
        "        net_h0 = ReshapeLayer(net_h0, [-1, s16, s16, gf_dim*8], name='g_h0/reshape')\r\n",
        "\r\n",
        "        net = Conv2d(net_h0, gf_dim*2, (1, 1), (1, 1),\r\n",
        "                padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h1_res/batch_norm')\r\n",
        "        net = Conv2d(net, gf_dim*2, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h1_res/batch_norm2')\r\n",
        "        net = Conv2d(net, gf_dim*8, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h1_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, # act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h1_res/batch_norm3')\r\n",
        "        net_h1 = ElementwiseLayer(layer=[net_h0, net], combine_fn=tf.add, name='g_h1_res/add')\r\n",
        "        net_h1.outputs = tf.nn.relu(net_h1.outputs)\r\n",
        "\r\n",
        "        # Note: you can also use DeConv2d to replace UpSampling2dLayer and Conv2d\r\n",
        "        # net_h2 = DeConv2d(net_h1, gf_dim*4, (4, 4), out_size=(s8, s8), strides=(2, 2),\r\n",
        "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h2/decon2d')\r\n",
        "        net_h2 = UpSampling2dLayer(net_h1, size=[s8, s8], is_scale=False, method=1,\r\n",
        "                align_corners=False, name='g_h2/upsample2d')\r\n",
        "        net_h2 = Conv2d(net_h2, gf_dim*4, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2,# act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h2/batch_norm')\r\n",
        "\r\n",
        "        net = Conv2d(net_h2, gf_dim, (1, 1), (1, 1),\r\n",
        "                padding='VALID', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h3_res/batch_norm')\r\n",
        "        net = Conv2d(net, gf_dim, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=tf.nn.relu, is_train=is_train,\r\n",
        "                gamma_init=gamma_init, name='g_h3_res/batch_norm2')\r\n",
        "        net = Conv2d(net, gf_dim*4, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h3_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, #act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h3_res/batch_norm3')\r\n",
        "        net_h3 = ElementwiseLayer(layer=[net_h2, net], combine_fn=tf.add, name='g_h3/add')\r\n",
        "        net_h3.outputs = tf.nn.relu(net_h3.outputs)\r\n",
        "\r\n",
        "        # net_h4 = DeConv2d(net_h3, gf_dim*2, (4, 4), out_size=(s4, s4), strides=(2, 2),\r\n",
        "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h4/decon2d'),\r\n",
        "        net_h4 = UpSampling2dLayer(net_h3, size=[s4, s4], is_scale=False, method=1,\r\n",
        "                align_corners=False, name='g_h4/upsample2d')\r\n",
        "        net_h4 = Conv2d(net_h4, gf_dim*2, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h4/conv2d')\r\n",
        "        net_h4 = BatchNormLayer(net_h4, act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h4/batch_norm')\r\n",
        "\r\n",
        "        # net_h5 = DeConv2d(net_h4, gf_dim, (4, 4), out_size=(s2, s2), strides=(2, 2),\r\n",
        "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, b_init=b_init, name='g_h5/decon2d')\r\n",
        "        net_h5 = UpSampling2dLayer(net_h4, size=[s2, s2], is_scale=False, method=1,\r\n",
        "                align_corners=False, name='g_h5/upsample2d')\r\n",
        "        net_h5 = Conv2d(net_h5, gf_dim, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, b_init=None, name='g_h5/conv2d')\r\n",
        "        net_h5 = BatchNormLayer(net_h5, act=tf.nn.relu,\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='g_h5/batch_norm')\r\n",
        "\r\n",
        "        # net_ho = DeConv2d(net_h5, c_dim, (4, 4), out_size=(s, s), strides=(2, 2),\r\n",
        "        #         padding='SAME', batch_size=batch_size, act=None, W_init=w_init, name='g_ho/decon2d')\r\n",
        "        net_ho = UpSampling2dLayer(net_h5, size=[s, s], is_scale=False, method=1,\r\n",
        "                align_corners=False, name='g_ho/upsample2d')\r\n",
        "        net_ho = Conv2d(net_ho, c_dim, (3, 3), (1, 1),\r\n",
        "                padding='SAME', act=None, W_init=w_init, name='g_ho/conv2d')\r\n",
        "        logits = net_ho.outputs\r\n",
        "        net_ho.outputs = tf.nn.tanh(net_ho.outputs)\r\n",
        "    return net_ho, logits\r\n",
        "\r\n",
        "def discriminator_txt2img_resnet(input_images, t_txt=None, is_train=True, reuse=False):\r\n",
        "    \"\"\" 64x64 + (txt) --> real/fake \"\"\"\r\n",
        "    # https://github.com/hanzhanggit/StackGAN/blob/master/stageI/model.py\r\n",
        "    # Discriminator with ResNet : line 197 https://github.com/reedscot/icml2016/blob/master/main_cls.lua\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "    df_dim = 64  # 64 for flower, 196 for MSCOCO\r\n",
        "    s = 64 # output image size [64]\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"discriminator\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "        net_in = InputLayer(input_images, name='d_input/images')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                padding='SAME', W_init=w_init, name='d_h0/conv2d')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h1/batchnorm')\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h2/batchnorm')\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h3/batchnorm')\r\n",
        "\r\n",
        "        net = Conv2d(net_h3, df_dim*2, (1, 1), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='d_h4_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm')\r\n",
        "        net = Conv2d(net, df_dim*2, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm2')\r\n",
        "        net = Conv2d(net, df_dim*8, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm3')\r\n",
        "        net_h4 = ElementwiseLayer(layer=[net_h3, net], combine_fn=tf.add, name='d_h4/add')\r\n",
        "        net_h4.outputs = tl.act.lrelu(net_h4.outputs, 0.2)\r\n",
        "\r\n",
        "        if t_txt is not None:\r\n",
        "            net_txt = InputLayer(t_txt, name='d_input_txt')\r\n",
        "            net_txt = DenseLayer(net_txt, n_units=t_dim,\r\n",
        "                   act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                   W_init=w_init, name='d_reduce_txt/dense')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim1')\r\n",
        "            net_txt = ExpandDimsLayer(net_txt, 1, name='d_txt/expanddim2')\r\n",
        "            net_txt = TileLayer(net_txt, [1, 4, 4, 1], name='d_txt/tile')\r\n",
        "            net_h4_concat = ConcatLayer([net_h4, net_txt], concat_dim=3, name='d_h3_concat')\r\n",
        "            # 243 (ndf*8 + 128 or 256) x 4 x 4\r\n",
        "            net_h4 = Conv2d(net_h4_concat, df_dim*8, (1, 1), (1, 1),\r\n",
        "                    padding='VALID', W_init=w_init, b_init=None, name='d_h3/conv2d_2')\r\n",
        "            net_h4 = BatchNormLayer(net_h4, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                    is_train=is_train, gamma_init=gamma_init, name='d_h3/batch_norm_2')\r\n",
        "\r\n",
        "        net_ho = Conv2d(net_h4, 1, (s16, s16), (s16, s16), padding='VALID', W_init=w_init, name='d_ho/conv2d')\r\n",
        "        # 1 x 1 x 1\r\n",
        "        # net_ho = FlattenLayer(net_h4, name='d_ho/flatten')\r\n",
        "        logits = net_ho.outputs\r\n",
        "        net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\r\n",
        "    return net_ho, logits\r\n",
        "\r\n",
        "def z_encoder(input_images, is_train=True, reuse=False):\r\n",
        "    \"\"\" 64x64 -> z \"\"\"\r\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "    gamma_init=tf.random_normal_initializer(1., 0.02)\r\n",
        "    df_dim = 64  # 64 for flower, 196 for MSCOCO\r\n",
        "    s = 64 # output image size [64]\r\n",
        "    s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"z_encoder\", reuse=reuse):\r\n",
        "        tl.layers.set_name_reuse(reuse)\r\n",
        "\r\n",
        "        net_in = InputLayer(input_images, name='d_input/images')\r\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                padding='SAME', W_init=w_init, name='d_h0/conv2d')\r\n",
        "\r\n",
        "        net_h1 = Conv2d(net_h0, df_dim*2, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h1/conv2d')\r\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h1/batchnorm')\r\n",
        "        net_h2 = Conv2d(net_h1, df_dim*4, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h2/conv2d')\r\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h2/batchnorm')\r\n",
        "        net_h3 = Conv2d(net_h2, df_dim*8, (4, 4), (2, 2), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h3/conv2d')\r\n",
        "        net_h3 = BatchNormLayer(net_h3, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h3/batchnorm')\r\n",
        "\r\n",
        "        net = Conv2d(net_h3, df_dim*2, (1, 1), (1, 1), act=None,\r\n",
        "                padding='VALID', W_init=w_init, b_init=None, name='d_h4_res/conv2d')\r\n",
        "        net = BatchNormLayer(net, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm')\r\n",
        "        net = Conv2d(net, df_dim*2, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d2')\r\n",
        "        net = BatchNormLayer(net, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm2')\r\n",
        "        net = Conv2d(net, df_dim*8, (3, 3), (1, 1), act=None,\r\n",
        "                padding='SAME', W_init=w_init, b_init=None, name='d_h4_res/conv2d3')\r\n",
        "        net = BatchNormLayer(net, #act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "                is_train=is_train, gamma_init=gamma_init, name='d_h4_res/batchnorm3')\r\n",
        "        net_h4 = ElementwiseLayer(layer=[net_h3, net], combine_fn=tf.add, name='d_h4/add')\r\n",
        "        net_h4.outputs = tl.act.lrelu(net_h4.outputs, 0.2)\r\n",
        "\r\n",
        "        net_ho = FlattenLayer(net_h4, name='d_ho/flatten')\r\n",
        "        net_ho = DenseLayer(net_ho, n_units=z_dim, act=tf.identity,\r\n",
        "                W_init = w_init, name='d_ho/dense')\r\n",
        "\r\n",
        "        # w_init = tf.random_normal_initializer(stddev=0.02)\r\n",
        "        # b_init = None\r\n",
        "        # gamma_init = tf.random_normal_initializer(1., 0.02)\r\n",
        "        #\r\n",
        "        # net_in = InputLayer(input_images, name='p/in')\r\n",
        "        # net_h0 = Conv2d(net_in, df_dim, (5, 5), (2, 2), act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "        #         padding='SAME', W_init=w_init, name='p/h0/conv2d')\r\n",
        "        #\r\n",
        "        # net_h1 = Conv2d(net_h0, df_dim*2, (5, 5), (2, 2), act=None,\r\n",
        "        #         padding='SAME', W_init=w_init, b_init=b_init, name='p/h1/conv2d')\r\n",
        "        # net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "        #         is_train=is_train, gamma_init=gamma_init, name='p/h1/batch_norm')\r\n",
        "        #\r\n",
        "        # net_h2 = Conv2d(net_h1, df_dim*4, (5, 5), (2, 2), act=None,\r\n",
        "        #         padding='SAME', W_init=w_init, b_init=b_init, name='p/h2/conv2d')\r\n",
        "        # net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "        #         is_train=is_train, gamma_init=gamma_init, name='p/h2/batch_norm')\r\n",
        "        #\r\n",
        "        # net_h3 = Conv2d(net_h2, df_dim*8, (5, 5), (2, 2), act=None,\r\n",
        "        #         padding='SAME', W_init=w_init, b_init=b_init, name='p/h3/conv2d')\r\n",
        "        # net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\r\n",
        "        #         is_train=is_train, gamma_init=gamma_init, name='p/h3/batch_norm')\r\n",
        "        #\r\n",
        "        # net_h4 = FlattenLayer(net_h3, name='p/h4/flatten')\r\n",
        "        # net_ho = DenseLayer(net_h4, n_units=z_dim,\r\n",
        "        #         act=tf.identity,\r\n",
        "        #         # act=tf.nn.tanh,\r\n",
        "        #         W_init = w_init, name='p/h4/output_real_fake')\r\n",
        "    return net_ho"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBw-uuBMcvhr"
      },
      "source": [
        "# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\r\n",
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import os.path\r\n",
        "import sys\r\n",
        "import tarfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from six.moves import urllib\r\n",
        "import tensorflow as tf\r\n",
        "import glob\r\n",
        "import scipy.misc\r\n",
        "import math\r\n",
        "import sys\r\n",
        "\r\n",
        "MODEL_DIR = '/tmp/imagenet'\r\n",
        "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\r\n",
        "softmax = None\r\n",
        "\r\n",
        "# Call this function with list of images. Each of elements should be a\r\n",
        "# numpy array with values ranging from 0 to 255.\r\n",
        "def get_inception_score(images, splits=10):\r\n",
        "  assert(type(images) == list)\r\n",
        "  assert(type(images[0]) == np.ndarray)\r\n",
        "  assert(len(images[0].shape) == 3)\r\n",
        "  assert(np.max(images[0]) > 10)\r\n",
        "  assert(np.min(images[0]) >= 0.0)\r\n",
        "  inps = []\r\n",
        "  for img in images:\r\n",
        "    img = img.astype(np.float32)\r\n",
        "    inps.append(np.expand_dims(img, 0))\r\n",
        "  bs = 100\r\n",
        "  with tf.Session() as sess:\r\n",
        "    preds = []\r\n",
        "    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\r\n",
        "    for i in range(n_batches):\r\n",
        "        sys.stdout.write(\".\")\r\n",
        "        sys.stdout.flush()\r\n",
        "        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\r\n",
        "        inp = np.concatenate(inp, 0)\r\n",
        "        pred = sess.run(softmax, {'ExpandDims:0': inp})\r\n",
        "        preds.append(pred)\r\n",
        "    preds = np.concatenate(preds, 0)\r\n",
        "    scores = []\r\n",
        "    for i in range(splits):\r\n",
        "      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\r\n",
        "      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\r\n",
        "      kl = np.mean(np.sum(kl, 1))\r\n",
        "      scores.append(np.exp(kl))\r\n",
        "    return np.mean(scores), np.std(scores)\r\n",
        "\r\n",
        "# This function is called automatically.\r\n",
        "def _init_inception():\r\n",
        "  global softmax\r\n",
        "  if not os.path.exists(MODEL_DIR):\r\n",
        "    os.makedirs(MODEL_DIR)\r\n",
        "  filename = DATA_URL.split('/')[-1]\r\n",
        "  filepath = os.path.join(MODEL_DIR, filename)\r\n",
        "  if not os.path.exists(filepath):\r\n",
        "    def _progress(count, block_size, total_size):\r\n",
        "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\r\n",
        "          filename, float(count * block_size) / float(total_size) * 100.0))\r\n",
        "      sys.stdout.flush()\r\n",
        "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\r\n",
        "    print()\r\n",
        "    statinfo = os.stat(filepath)\r\n",
        "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\r\n",
        "  tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\r\n",
        "  with tf.gfile.FastGFile(os.path.join(\r\n",
        "      MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\r\n",
        "    graph_def = tf.GraphDef()\r\n",
        "    graph_def.ParseFromString(f.read())\r\n",
        "    _ = tf.import_graph_def(graph_def, name='')\r\n",
        "  # Works with an arbitrary minibatch size.\r\n",
        "  with tf.Session() as sess:\r\n",
        "    pool3 = sess.graph.get_tensor_by_name('pool_3:0')\r\n",
        "    ops = pool3.graph.get_operations()\r\n",
        "    for op_idx, op in enumerate(ops):\r\n",
        "        for o in op.outputs:\r\n",
        "            shape = o.get_shape()\r\n",
        "            shape = [s.value for s in shape]\r\n",
        "            new_shape = []\r\n",
        "            for j, s in enumerate(shape):\r\n",
        "                if s == 1 and j == 0:\r\n",
        "                    new_shape.append(None)\r\n",
        "                else:\r\n",
        "                    new_shape.append(s)\r\n",
        "            o._shape = tf.TensorShape(new_shape)\r\n",
        "    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\r\n",
        "    logits = tf.matmul(tf.squeeze(pool3), w)\r\n",
        "    softmax = tf.nn.softmax(logits)\r\n",
        "\r\n",
        "if softmax is None:\r\n",
        "    _init_inception()\r\n",
        "    ###======================== PREPARE DATA ====================================###\r\n",
        "    ## Load Oxford 102 flowers dataset\r\n",
        "    # from data_loader import *\r\n",
        "    import pickle\r\n",
        "\r\n",
        "    # with open(\"_vocab.pickle\", 'rb') as f:\r\n",
        "    #     vocab = pickle.load(f)\r\n",
        "    with open(\"_image_train.pickle\", 'rb') as f:\r\n",
        "        images_train_256, images_train = pickle.load(f)\r\n",
        "    # with open(\"_image_test.pickle\", 'rb') as f:\r\n",
        "    #     images_test_256, images_test = pickle.load(f)\r\n",
        "    # with open(\"_n.pickle\", 'rb') as f:\r\n",
        "    #     n_captions_train, n_captions_test, n_captions_per_image, n_images_train, n_images_test = pickle.load(f)\r\n",
        "    # with open(\"_caption.pickle\", 'rb') as f:\r\n",
        "    #     captions_ids_train, captions_ids_test = pickle.load(f)\r\n",
        "    # images_train_256 = np.array(images_train_256)\r\n",
        "    # images_test_256 = np.array(images_test_256)\r\n",
        "    # images_train = np.array(images_train)\r\n",
        "    # images_test = np.array(images_test)\r\n",
        "    # print(np.max(images_test_256[0]))\r\n",
        "    # exit()\r\n",
        "    score_mean, score_std = get_inception_score(images_train_256)\r\n",
        "    print(\"\\nscore:\",score_mean, score_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "UW7zXBOYZJk4",
        "outputId": "29021f4b-6eb1-4b54-88b9-1f05ab4c4c8b"
      },
      "source": [
        "#amarshuru\r\n",
        "\"\"\"\r\n",
        "Deep learning and Reinforcement learning library for Researchers and Engineers\r\n",
        "\"\"\"\r\n",
        "# from __future__ import absolute_import\r\n",
        "\r\n",
        "\r\n",
        "try:\r\n",
        "    install_instr = \"Please make sure you install a recent enough version of TensorFlow.\"\r\n",
        "    import tensorflow\r\n",
        "except ImportError:\r\n",
        "    raise ImportError(\"__init__.py : Could not import TensorFlow.\" + install_instr)\r\n",
        "\r\n",
        "from . import activation\r\n",
        "act = activation\r\n",
        "from . import cost\r\n",
        "from . import files\r\n",
        "# from . import init\r\n",
        "from . import iterate\r\n",
        "from . import layers\r\n",
        "from . import ops\r\n",
        "from . import utils\r\n",
        "from . import visualize\r\n",
        "from . import prepro        # was preprocesse\r\n",
        "from . import nlp\r\n",
        "from . import rein\r\n",
        "\r\n",
        "\r\n",
        "__version__ = \"1.4.3\"\r\n",
        "\r\n",
        "global_flag = {}\r\n",
        "global_dict = {}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a1c1af0dcd0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__init__.py : Could not import TensorFlow.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minstall_instr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRyKa22dddQn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "def identity(x, name=None):\r\n",
        "    \"\"\"The identity activation function, Shortcut is ``linear``.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : a tensor input\r\n",
        "        input(s)\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    A `Tensor` with the same type as `x`.\r\n",
        "    \"\"\"\r\n",
        "    return x\r\n",
        "\r\n",
        "# Shortcut\r\n",
        "linear = identity\r\n",
        "\r\n",
        "def ramp(x=None, v_min=0, v_max=1, name=None):\r\n",
        "    \"\"\"The ramp activation function.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : a tensor input\r\n",
        "        input(s)\r\n",
        "    v_min : float\r\n",
        "        if input(s) smaller than v_min, change inputs to v_min\r\n",
        "    v_max : float\r\n",
        "        if input(s) greater than v_max, change inputs to v_max\r\n",
        "    name : a string or None\r\n",
        "        An optional name to attach to this activation function.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    A `Tensor` with the same type as `x`.\r\n",
        "    \"\"\"\r\n",
        "    return tf.clip_by_value(x, clip_value_min=v_min, clip_value_max=v_max, name=name)\r\n",
        "\r\n",
        "def leaky_relu(x=None, alpha=0.1, name=\"LeakyReLU\"):\r\n",
        "    \"\"\"The LeakyReLU, Shortcut is ``lrelu``.\r\n",
        "    Modified version of ReLU, introducing a nonzero gradient for negative\r\n",
        "    input.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\r\n",
        "        `int16`, or `int8`.\r\n",
        "    alpha : `float`. slope.\r\n",
        "    name : a string or None\r\n",
        "        An optional name to attach to this activation function.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> network = tl.layers.DenseLayer(network, n_units=100, name = 'dense_lrelu',\r\n",
        "    ...                 act= lambda x : tl.act.lrelu(x, 0.2))\r\n",
        "    References\r\n",
        "    ------------\r\n",
        "    - `Rectifier Nonlinearities Improve Neural Network Acoustic Models, Maas et al. (2013) <http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf>`_\r\n",
        "    \"\"\"\r\n",
        "    with tf.name_scope(name) as scope:\r\n",
        "        # x = tf.nn.relu(x)\r\n",
        "        # m_x = tf.nn.relu(-x)\r\n",
        "        # x -= alpha * m_x\r\n",
        "        x = tf.maximum(x, alpha * x)\r\n",
        "    return x\r\n",
        "\r\n",
        "#Shortcut\r\n",
        "lrelu = leaky_relu\r\n",
        "\r\n",
        "def pixel_wise_softmax(output, name='pixel_wise_softmax'):\r\n",
        "    \"\"\"Return the softmax outputs of images, every pixels have multiple label, the sum of a pixel is 1.\r\n",
        "    Usually be used for image segmentation.\r\n",
        "    Parameters\r\n",
        "    ------------\r\n",
        "    output : tensor\r\n",
        "        - For 2d image, 4D tensor [batch_size, height, weight, channel], channel >= 2.\r\n",
        "        - For 3d image, 5D tensor [batch_size, depth, height, weight, channel], channel >= 2.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> outputs = pixel_wise_softmax(network.outputs)\r\n",
        "    >>> dice_loss = 1 - dice_coe(outputs, y_, epsilon=1e-5)\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `tf.reverse <https://www.tensorflow.org/versions/master/api_docs/python/array_ops.html#reverse>`_\r\n",
        "    \"\"\"\r\n",
        "    with tf.name_scope(name) as scope:\r\n",
        "        return tf.nn.softmax(output)\r\n",
        "        ## old implementation\r\n",
        "        # exp_map = tf.exp(output)\r\n",
        "        # if output.get_shape().ndims == 4:   # 2d image\r\n",
        "        #     evidence = tf.add(exp_map, tf.reverse(exp_map, [False, False, False, True]))\r\n",
        "        # elif output.get_shape().ndims == 5: # 3d image\r\n",
        "        #     evidence = tf.add(exp_map, tf.reverse(exp_map, [False, False, False, False, True]))\r\n",
        "        # else:\r\n",
        "        #     raise Exception(\"output parameters should be 2d or 3d image, not %s\" % str(output._shape))\r\n",
        "        # return tf.div(exp_map, evidence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58-OlWYYdgE-"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numbers\r\n",
        "from tensorflow.python.framework import ops\r\n",
        "from tensorflow.python.ops import standard_ops\r\n",
        "\r\n",
        "## Cost Functions\r\n",
        "\r\n",
        "def cross_entropy(output, target, name=None):\r\n",
        "    \"\"\"It is a softmax cross-entropy operation, returns the TensorFlow expression of cross-entropy of two distributions, implement\r\n",
        "    softmax internally. See ``tf.nn.sparse_softmax_cross_entropy_with_logits``.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    output : Tensorflow variable\r\n",
        "        A distribution with shape: [batch_size, n_feature].\r\n",
        "    target : Tensorflow variable\r\n",
        "        A batch of index with shape: [batch_size, ].\r\n",
        "    name : string\r\n",
        "        Name of this loss.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> ce = tl.cost.cross_entropy(y_logits, y_target_logits, 'my_loss')\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - About cross-entropy: `wiki <https://en.wikipedia.org/wiki/Cross_entropy>`_.\\n\r\n",
        "    - The code is borrowed from: `here <https://en.wikipedia.org/wiki/Cross_entropy>`_.\r\n",
        "    \"\"\"\r\n",
        "    try: # old\r\n",
        "        return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, targets=target))\r\n",
        "    except: # TF 1.0\r\n",
        "        assert name is not None, \"Please give a unique name to tl.cost.cross_entropy for TF1.0+\"\r\n",
        "        return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=target, logits=output, name=name))\r\n",
        "\r\n",
        "def sigmoid_cross_entropy(output, target, name=None):\r\n",
        "    \"\"\"It is a sigmoid cross-entropy operation, see ``tf.nn.sigmoid_cross_entropy_with_logits``.\r\n",
        "    \"\"\"\r\n",
        "    try: # TF 1.0\r\n",
        "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output, name=name))\r\n",
        "    except:\r\n",
        "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, targets=target))\r\n",
        "\r\n",
        "\r\n",
        "def binary_cross_entropy(output, target, epsilon=1e-8, name='bce_loss'):\r\n",
        "    \"\"\"Computes binary cross entropy given `output`.\r\n",
        "    For brevity, let `x = output`, `z = target`.  The binary cross entropy loss is\r\n",
        "        loss(x, z) = - sum_i (x[i] * log(z[i]) + (1 - x[i]) * log(1 - z[i]))\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    output : tensor of type `float32` or `float64`.\r\n",
        "    target : tensor of the same type and shape as `output`.\r\n",
        "    epsilon : float\r\n",
        "        A small value to avoid output is zero.\r\n",
        "    name : string\r\n",
        "        An optional name to attach to this layer.\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `DRAW <https://github.com/ericjang/draw/blob/master/draw.py#L73>`_\r\n",
        "    \"\"\"\r\n",
        "#     from tensorflow.python.framework import ops\r\n",
        "#     with ops.op_scope([output, target], name, \"bce_loss\") as name:\r\n",
        "#         output = ops.convert_to_tensor(output, name=\"preds\")\r\n",
        "#         target = ops.convert_to_tensor(targets, name=\"target\")\r\n",
        "    with tf.name_scope(name):\r\n",
        "        return tf.reduce_mean(-(target * tf.log(output + epsilon) +\r\n",
        "                              (1. - target) * tf.log(1. - output + epsilon)))\r\n",
        "\r\n",
        "\r\n",
        "def mean_squared_error(output, target, is_mean=False):\r\n",
        "    \"\"\"Return the TensorFlow expression of mean-squre-error of two distributions.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    output : 2D or 4D tensor.\r\n",
        "    target : 2D or 4D tensor.\r\n",
        "    is_mean : boolean, if True, use ``tf.reduce_mean`` to compute the loss of one data, otherwise, use ``tf.reduce_sum`` (default).\r\n",
        "    References\r\n",
        "    ------------\r\n",
        "    - `Wiki Mean Squared Error <https://en.wikipedia.org/wiki/Mean_squared_error>`_\r\n",
        "    \"\"\"\r\n",
        "    with tf.name_scope(\"mean_squared_error_loss\"):\r\n",
        "        if output.get_shape().ndims == 2:   # [batch_size, n_feature]\r\n",
        "            if is_mean:\r\n",
        "                mse = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(output, target), 1))\r\n",
        "            else:\r\n",
        "                mse = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(output, target), 1))\r\n",
        "        elif output.get_shape().ndims == 4: # [batch_size, w, h, c]\r\n",
        "            if is_mean:\r\n",
        "                mse = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(output, target), [1, 2, 3]))\r\n",
        "            else:\r\n",
        "                mse = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(output, target), [1, 2, 3]))\r\n",
        "        return mse\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def dice_coe(output, target, epsilon=1e-10):\r\n",
        "    \"\"\"Sørensen–Dice coefficient for comparing the similarity of two distributions,\r\n",
        "    usually be used for binary image segmentation i.e. labels are binary.\r\n",
        "    The coefficient = [0, 1], 1 if totally match.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    output : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    target : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    epsilon : float\r\n",
        "        An optional name to attach to this layer.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\r\n",
        "    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_, epsilon=1e-5)\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `wiki-dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`_\r\n",
        "    \"\"\"\r\n",
        "    # inse = tf.reduce_sum( tf.mul(output, target) )\r\n",
        "    # l = tf.reduce_sum( tf.mul(output, output) )\r\n",
        "    # r = tf.reduce_sum( tf.mul(target, target) )\r\n",
        "    inse = tf.reduce_sum( output * target )\r\n",
        "    l = tf.reduce_sum( output * output )\r\n",
        "    r = tf.reduce_sum( target * target )\r\n",
        "    dice = 2 * (inse) / (l + r)\r\n",
        "    if epsilon == 0:\r\n",
        "        return dice\r\n",
        "    else:\r\n",
        "        return tf.clip_by_value(dice, 0, 1.0-epsilon)\r\n",
        "\r\n",
        "\r\n",
        "def dice_hard_coe(output, target, epsilon=1e-10):\r\n",
        "    \"\"\"Non-differentiable Sørensen–Dice coefficient for comparing the similarity of two distributions,\r\n",
        "    usually be used for binary image segmentation i.e. labels are binary.\r\n",
        "    The coefficient = [0, 1], 1 if totally match.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    output : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    target : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    epsilon : float\r\n",
        "        An optional name to attach to this layer.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> outputs = pixel_wise_softmax(network.outputs)\r\n",
        "    >>> dice_loss = 1 - dice_coe(outputs, y_, epsilon=1e-5)\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `wiki-dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`_\r\n",
        "    \"\"\"\r\n",
        "    output = tf.cast(output > 0.5, dtype=tf.float32)\r\n",
        "    target = tf.cast(target > 0.5, dtype=tf.float32)\r\n",
        "    inse = tf.reduce_sum( output * target )\r\n",
        "    l = tf.reduce_sum( output * output )\r\n",
        "    r = tf.reduce_sum( target * target )\r\n",
        "    dice = 2 * (inse) / (l + r)\r\n",
        "    if epsilon == 0:\r\n",
        "        return dice\r\n",
        "    else:\r\n",
        "        return tf.clip_by_value(dice, 0, 1.0-epsilon)\r\n",
        "\r\n",
        "def iou_coe(output, target, threshold=0.5, epsilon=1e-10):\r\n",
        "    \"\"\"Non-differentiable Intersection over Union, usually be used for evaluating binary image segmentation.\r\n",
        "    The coefficient = [0, 1], 1 means totally match.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    output : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    target : tensor\r\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\r\n",
        "    threshold : float\r\n",
        "        The threshold value to be true.\r\n",
        "    epsilon : float\r\n",
        "        A small value to avoid zero denominator when both output and target output nothing.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\r\n",
        "    >>> iou = tl.cost.iou_coe(outputs[:,:,:,0], y_[:,:,:,0])\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    - IOU cannot be used as training loss, people usually use dice coefficient for training, and IOU for evaluating.\r\n",
        "    \"\"\"\r\n",
        "    pre = tf.cast(output > threshold, dtype=tf.float32)\r\n",
        "    truth = tf.cast(target > threshold, dtype=tf.float32)\r\n",
        "    intersection = tf.reduce_sum(pre * truth)\r\n",
        "    union = tf.reduce_sum(tf.cast((pre + truth) > threshold, dtype=tf.float32))\r\n",
        "    return tf.reduce_sum(intersection) / (tf.reduce_sum(union) + epsilon)\r\n",
        "\r\n",
        "\r\n",
        "def cross_entropy_seq(logits, target_seqs, batch_size=None):#, batch_size=1, num_steps=None):\r\n",
        "    \"\"\"Returns the expression of cross-entropy of two sequences, implement\r\n",
        "    softmax internally. Normally be used for Fixed Length RNN outputs.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    logits : Tensorflow variable\r\n",
        "        2D tensor, ``network.outputs``, [batch_size*n_steps (n_examples), number of output units]\r\n",
        "    target_seqs : Tensorflow variable\r\n",
        "        target : 2D tensor [batch_size, n_steps], if the number of step is dynamic, please use ``cross_entropy_seq_with_mask`` instead.\r\n",
        "    batch_size : None or int.\r\n",
        "        If not None, the return cost will be divided by batch_size.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see PTB tutorial for more details\r\n",
        "    >>> input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\r\n",
        "    >>> targets = tf.placeholder(tf.int32, [batch_size, num_steps])\r\n",
        "    >>> cost = tf.cost.cross_entropy_seq(network.outputs, targets)\r\n",
        "    \"\"\"\r\n",
        "    try: # TF 1.0\r\n",
        "        sequence_loss_by_example_fn = tf.contrib.legacy_seq2seq.sequence_loss_by_example\r\n",
        "    except:\r\n",
        "        sequence_loss_by_example_fn = tf.nn.seq2seq.sequence_loss_by_example\r\n",
        "\r\n",
        "    loss = sequence_loss_by_example_fn(\r\n",
        "        [logits],\r\n",
        "        [tf.reshape(target_seqs, [-1])],\r\n",
        "        [tf.ones_like(tf.reshape(target_seqs, [-1]), dtype=tf.float32)])\r\n",
        "        # [tf.ones([batch_size * num_steps])])\r\n",
        "    cost = tf.reduce_sum(loss) #/ batch_size\r\n",
        "    if batch_size is not None:\r\n",
        "        cost = cost / batch_size\r\n",
        "    return cost\r\n",
        "\r\n",
        "\r\n",
        "def cross_entropy_seq_with_mask(logits, target_seqs, input_mask, return_details=False, name=None):\r\n",
        "    \"\"\"Returns the expression of cross-entropy of two sequences, implement\r\n",
        "    softmax internally. Normally be used for Dynamic RNN outputs.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    logits : network identity outputs\r\n",
        "        2D tensor, ``network.outputs``, [batch_size, number of output units].\r\n",
        "    target_seqs : int of tensor, like word ID.\r\n",
        "        [batch_size, ?]\r\n",
        "    input_mask : the mask to compute loss\r\n",
        "        The same size with target_seqs, normally 0 and 1.\r\n",
        "    return_details : boolean\r\n",
        "        - If False (default), only returns the loss.\r\n",
        "        - If True, returns the loss, losses, weights and targets (reshape to one vetcor).\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - see Image Captioning Example.\r\n",
        "    \"\"\"\r\n",
        "    targets = tf.reshape(target_seqs, [-1])   # to one vector\r\n",
        "    weights = tf.to_float(tf.reshape(input_mask, [-1]))   # to one vector like targets\r\n",
        "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets, name=name) * weights\r\n",
        "    #losses = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets, name=name)) # for TF1.0 and others\r\n",
        "\r\n",
        "    try: ## TF1.0\r\n",
        "        loss = tf.divide(tf.reduce_sum(losses),   # loss from mask. reduce_sum before element-wise mul with mask !!\r\n",
        "                        tf.reduce_sum(weights),\r\n",
        "                        name=\"seq_loss_with_mask\")\r\n",
        "    except: ## TF0.12\r\n",
        "        loss = tf.div(tf.reduce_sum(losses),   # loss from mask. reduce_sum before element-wise mul with mask !!\r\n",
        "                        tf.reduce_sum(weights),\r\n",
        "                        name=\"seq_loss_with_mask\")\r\n",
        "    if return_details:\r\n",
        "        return loss, losses, weights, targets\r\n",
        "    else:\r\n",
        "        return loss\r\n",
        "\r\n",
        "\r\n",
        "def cosine_similarity(v1, v2):\r\n",
        "    \"\"\"Cosine similarity [-1, 1], `wiki <https://en.wikipedia.org/wiki/Cosine_similarity>`_.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    v1, v2 : tensor of [batch_size, n_feature], with the same number of features.\r\n",
        "    Returns\r\n",
        "    -----------\r\n",
        "    a tensor of [batch_size, ]\r\n",
        "    \"\"\"\r\n",
        "    try: ## TF1.0\r\n",
        "        cost = tf.reduce_sum(tf.multiply(v1, v2), 1) / (tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), 1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1)))\r\n",
        "    except: ## TF0.12\r\n",
        "        cost = tf.reduce_sum(tf.mul(v1, v2), reduction_indices=1) / (tf.sqrt(tf.reduce_sum(tf.mul(v1, v1), reduction_indices=1)) * tf.sqrt(tf.reduce_sum(tf.mul(v2, v2), reduction_indices=1)))\r\n",
        "    return cost\r\n",
        "\r\n",
        "\r\n",
        "## Regularization Functions\r\n",
        "def li_regularizer(scale, scope=None):\r\n",
        "  \"\"\"li regularization removes the neurons of previous layer, `i` represents `inputs`.\\n\r\n",
        "  Returns a function that can be used to apply group li regularization to weights.\\n\r\n",
        "  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\r\n",
        "  Parameters\r\n",
        "  ----------\r\n",
        "  scale : float\r\n",
        "    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\r\n",
        "  scope: An optional scope name for TF12+.\r\n",
        "  Returns\r\n",
        "  --------\r\n",
        "  A function with signature `li(weights, name=None)` that apply Li regularization.\r\n",
        "  Raises\r\n",
        "  ------\r\n",
        "  ValueError : if scale is outside of the range [0.0, 1.0] or if scale is not a float.\r\n",
        "  \"\"\"\r\n",
        "  import numbers\r\n",
        "  from tensorflow.python.framework import ops\r\n",
        "  from tensorflow.python.ops import standard_ops\r\n",
        "  # from tensorflow.python.platform import tf_logging as logging\r\n",
        "\r\n",
        "  if isinstance(scale, numbers.Integral):\r\n",
        "    raise ValueError('scale cannot be an integer: %s' % scale)\r\n",
        "  if isinstance(scale, numbers.Real):\r\n",
        "    if scale < 0.:\r\n",
        "      raise ValueError('Setting a scale less than 0 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    if scale >= 1.:\r\n",
        "      raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    if scale == 0.:\r\n",
        "      logging.info('Scale of 0 disables regularizer.')\r\n",
        "      return lambda _, name=None: None\r\n",
        "\r\n",
        "  def li(weights, name=None):\r\n",
        "    \"\"\"Applies li regularization to weights.\"\"\"\r\n",
        "    with tf.name_scope('li_regularizer') as scope:\r\n",
        "        my_scale = ops.convert_to_tensor(scale,\r\n",
        "                                           dtype=weights.dtype.base_dtype,\r\n",
        "                                           name='scale')\r\n",
        "        if tf.__version__ <= '0.12':\r\n",
        "            standard_ops_fn = standard_ops.mul\r\n",
        "        else:\r\n",
        "            standard_ops_fn = standard_ops.multiply\r\n",
        "            return standard_ops_fn(\r\n",
        "              my_scale,\r\n",
        "              standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 1))),\r\n",
        "              name=scope)\r\n",
        "  return li\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def lo_regularizer(scale, scope=None):\r\n",
        "  \"\"\"lo regularization removes the neurons of current layer, `o` represents `outputs`\\n\r\n",
        "  Returns a function that can be used to apply group lo regularization to weights.\\n\r\n",
        "  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\r\n",
        "  Parameters\r\n",
        "  ----------\r\n",
        "  scale : float\r\n",
        "    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\r\n",
        "  scope: An optional scope name for TF12+.\r\n",
        "  Returns\r\n",
        "  -------\r\n",
        "  A function with signature `lo(weights, name=None)` that apply Lo regularization.\r\n",
        "  Raises\r\n",
        "  ------\r\n",
        "  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\r\n",
        "  \"\"\"\r\n",
        "  import numbers\r\n",
        "  from tensorflow.python.framework import ops\r\n",
        "  from tensorflow.python.ops import standard_ops\r\n",
        "  # from tensorflow.python.platform import tf_logging as logging\r\n",
        "\r\n",
        "  if isinstance(scale, numbers.Integral):\r\n",
        "    raise ValueError('scale cannot be an integer: %s' % scale)\r\n",
        "  if isinstance(scale, numbers.Real):\r\n",
        "    if scale < 0.:\r\n",
        "      raise ValueError('Setting a scale less than 0 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    if scale >= 1.:\r\n",
        "      raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    if scale == 0.:\r\n",
        "      logging.info('Scale of 0 disables regularizer.')\r\n",
        "      return lambda _, name=None: None\r\n",
        "\r\n",
        "  def lo(weights, name='lo_regularizer'):\r\n",
        "    \"\"\"Applies group column regularization to weights.\"\"\"\r\n",
        "    with tf.name_scope(name) as scope:\r\n",
        "        my_scale = ops.convert_to_tensor(scale,\r\n",
        "                                       dtype=weights.dtype.base_dtype,\r\n",
        "                                       name='scale')\r\n",
        "        if tf.__version__ <= '0.12':\r\n",
        "            standard_ops_fn = standard_ops.mul\r\n",
        "        else:\r\n",
        "            standard_ops_fn = standard_ops.multiply\r\n",
        "        return standard_ops_fn(\r\n",
        "          my_scale,\r\n",
        "          standard_ops.reduce_sum(standard_ops.sqrt(standard_ops.reduce_sum(tf.square(weights), 0))),\r\n",
        "          name=scope)\r\n",
        "  return lo\r\n",
        "\r\n",
        "def maxnorm_regularizer(scale=1.0, scope=None):\r\n",
        "  \"\"\"Max-norm regularization returns a function that can be used\r\n",
        "  to apply max-norm regularization to weights.\r\n",
        "  About max-norm: `wiki <https://en.wikipedia.org/wiki/Matrix_norm#Max_norm>`_.\\n\r\n",
        "  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\r\n",
        "  Parameters\r\n",
        "  ----------\r\n",
        "  scale : float\r\n",
        "    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\r\n",
        "  scope: An optional scope name.\r\n",
        "  Returns\r\n",
        "  ---------\r\n",
        "  A function with signature `mn(weights, name=None)` that apply Lo regularization.\r\n",
        "  Raises\r\n",
        "  --------\r\n",
        "  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\r\n",
        "  \"\"\"\r\n",
        "  import numbers\r\n",
        "  from tensorflow.python.framework import ops\r\n",
        "  from tensorflow.python.ops import standard_ops\r\n",
        "\r\n",
        "  if isinstance(scale, numbers.Integral):\r\n",
        "    raise ValueError('scale cannot be an integer: %s' % scale)\r\n",
        "  if isinstance(scale, numbers.Real):\r\n",
        "    if scale < 0.:\r\n",
        "      raise ValueError('Setting a scale less than 0 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    # if scale >= 1.:\r\n",
        "    #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %\r\n",
        "    #                    scale)\r\n",
        "    if scale == 0.:\r\n",
        "      logging.info('Scale of 0 disables regularizer.')\r\n",
        "      return lambda _, name=None: None\r\n",
        "\r\n",
        "  def mn(weights, name='max_regularizer'):\r\n",
        "    \"\"\"Applies max-norm regularization to weights.\"\"\"\r\n",
        "    with tf.name_scope(name) as scope:\r\n",
        "          my_scale = ops.convert_to_tensor(scale,\r\n",
        "                                           dtype=weights.dtype.base_dtype,\r\n",
        "                                           name='scale')\r\n",
        "          if tf.__version__ <= '0.12':\r\n",
        "              standard_ops_fn = standard_ops.mul\r\n",
        "          else:\r\n",
        "              standard_ops_fn = standard_ops.multiply\r\n",
        "          return standard_ops_fn(my_scale, standard_ops.reduce_max(standard_ops.abs(weights)), name=scope)\r\n",
        "  return mn\r\n",
        "\r\n",
        "def maxnorm_o_regularizer(scale, scope):\r\n",
        "  \"\"\"Max-norm output regularization removes the neurons of current layer.\\n\r\n",
        "  Returns a function that can be used to apply max-norm regularization to each column of weight matrix.\\n\r\n",
        "  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\r\n",
        "  Parameters\r\n",
        "  ----------\r\n",
        "  scale : float\r\n",
        "    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\r\n",
        "  scope: An optional scope name.\r\n",
        "  Returns\r\n",
        "  ---------\r\n",
        "  A function with signature `mn_o(weights, name=None)` that apply Lo regularization.\r\n",
        "  Raises\r\n",
        "  ---------\r\n",
        "  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\r\n",
        "  \"\"\"\r\n",
        "  import numbers\r\n",
        "  from tensorflow.python.framework import ops\r\n",
        "  from tensorflow.python.ops import standard_ops\r\n",
        "\r\n",
        "  if isinstance(scale, numbers.Integral):\r\n",
        "    raise ValueError('scale cannot be an integer: %s' % scale)\r\n",
        "  if isinstance(scale, numbers.Real):\r\n",
        "    if scale < 0.:\r\n",
        "      raise ValueError('Setting a scale less than 0 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    # if scale >= 1.:\r\n",
        "    #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %\r\n",
        "    #                    scale)\r\n",
        "    if scale == 0.:\r\n",
        "      logging.info('Scale of 0 disables regularizer.')\r\n",
        "      return lambda _, name=None: None\r\n",
        "\r\n",
        "  def mn_o(weights, name='maxnorm_o_regularizer'):\r\n",
        "     \"\"\"Applies max-norm regularization to weights.\"\"\"\r\n",
        "     with tf.name_scope(name) as scope:\r\n",
        "          my_scale = ops.convert_to_tensor(scale,\r\n",
        "                                           dtype=weights.dtype.base_dtype,\r\n",
        "                                                   name='scale')\r\n",
        "          if tf.__version__ <= '0.12':\r\n",
        "             standard_ops_fn = standard_ops.mul\r\n",
        "          else:\r\n",
        "             standard_ops_fn = standard_ops.multiply\r\n",
        "          return standard_ops_fn(my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 0)), name=scope)\r\n",
        "  return mn_o\r\n",
        "\r\n",
        "def maxnorm_i_regularizer(scale, scope=None):\r\n",
        "  \"\"\"Max-norm input regularization removes the neurons of previous layer.\\n\r\n",
        "  Returns a function that can be used to apply max-norm regularization to each row of weight matrix.\\n\r\n",
        "  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\r\n",
        "  Parameters\r\n",
        "  ----------\r\n",
        "  scale : float\r\n",
        "    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\r\n",
        "  scope: An optional scope name.\r\n",
        "  Returns\r\n",
        "  ---------\r\n",
        "  A function with signature `mn_i(weights, name=None)` that apply Lo regularization.\r\n",
        "  Raises\r\n",
        "  ---------\r\n",
        "  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\r\n",
        "  \"\"\"\r\n",
        "  import numbers\r\n",
        "  from tensorflow.python.framework import ops\r\n",
        "  from tensorflow.python.ops import standard_ops\r\n",
        "\r\n",
        "  if isinstance(scale, numbers.Integral):\r\n",
        "    raise ValueError('scale cannot be an integer: %s' % scale)\r\n",
        "  if isinstance(scale, numbers.Real):\r\n",
        "    if scale < 0.:\r\n",
        "      raise ValueError('Setting a scale less than 0 on a regularizer: %g' %\r\n",
        "                       scale)\r\n",
        "    # if scale >= 1.:\r\n",
        "    #   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %\r\n",
        "    #                    scale)\r\n",
        "    if scale == 0.:\r\n",
        "      logging.info('Scale of 0 disables regularizer.')\r\n",
        "      return lambda _, name=None: None\r\n",
        "\r\n",
        "  def mn_i(weights, name='maxnorm_i_regularizer'):\r\n",
        "     \"\"\"Applies max-norm regularization to weights.\"\"\"\r\n",
        "     with tf.name_scope(name) as scope:\r\n",
        "          my_scale = ops.convert_to_tensor(scale,\r\n",
        "                                           dtype=weights.dtype.base_dtype,\r\n",
        "                                                   name='scale')\r\n",
        "          if tf.__version__ <= '0.12':\r\n",
        "             standard_ops_fn = standard_ops.mul\r\n",
        "          else:\r\n",
        "             standard_ops_fn = standard_ops.multiply\r\n",
        "          return standard_ops_fn(my_scale, standard_ops.reduce_sum(standard_ops.reduce_max(standard_ops.abs(weights), 1)), name=scope)\r\n",
        "  return mn_i\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "npzC0sFKdmyo",
        "outputId": "5db05151-0438-4a6d-bacd-e4c288e38b9f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorlayer as tl\r\n",
        "from . import iterate\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import math\r\n",
        "\r\n",
        "\r\n",
        "import pymongo\r\n",
        "import gridfs\r\n",
        "import pickle\r\n",
        "from pymongo import MongoClient\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "class TensorDB(object):\r\n",
        "    \"\"\"TensorDB is a MongoDB based manager that help you to manage data, model and logging.\r\n",
        "    Parameters\r\n",
        "    -------------\r\n",
        "    ip : string, localhost or IP address.\r\n",
        "    port : int, port number.\r\n",
        "    db_name : string, database name.\r\n",
        "    user_name : string, set to None if it donnot need authentication.\r\n",
        "    password : string.\r\n",
        "    Properties\r\n",
        "    ------------\r\n",
        "    db : ``pymongo.MongoClient[db_name]``, xxxxxx\r\n",
        "    datafs : ``gridfs.GridFS(self.db, collection=\"datafs\")``, xxxxxxxxxx\r\n",
        "    modelfs : ``gridfs.GridFS(self.db, collection=\"modelfs\")``,\r\n",
        "    paramsfs : ``gridfs.GridFS(self.db, collection=\"paramsfs\")``,\r\n",
        "    db.Params : Collection for\r\n",
        "    db.TrainLog : Collection for\r\n",
        "    db.ValidLog : Collection for\r\n",
        "    db.TestLog : Collection for\r\n",
        "    Dependencies\r\n",
        "    -------------\r\n",
        "    1 : MongoDB, as TensorDB is based on MongoDB, you need to install it in your\r\n",
        "       local machine or remote machine.\r\n",
        "    2 : pip install pymongo, for MongoDB python API.\r\n",
        "    Optional Tools\r\n",
        "    ----------------\r\n",
        "    1 : You may like to install MongoChef or Mongo Management Studo APP for\r\n",
        "       visualizing or testing your MongoDB.\r\n",
        "    \"\"\"\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        ip = 'localhost',\r\n",
        "        port = 27017,\r\n",
        "        db_name = 'db_name',\r\n",
        "        user_name = None,\r\n",
        "        password = 'password',\r\n",
        "    ):\r\n",
        "        ## connect mongodb\r\n",
        "        client = MongoClient(ip, port)\r\n",
        "        self.db = client[db_name]\r\n",
        "        if user_name != None:\r\n",
        "            self.db.authenticate(user_name, password)\r\n",
        "        ## define file system (Buckets)\r\n",
        "        self.datafs = gridfs.GridFS(self.db, collection=\"datafs\")\r\n",
        "        self.modelfs = gridfs.GridFS(self.db, collection=\"modelfs\")\r\n",
        "        self.paramsfs = gridfs.GridFS(self.db, collection=\"paramsfs\")\r\n",
        "        ##\r\n",
        "        print(\"[TensorDB] Connect SUCCESS {}:{} {} {}\".format(ip, port, db_name, user_name))\r\n",
        "\r\n",
        "        self.ip = ip\r\n",
        "        self.port = port\r\n",
        "        self.db_name = db_name\r\n",
        "        self.user_name = user_name\r\n",
        "\r\n",
        "    # def save_bulk_data(self, data=None, filename='filename'):\r\n",
        "    #     \"\"\" Put bulk data into TensorDB.datafs, return file ID.\r\n",
        "    #     When you have a very large data, you may like to save it into GridFS Buckets\r\n",
        "    #     instead of Collections, then when you want to load it, XXXX\r\n",
        "    #\r\n",
        "    #     Parameters\r\n",
        "    #     -----------\r\n",
        "    #     data : serialized data.\r\n",
        "    #     filename : string, GridFS Buckets.\r\n",
        "    #\r\n",
        "    #     References\r\n",
        "    #     -----------\r\n",
        "    #     - MongoDB find, xxxxx\r\n",
        "    #     \"\"\"\r\n",
        "    #     s = time.time()\r\n",
        "    #     f_id = self.datafs.put(data, filename=filename)\r\n",
        "    #     print(\"[TensorDB] save_bulk_data: {} took: {}s\".format(filename, round(time.time()-s, 2)))\r\n",
        "    #     return f_id\r\n",
        "    #\r\n",
        "    # def save_collection(self, data=None, collect_name='collect_name'):\r\n",
        "    #     \"\"\" Insert data into MongoDB Collections, return xx.\r\n",
        "    #\r\n",
        "    #     Parameters\r\n",
        "    #     -----------\r\n",
        "    #     data : serialized data.\r\n",
        "    #     collect_name : string, MongoDB collection name.\r\n",
        "    #\r\n",
        "    #     References\r\n",
        "    #     -----------\r\n",
        "    #     - MongoDB find, xxxxx\r\n",
        "    #     \"\"\"\r\n",
        "    #     s = time.time()\r\n",
        "    #     rl = self.db[collect_name].insert_many(data)\r\n",
        "    #     print(\"[TensorDB] save_collection: {} took: {}s\".format(collect_name, round(time.time()-s, 2)))\r\n",
        "    #     return rl\r\n",
        "    #\r\n",
        "    # def find(self, args={}, collect_name='collect_name'):\r\n",
        "    #     \"\"\" Find data from MongoDB Collections.\r\n",
        "    #\r\n",
        "    #     Parameters\r\n",
        "    #     -----------\r\n",
        "    #     args : dictionary, arguments for finding.\r\n",
        "    #     collect_name : string, MongoDB collection name.\r\n",
        "    #\r\n",
        "    #     References\r\n",
        "    #     -----------\r\n",
        "    #     - MongoDB find, xxxxx\r\n",
        "    #     \"\"\"\r\n",
        "    #     s = time.time()\r\n",
        "    #\r\n",
        "    #     pc = self.db[collect_name].find(args)  # pymongo.cursor.Cursor object\r\n",
        "    #     flist = pc.distinct('f_id')\r\n",
        "    #     fldict = {}\r\n",
        "    #     for f in flist: # you may have multiple Buckets files\r\n",
        "    #         # fldict[f] = pickle.loads(self.datafs.get(f).read())\r\n",
        "    #         # s2 = time.time()\r\n",
        "    #         tmp = self.datafs.get(f).read()\r\n",
        "    #         # print(time.time()-s2)\r\n",
        "    #         fldict[f] = pickle.loads(tmp)\r\n",
        "    #         # print(time.time()-s2)\r\n",
        "    #         # exit()\r\n",
        "    #     # print(round(time.time()-s, 2))\r\n",
        "    #     data = [fldict[x['f_id']][x['id']] for x in pc]\r\n",
        "    #     data = np.asarray(data)\r\n",
        "    #     print(\"[TensorDB] find: {} get: {} took: {}s\".format(collect_name, pc.count(), round(time.time()-s, 2)))\r\n",
        "    #     return data\r\n",
        "\r\n",
        "    # def del_data(self, data, args={}):\r\n",
        "    #     pass\r\n",
        "    #\r\n",
        "    # def save_model(self):\r\n",
        "    #     pass\r\n",
        "    #\r\n",
        "    # def load_model(self):\r\n",
        "    #     pass\r\n",
        "    #\r\n",
        "    # def del_model(self):\r\n",
        "    #     pass\r\n",
        "\r\n",
        "    def save_params(self, params=[], args={}):#, file_name='parameters'):\r\n",
        "        \"\"\" Save parameters into MongoDB Buckets, and save the file ID into Params Collections.\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        params : a list of parameters\r\n",
        "        args : dictionary, item meta data.\r\n",
        "        Returns\r\n",
        "        ---------\r\n",
        "        f_id : the Buckets ID of the parameters.\r\n",
        "        \"\"\"\r\n",
        "        s = time.time()\r\n",
        "        f_id = self.paramsfs.put(pickle.dumps(params, protocol=2))#, file_name=file_name)\r\n",
        "        args.update({'f_id': f_id, 'time': datetime.utcnow()})\r\n",
        "        self.db.Params.insert_one(args)\r\n",
        "        # print(\"[TensorDB] Save params: {} SUCCESS, took: {}s\".format(file_name, round(time.time()-s, 2)))\r\n",
        "        print(\"[TensorDB] Save params: SUCCESS, took: {}s\".format(round(time.time()-s, 2)))\r\n",
        "        return f_id\r\n",
        "\r\n",
        "    def find_one_params(self, args={}):\r\n",
        "        \"\"\" Find one parameter from MongoDB Buckets.\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        args : dictionary, find items.\r\n",
        "        Returns\r\n",
        "        --------\r\n",
        "        params : the parameters, return False if nothing found.\r\n",
        "        f_id : the Buckets ID of the parameters, return False if nothing found.\r\n",
        "        \"\"\"\r\n",
        "        s = time.time()\r\n",
        "        d = self.db.Params.find_one(args)\r\n",
        "\r\n",
        "        if d is not None:\r\n",
        "            f_id = d['f_id']\r\n",
        "        else:\r\n",
        "            print(\"[TensorDB] FAIL! Cannot find: {}\".format(args))\r\n",
        "            return False, False\r\n",
        "        try:\r\n",
        "            params = pickle.loads(self.paramsfs.get(f_id).read())\r\n",
        "            print(\"[TensorDB] Find one params SUCCESS, {} took: {}s\".format(args, round(time.time()-s, 2)))\r\n",
        "            return params, f_id\r\n",
        "        except:\r\n",
        "            return False, False\r\n",
        "\r\n",
        "    def find_all_params(self, args={}):\r\n",
        "        \"\"\" Find all parameter from MongoDB Buckets\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        args : dictionary, find items\r\n",
        "        Returns\r\n",
        "        --------\r\n",
        "        params : the parameters, return False if nothing found.\r\n",
        "        \"\"\"\r\n",
        "        s = time.time()\r\n",
        "        pc = self.db.Params.find(args)\r\n",
        "\r\n",
        "        if pc is not None:\r\n",
        "            f_id_list = pc.distinct('f_id')\r\n",
        "            params = []\r\n",
        "            for f_id in f_id_list: # you may have multiple Buckets files\r\n",
        "                tmp = self.paramsfs.get(f_id).read()\r\n",
        "                params.append(pickle.loads(tmp))\r\n",
        "        else:\r\n",
        "            print(\"[TensorDB] FAIL! Cannot find any: {}\".format(args))\r\n",
        "            return False\r\n",
        "\r\n",
        "        print(\"[TensorDB] Find all params SUCCESS, took: {}s\".format(round(time.time()-s, 2)))\r\n",
        "        return params\r\n",
        "\r\n",
        "    def del_params(self, args={}):\r\n",
        "        \"\"\" Delete params in MongoDB uckets.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, find items to delete, leave it empty to delete all parameters.\r\n",
        "        \"\"\"\r\n",
        "        pc = self.db.Params.find(args)\r\n",
        "        f_id_list = pc.distinct('f_id')\r\n",
        "        # remove from Buckets\r\n",
        "        for f in f_id_list:\r\n",
        "            self.paramsfs.delete(f)\r\n",
        "        # remove from Collections\r\n",
        "        self.db.Params.remove(args)\r\n",
        "\r\n",
        "        print(\"[TensorDB] Delete params SUCCESS: {}\".format(args))\r\n",
        "\r\n",
        "    def _print_dict(self, args):\r\n",
        "        # return \" / \".join(str(key) + \": \"+ str(value) for key, value in args.items())\r\n",
        "        string = ''\r\n",
        "        for key, value in args.items():\r\n",
        "            if key is not '_id':\r\n",
        "                string += str(key) + \": \"+ str(value) + \" / \"\r\n",
        "        return string\r\n",
        "\r\n",
        "    def save_job(self, script=None, args={}):\r\n",
        "        \"\"\"Save the job.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        script : a script file name or None.\r\n",
        "        args : dictionary, items to save.\r\n",
        "        Examples\r\n",
        "        ---------\r\n",
        "        >>> # Save your job\r\n",
        "        >>> db.save_job('your_script.py', {'job_id': 1, 'learning_rate': 0.01, 'n_units': 100})\r\n",
        "        >>> # Run your job\r\n",
        "        >>> temp = db.find_one_job(args={'job_id': 1})\r\n",
        "        >>> print(temp['learning_rate'])\r\n",
        "        ... 0.01\r\n",
        "        >>> import _your_script\r\n",
        "        ... running your script\r\n",
        "        \"\"\"\r\n",
        "        if script is None:\r\n",
        "            _script = open(script, 'rb').read()\r\n",
        "            args.update({'script': _script, 'script_name': script})\r\n",
        "        _result = self.db.Job.insert_one(args)\r\n",
        "        _log = self._print_dict(args)\r\n",
        "        print(\"[TensorDB] Save Job: {}\".format(script))\r\n",
        "        return _result\r\n",
        "\r\n",
        "    def find_one_job(self, args={}):\r\n",
        "        \"\"\" Find one job from MongoDB Job Collections.\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        args : dictionary, find items.\r\n",
        "        Returns\r\n",
        "        --------\r\n",
        "        dictionary : contains all meta data and script.\r\n",
        "        \"\"\"\r\n",
        "        temp = self.db.Job.find_one(args)\r\n",
        "\r\n",
        "        if 'script_name' in temp.keys():\r\n",
        "            f = open('_' + temp['script_name'], 'wb')\r\n",
        "            f.write(temp['script'])\r\n",
        "            f.close()\r\n",
        "        print(\"[TensorDB] Find Job: {}\".format(args))\r\n",
        "        return temp\r\n",
        "\r\n",
        "    def train_log(self, args={}):\r\n",
        "        \"\"\"Save the training log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, items to save.\r\n",
        "        Examples\r\n",
        "        ---------\r\n",
        "        >>> db.train_log(time=time.time(), {'loss': loss, 'acc': acc})\r\n",
        "        \"\"\"\r\n",
        "        _result = self.db.TrainLog.insert_one(args)\r\n",
        "        _log = self._print_dict(args)\r\n",
        "        print(\"[TensorDB] TrainLog: \" +_log)\r\n",
        "        return _result\r\n",
        "\r\n",
        "    def del_train_log(self, args={}):\r\n",
        "        \"\"\" Delete train log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, find items to delete, leave it empty to delete all log.\r\n",
        "        \"\"\"\r\n",
        "        self.db.TrainLog.delete_many(args)\r\n",
        "        print(\"[TensorDB] Delete TrainLog SUCCESS\")\r\n",
        "\r\n",
        "    def valid_log(self, args={}):\r\n",
        "        \"\"\"Save the validating log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, items to save.\r\n",
        "        Examples\r\n",
        "        ---------\r\n",
        "        >>> db.valid_log(time=time.time(), {'loss': loss, 'acc': acc})\r\n",
        "        \"\"\"\r\n",
        "        _result = self.db.ValidLog.insert_one(args)\r\n",
        "        # _log = \"\".join(str(key) + \": \" + str(value) for key, value in args.items())\r\n",
        "        _log = self._print_dict(args)\r\n",
        "        print(\"[TensorDB] ValidLog: \" +_log)\r\n",
        "        return _result\r\n",
        "\r\n",
        "    def del_valid_log(self, args={}):\r\n",
        "        \"\"\" Delete validation log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, find items to delete, leave it empty to delete all log.\r\n",
        "        \"\"\"\r\n",
        "        self.db.ValidLog.delete_many(args)\r\n",
        "        print(\"[TensorDB] Delete ValidLog SUCCESS\")\r\n",
        "\r\n",
        "    def test_log(self, args={}):\r\n",
        "        \"\"\"Save the testing log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, items to save.\r\n",
        "        Examples\r\n",
        "        ---------\r\n",
        "        >>> db.test_log(time=time.time(), {'loss': loss, 'acc': acc})\r\n",
        "        \"\"\"\r\n",
        "        _result = self.db.TestLog.insert_one(args)\r\n",
        "        # _log = \"\".join(str(key) + str(value) for key, value in args.items())\r\n",
        "        _log = self._print_dict(args)\r\n",
        "        print(\"[TensorDB] TestLog: \" +_log)\r\n",
        "        return _result\r\n",
        "\r\n",
        "    def del_test_log(self, args={}):\r\n",
        "        \"\"\" Delete test log.\r\n",
        "        Parameters\r\n",
        "        -----------\r\n",
        "        args : dictionary, find items to delete, leave it empty to delete all log.\r\n",
        "        \"\"\"\r\n",
        "        self.db.TestLog.delete_many(args)\r\n",
        "        print(\"[TensorDB] Delete TestLog SUCCESS\")\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        _s = \"[TensorDB] Info:\\n\"\r\n",
        "        _t = _s + \"    \" + str(self.db)\r\n",
        "        return _t\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "\r\n",
        "    db = TensorDB(ip='localhost', port=27017, db_name='mnist', user_name=None, password=None)\r\n",
        "\r\n",
        "    db.save_job('your_script.py', {'job_id': 1, 'learning_rate': 0.01, 'n_units': 100})\r\n",
        "    temp = db.find_one_job(args={'job_id': 1})\r\n",
        "\r\n",
        "    print(temp['learning_rate'])\r\n",
        "\r\n",
        "    import _your_script\r\n",
        "    print(\"import _your_script SUCCESS\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-833d269ebb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorlayer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "-o2C7XBad0S3",
        "outputId": "9dbc4317-b29e-493a-cc8a-9e31ba19f26d"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import sys\r\n",
        "import tarfile\r\n",
        "import gzip\r\n",
        "import zipfile\r\n",
        "from . import visualize\r\n",
        "from . import nlp\r\n",
        "import pickle\r\n",
        "from six.moves import urllib\r\n",
        "from six.moves import cPickle\r\n",
        "from six.moves import zip\r\n",
        "from tensorflow.python.platform import gfile\r\n",
        "\r\n",
        "\r\n",
        "## Load dataset functions\r\n",
        "def load_mnist_dataset(shape=(-1,784), path=\"data/mnist/\"):\r\n",
        "    \"\"\"Automatically download MNIST dataset\r\n",
        "    and return the training, validation and test set with 50000, 10000 and 10000\r\n",
        "    digit images respectively.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    shape : tuple\r\n",
        "        The shape of digit images, defaults to (-1,784)\r\n",
        "    path : string\r\n",
        "        Path to download data to, defaults to data/mnist/\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1,784))\r\n",
        "    >>> X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 28, 28, 1))\r\n",
        "    \"\"\"\r\n",
        "    # We first define functions for loading MNIST images and labels.\r\n",
        "    # For convenience, they also download the requested files if needed.\r\n",
        "    def load_mnist_images(path, filename):\r\n",
        "        filepath = maybe_download_and_extract(filename, path, 'http://yann.lecun.com/exdb/mnist/')\r\n",
        "\r\n",
        "        print(filepath)\r\n",
        "        # Read the inputs in Yann LeCun's binary format.\r\n",
        "        with gzip.open(filepath, 'rb') as f:\r\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\r\n",
        "        # The inputs are vectors now, we reshape them to monochrome 2D images,\r\n",
        "        # following the shape convention: (examples, channels, rows, columns)\r\n",
        "        data = data.reshape(shape)\r\n",
        "        # The inputs come as bytes, we convert them to float32 in range [0,1].\r\n",
        "        # (Actually to range [0, 255/256], for compatibility to the version\r\n",
        "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\r\n",
        "        return data / np.float32(256)\r\n",
        "\r\n",
        "    def load_mnist_labels(path, filename):\r\n",
        "        filepath = maybe_download_and_extract(filename, path, 'http://yann.lecun.com/exdb/mnist/')\r\n",
        "        # Read the labels in Yann LeCun's binary format.\r\n",
        "        with gzip.open(filepath, 'rb') as f:\r\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=8)\r\n",
        "        # The labels are vectors of integers now, that's exactly what we want.\r\n",
        "        return data\r\n",
        "\r\n",
        "    # Download and read the training and test set images and labels.\r\n",
        "    print(\"Load or Download MNIST > {}\".format(path))\r\n",
        "    X_train = load_mnist_images(path, 'train-images-idx3-ubyte.gz')\r\n",
        "    y_train = load_mnist_labels(path, 'train-labels-idx1-ubyte.gz')\r\n",
        "    X_test = load_mnist_images(path, 't10k-images-idx3-ubyte.gz')\r\n",
        "    y_test = load_mnist_labels(path, 't10k-labels-idx1-ubyte.gz')\r\n",
        "\r\n",
        "    # We reserve the last 10000 training examples for validation.\r\n",
        "    X_train, X_val = X_train[:-10000], X_train[-10000:]\r\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\r\n",
        "\r\n",
        "    # We just return all the arrays in order, as expected in main().\r\n",
        "    # (It doesn't matter how we do this as long as we can read them again.)\r\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\r\n",
        "    y_train = np.asarray(y_train, dtype=np.int32)\r\n",
        "    X_val = np.asarray(X_val, dtype=np.float32)\r\n",
        "    y_val = np.asarray(y_val, dtype=np.int32)\r\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\r\n",
        "    y_test = np.asarray(y_test, dtype=np.int32)\r\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\r\n",
        "\r\n",
        "\r\n",
        "def load_cifar10_dataset(shape=(-1, 32, 32, 3), path='data/cifar10/', plotable=False, second=3):\r\n",
        "    \"\"\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with\r\n",
        "    6000 images per class. There are 50000 training images and 10000 test images.\r\n",
        "    The dataset is divided into five training batches and one test batch, each with\r\n",
        "    10000 images. The test batch contains exactly 1000 randomly-selected images from\r\n",
        "    each class. The training batches contain the remaining images in random order,\r\n",
        "    but some training batches may contain more images from one class than another.\r\n",
        "    Between them, the training batches contain exactly 5000 images from each class.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    shape : tupe\r\n",
        "        The shape of digit images: e.g. (-1, 3, 32, 32) , (-1, 32, 32, 3) , (-1, 32*32*3)\r\n",
        "    plotable : True, False\r\n",
        "        Whether to plot some image examples.\r\n",
        "    second : int\r\n",
        "        If ``plotable`` is True, ``second`` is the display time.\r\n",
        "    path : string\r\n",
        "        Path to download data to, defaults to data/cifar10/\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=True)\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    CIFAR-10 images can only be display without color change under uint8.\r\n",
        "    >>> X_train = np.asarray(X_train, dtype=np.uint8)\r\n",
        "    >>> plt.ion()\r\n",
        "    >>> fig = plt.figure(1232)\r\n",
        "    >>> count = 1\r\n",
        "    >>> for row in range(10):\r\n",
        "    >>>     for col in range(10):\r\n",
        "    >>>         a = fig.add_subplot(10, 10, count)\r\n",
        "    >>>         plt.imshow(X_train[count-1], interpolation='nearest')\r\n",
        "    >>>         plt.gca().xaxis.set_major_locator(plt.NullLocator())    # 不显示刻度(tick)\r\n",
        "    >>>         plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "    >>>         count = count + 1\r\n",
        "    >>> plt.draw()\r\n",
        "    >>> plt.pause(3)\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `CIFAR website <https://www.cs.toronto.edu/~kriz/cifar.html>`_\r\n",
        "    - `Data download link <https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz>`_\r\n",
        "    - `Code references <https://teratail.com/questions/28932>`_\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    print(\"Load or Download cifar10 > {}\".format(path))\r\n",
        "\r\n",
        "    #Helper function to unpickle the data\r\n",
        "    def unpickle(file):\r\n",
        "        fp = open(file, 'rb')\r\n",
        "        if sys.version_info.major == 2:\r\n",
        "            data = pickle.load(fp)\r\n",
        "        elif sys.version_info.major == 3:\r\n",
        "            data = pickle.load(fp, encoding='latin-1')\r\n",
        "        fp.close()\r\n",
        "        return data\r\n",
        "\r\n",
        "    filename = 'cifar-10-python.tar.gz'\r\n",
        "    url = 'https://www.cs.toronto.edu/~kriz/'\r\n",
        "    #Download and uncompress file\r\n",
        "    maybe_download_and_extract(filename, path, url, extract=True)\r\n",
        "\r\n",
        "    #Unpickle file and fill in data\r\n",
        "    X_train = None\r\n",
        "    y_train = []\r\n",
        "    for i in range(1,6):\r\n",
        "        data_dic = unpickle(os.path.join(path, 'cifar-10-batches-py/', \"data_batch_{}\".format(i)))\r\n",
        "        if i == 1:\r\n",
        "            X_train = data_dic['data']\r\n",
        "        else:\r\n",
        "            X_train = np.vstack((X_train, data_dic['data']))\r\n",
        "        y_train += data_dic['labels']\r\n",
        "\r\n",
        "    test_data_dic = unpickle(os.path.join(path,  'cifar-10-batches-py/', \"test_batch\"))\r\n",
        "    X_test = test_data_dic['data']\r\n",
        "    y_test = np.array(test_data_dic['labels'])\r\n",
        "\r\n",
        "    if shape == (-1, 3, 32, 32):\r\n",
        "        X_test = X_test.reshape(shape)\r\n",
        "        X_train = X_train.reshape(shape)\r\n",
        "    elif shape == (-1, 32, 32, 3):\r\n",
        "        X_test = X_test.reshape(shape, order='F')\r\n",
        "        X_train = X_train.reshape(shape, order='F')\r\n",
        "        X_test = np.transpose(X_test, (0, 2, 1, 3))\r\n",
        "        X_train = np.transpose(X_train, (0, 2, 1, 3))\r\n",
        "    else:\r\n",
        "        X_test = X_test.reshape(shape)\r\n",
        "        X_train = X_train.reshape(shape)\r\n",
        "\r\n",
        "    y_train = np.array(y_train)\r\n",
        "\r\n",
        "    if plotable == True:\r\n",
        "        print('\\nCIFAR-10')\r\n",
        "        import matplotlib.pyplot as plt\r\n",
        "        fig = plt.figure(1)\r\n",
        "\r\n",
        "        print('Shape of a training image: X_train[0]',X_train[0].shape)\r\n",
        "\r\n",
        "        plt.ion()       # interactive mode\r\n",
        "        count = 1\r\n",
        "        for row in range(10):\r\n",
        "            for col in range(10):\r\n",
        "                a = fig.add_subplot(10, 10, count)\r\n",
        "                if shape == (-1, 3, 32, 32):\r\n",
        "                    # plt.imshow(X_train[count-1], interpolation='nearest')\r\n",
        "                    plt.imshow(np.transpose(X_train[count-1], (1, 2, 0)), interpolation='nearest')\r\n",
        "                    # plt.imshow(np.transpose(X_train[count-1], (2, 1, 0)), interpolation='nearest')\r\n",
        "                elif shape == (-1, 32, 32, 3):\r\n",
        "                    plt.imshow(X_train[count-1], interpolation='nearest')\r\n",
        "                    # plt.imshow(np.transpose(X_train[count-1], (1, 0, 2)), interpolation='nearest')\r\n",
        "                else:\r\n",
        "                    raise Exception(\"Do not support the given 'shape' to plot the image examples\")\r\n",
        "                plt.gca().xaxis.set_major_locator(plt.NullLocator())    # 不显示刻度(tick)\r\n",
        "                plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "                count = count + 1\r\n",
        "        plt.draw()      # interactive mode\r\n",
        "        plt.pause(3)   # interactive mode\r\n",
        "\r\n",
        "        print(\"X_train:\",X_train.shape)\r\n",
        "        print(\"y_train:\",y_train.shape)\r\n",
        "        print(\"X_test:\",X_test.shape)\r\n",
        "        print(\"y_test:\",y_test.shape)\r\n",
        "\r\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\r\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\r\n",
        "    y_train = np.asarray(y_train, dtype=np.int32)\r\n",
        "    y_test = np.asarray(y_test, dtype=np.int32)\r\n",
        "\r\n",
        "    return X_train, y_train, X_test, y_test\r\n",
        "\r\n",
        "\r\n",
        "def load_ptb_dataset(path='data/ptb/'):\r\n",
        "    \"\"\"Penn TreeBank (PTB) dataset is used in many LANGUAGE MODELING papers,\r\n",
        "    including \"Empirical Evaluation and Combination of Advanced Language\r\n",
        "    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\r\n",
        "    It consists of 929k training words, 73k validation words, and 82k test\r\n",
        "    words. It has 10k words in its vocabulary.\r\n",
        "    In \"Recurrent Neural Network Regularization\", they trained regularized LSTMs\r\n",
        "    of two sizes; these are denoted the medium LSTM and large LSTM. Both LSTMs\r\n",
        "    have two layers and are unrolled for 35 steps. They initialize the hidden\r\n",
        "    states to zero. They then use the final hidden states of the current\r\n",
        "    minibatch as the initial hidden state of the subsequent minibatch\r\n",
        "    (successive minibatches sequentially traverse the training set).\r\n",
        "    The size of each minibatch is 20.\r\n",
        "    The medium LSTM has 650 units per layer and its parameters are initialized\r\n",
        "    uniformly in [−0.05, 0.05]. They apply 50% dropout on the non-recurrent\r\n",
        "    connections. They train the LSTM for 39 epochs with a learning rate of 1,\r\n",
        "    and after 6 epochs they decrease it by a factor of 1.2 after each epoch.\r\n",
        "    They clip the norm of the gradients (normalized by minibatch size) at 5.\r\n",
        "    The large LSTM has 1500 units per layer and its parameters are initialized\r\n",
        "    uniformly in [−0.04, 0.04]. We apply 65% dropout on the non-recurrent\r\n",
        "    connections. They train the model for 55 epochs with a learning rate of 1;\r\n",
        "    after 14 epochs they start to reduce the learning rate by a factor of 1.15\r\n",
        "    after each epoch. They clip the norm of the gradients (normalized by\r\n",
        "    minibatch size) at 10.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : : string\r\n",
        "        Path to download data to, defaults to data/ptb/\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    train_data, valid_data, test_data, vocabulary size\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - ``tensorflow.models.rnn.ptb import reader``\r\n",
        "    Download Links\r\n",
        "    ---------------\r\n",
        "    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`_\r\n",
        "    \"\"\"\r\n",
        "    print(\"Load or Download Penn TreeBank (PTB) dataset > {}\".format(path))\r\n",
        "\r\n",
        "    #Maybe dowload and uncompress tar, or load exsisting files\r\n",
        "    filename = 'simple-examples.tgz'\r\n",
        "    url = 'http://www.fit.vutbr.cz/~imikolov/rnnlm/'\r\n",
        "    maybe_download_and_extract(filename, path, url, extract=True)\r\n",
        "\r\n",
        "    data_path = os.path.join(path, 'simple-examples', 'data')\r\n",
        "    train_path = os.path.join(data_path, \"ptb.train.txt\")\r\n",
        "    valid_path = os.path.join(data_path, \"ptb.valid.txt\")\r\n",
        "    test_path = os.path.join(data_path, \"ptb.test.txt\")\r\n",
        "\r\n",
        "    word_to_id = nlp.build_vocab(nlp.read_words(train_path))\r\n",
        "\r\n",
        "    train_data = nlp.words_to_word_ids(nlp.read_words(train_path), word_to_id)\r\n",
        "    valid_data = nlp.words_to_word_ids(nlp.read_words(valid_path), word_to_id)\r\n",
        "    test_data = nlp.words_to_word_ids(nlp.read_words(test_path), word_to_id)\r\n",
        "    vocabulary = len(word_to_id)\r\n",
        "\r\n",
        "    # print(nlp.read_words(train_path))     # ... 'according', 'to', 'mr.', '<unk>', '<eos>']\r\n",
        "    # print(train_data)                 # ...  214,         5,    23,    1,       2]\r\n",
        "    # print(word_to_id)                 # ... 'beyond': 1295, 'anti-nuclear': 9599, 'trouble': 1520, '<eos>': 2 ... }\r\n",
        "    # print(vocabulary)                 # 10000\r\n",
        "    # exit()\r\n",
        "    return train_data, valid_data, test_data, vocabulary\r\n",
        "\r\n",
        "\r\n",
        "def load_matt_mahoney_text8_dataset(path='data/mm_test8/'):\r\n",
        "    \"\"\"Download a text file from Matt Mahoney's website\r\n",
        "    if not present, and make sure it's the right size.\r\n",
        "    Extract the first file enclosed in a zip file as a list of words.\r\n",
        "    This dataset can be used for Word Embedding.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : : string\r\n",
        "        Path to download data to, defaults to data/mm_test8/\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    word_list : a list\r\n",
        "        a list of string (word).\\n\r\n",
        "        e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> words = tl.files.load_matt_mahoney_text8_dataset()\r\n",
        "    >>> print('Data size', len(words))\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    print(\"Load or Download matt_mahoney_text8 Dataset> {}\".format(path))\r\n",
        "\r\n",
        "    filename = 'text8.zip'\r\n",
        "    url = 'http://mattmahoney.net/dc/'\r\n",
        "    maybe_download_and_extract(filename, path, url, expected_bytes=31344016)\r\n",
        "\r\n",
        "    with zipfile.ZipFile(os.path.join(path, filename)) as f:\r\n",
        "        word_list = f.read(f.namelist()[0]).split()\r\n",
        "\r\n",
        "    return word_list\r\n",
        "\r\n",
        "\r\n",
        "def load_imdb_dataset(path='data/imdb/', nb_words=None, skip_top=0,\r\n",
        "              maxlen=None, test_split=0.2, seed=113,\r\n",
        "              start_char=1, oov_char=2, index_from=3):\r\n",
        "    \"\"\"Load IMDB dataset\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : : string\r\n",
        "        Path to download data to, defaults to data/imdb/\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_test, y_test = tl.files.load_imbd_dataset(\r\n",
        "    ...                                 nb_words=20000, test_split=0.2)\r\n",
        "    >>> print('X_train.shape', X_train.shape)\r\n",
        "    ... (20000,)  [[1, 62, 74, ... 1033, 507, 27],[1, 60, 33, ... 13, 1053, 7]..]\r\n",
        "    >>> print('y_train.shape', y_train.shape)\r\n",
        "    ... (20000,)  [1 0 0 ..., 1 0 1]\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `Modified from keras. <https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py>`_\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    filename = \"imdb.pkl\"\r\n",
        "    url = 'https://s3.amazonaws.com/text-datasets/'\r\n",
        "    maybe_download_and_extract(filename, path, url)\r\n",
        "\r\n",
        "    if filename.endswith(\".gz\"):\r\n",
        "        f = gzip.open(os.path.join(path, filename), 'rb')\r\n",
        "    else:\r\n",
        "        f = open(os.path.join(path, filename), 'rb')\r\n",
        "\r\n",
        "    X, labels = cPickle.load(f)\r\n",
        "    f.close()\r\n",
        "\r\n",
        "    np.random.seed(seed)\r\n",
        "    np.random.shuffle(X)\r\n",
        "    np.random.seed(seed)\r\n",
        "    np.random.shuffle(labels)\r\n",
        "\r\n",
        "    if start_char is not None:\r\n",
        "        X = [[start_char] + [w + index_from for w in x] for x in X]\r\n",
        "    elif index_from:\r\n",
        "        X = [[w + index_from for w in x] for x in X]\r\n",
        "\r\n",
        "    if maxlen:\r\n",
        "        new_X = []\r\n",
        "        new_labels = []\r\n",
        "        for x, y in zip(X, labels):\r\n",
        "            if len(x) < maxlen:\r\n",
        "                new_X.append(x)\r\n",
        "                new_labels.append(y)\r\n",
        "        X = new_X\r\n",
        "        labels = new_labels\r\n",
        "    if not X:\r\n",
        "        raise Exception('After filtering for sequences shorter than maxlen=' +\r\n",
        "                        str(maxlen) + ', no sequence was kept. '\r\n",
        "                        'Increase maxlen.')\r\n",
        "    if not nb_words:\r\n",
        "        nb_words = max([max(x) for x in X])\r\n",
        "\r\n",
        "    # by convention, use 2 as OOV word\r\n",
        "    # reserve 'index_from' (=3 by default) characters: 0 (padding), 1 (start), 2 (OOV)\r\n",
        "    if oov_char is not None:\r\n",
        "        X = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in X]\r\n",
        "    else:\r\n",
        "        nX = []\r\n",
        "        for x in X:\r\n",
        "            nx = []\r\n",
        "            for w in x:\r\n",
        "                if (w >= nb_words or w < skip_top):\r\n",
        "                    nx.append(w)\r\n",
        "            nX.append(nx)\r\n",
        "        X = nX\r\n",
        "\r\n",
        "    X_train = np.array(X[:int(len(X) * (1 - test_split))])\r\n",
        "    y_train = np.array(labels[:int(len(X) * (1 - test_split))])\r\n",
        "\r\n",
        "    X_test = np.array(X[int(len(X) * (1 - test_split)):])\r\n",
        "    y_test = np.array(labels[int(len(X) * (1 - test_split)):])\r\n",
        "\r\n",
        "    return X_train, y_train, X_test, y_test\r\n",
        "\r\n",
        "def load_nietzsche_dataset(path='data/nietzsche/'):\r\n",
        "    \"\"\"Load Nietzsche dataset.\r\n",
        "    Returns a string.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : string\r\n",
        "        Path to download data to, defaults to data/nietzsche/\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see tutorial_generate_text.py\r\n",
        "    >>> words = tl.files.load_nietzsche_dataset()\r\n",
        "    >>> words = basic_clean_str(words)\r\n",
        "    >>> words = words.split()\r\n",
        "    \"\"\"\r\n",
        "    print(\"Load or Download nietzsche dataset > {}\".format(path))\r\n",
        "\r\n",
        "    filename = \"nietzsche.txt\"\r\n",
        "    url = 'https://s3.amazonaws.com/text-datasets/'\r\n",
        "    filepath = maybe_download_and_extract(filename, path, url)\r\n",
        "\r\n",
        "    with open(filepath, \"r\") as f:\r\n",
        "        words = f.read()\r\n",
        "        return words\r\n",
        "\r\n",
        "def load_wmt_en_fr_dataset(path='data/wmt_en_fr/'):\r\n",
        "    \"\"\"It will download English-to-French translation data from the WMT'15\r\n",
        "    Website (10^9-French-English corpus), and the 2013 news test from\r\n",
        "    the same site as development set.\r\n",
        "    Returns the directories of training data and test data.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : string\r\n",
        "        Path to download data to, defaults to data/wmt_en_fr/\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - Code modified from /tensorflow/models/rnn/translation/data_utils.py\r\n",
        "    Notes\r\n",
        "    -----\r\n",
        "    Usually, it will take a long time to download this dataset.\r\n",
        "    \"\"\"\r\n",
        "    # URLs for WMT data.\r\n",
        "    _WMT_ENFR_TRAIN_URL = \"http://www.statmt.org/wmt10/\"\r\n",
        "    _WMT_ENFR_DEV_URL = \"http://www.statmt.org/wmt15/\"\r\n",
        "\r\n",
        "    def gunzip_file(gz_path, new_path):\r\n",
        "        \"\"\"Unzips from gz_path into new_path.\"\"\"\r\n",
        "        print(\"Unpacking %s to %s\" % (gz_path, new_path))\r\n",
        "        with gzip.open(gz_path, \"rb\") as gz_file:\r\n",
        "            with open(new_path, \"wb\") as new_file:\r\n",
        "                for line in gz_file:\r\n",
        "                    new_file.write(line)\r\n",
        "\r\n",
        "    def get_wmt_enfr_train_set(path):\r\n",
        "        \"\"\"Download the WMT en-fr training corpus to directory unless it's there.\"\"\"\r\n",
        "        filename = \"training-giga-fren.tar\"\r\n",
        "        maybe_download_and_extract(filename, path, _WMT_ENFR_TRAIN_URL, extract=True)\r\n",
        "        train_path = os.path.join(path, \"giga-fren.release2.fixed\")\r\n",
        "        gunzip_file(train_path + \".fr.gz\", train_path + \".fr\")\r\n",
        "        gunzip_file(train_path + \".en.gz\", train_path + \".en\")\r\n",
        "        return train_path\r\n",
        "\r\n",
        "    def get_wmt_enfr_dev_set(path):\r\n",
        "        \"\"\"Download the WMT en-fr training corpus to directory unless it's there.\"\"\"\r\n",
        "        filename = \"dev-v2.tgz\"\r\n",
        "        dev_file = maybe_download_and_extract(filename, path, _WMT_ENFR_DEV_URL, extract=False)\r\n",
        "        dev_name = \"newstest2013\"\r\n",
        "        dev_path = os.path.join(path, \"newstest2013\")\r\n",
        "        if not (gfile.Exists(dev_path + \".fr\") and gfile.Exists(dev_path + \".en\")):\r\n",
        "            print(\"Extracting tgz file %s\" % dev_file)\r\n",
        "            with tarfile.open(dev_file, \"r:gz\") as dev_tar:\r\n",
        "              fr_dev_file = dev_tar.getmember(\"dev/\" + dev_name + \".fr\")\r\n",
        "              en_dev_file = dev_tar.getmember(\"dev/\" + dev_name + \".en\")\r\n",
        "              fr_dev_file.name = dev_name + \".fr\"  # Extract without \"dev/\" prefix.\r\n",
        "              en_dev_file.name = dev_name + \".en\"\r\n",
        "              dev_tar.extract(fr_dev_file, path)\r\n",
        "              dev_tar.extract(en_dev_file, path)\r\n",
        "        return dev_path\r\n",
        "\r\n",
        "    print(\"Load or Download WMT English-to-French translation > {}\".format(path))\r\n",
        "\r\n",
        "    train_path = get_wmt_enfr_train_set(path)\r\n",
        "    dev_path = get_wmt_enfr_dev_set(path)\r\n",
        "\r\n",
        "    return train_path, dev_path\r\n",
        "\r\n",
        "\r\n",
        "## Load and save network\r\n",
        "def save_npz(save_list=[], name='model.npz', sess=None):\r\n",
        "    \"\"\"Input parameters and the file name, save parameters into .npz file. Use tl.utils.load_npz() to restore.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    save_list : a list\r\n",
        "        Parameters want to be saved.\r\n",
        "    name : a string or None\r\n",
        "        The name of the .npz file.\r\n",
        "    sess : None or Session\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> tl.files.save_npz(network.all_params, name='model_test.npz', sess=sess)\r\n",
        "    ... File saved to: model_test.npz\r\n",
        "    >>> load_params = tl.files.load_npz(name='model_test.npz')\r\n",
        "    ... Loading param0, (784, 800)\r\n",
        "    ... Loading param1, (800,)\r\n",
        "    ... Loading param2, (800, 800)\r\n",
        "    ... Loading param3, (800,)\r\n",
        "    ... Loading param4, (800, 10)\r\n",
        "    ... Loading param5, (10,)\r\n",
        "    >>> put parameters into a TensorLayer network, please see assign_params()\r\n",
        "    Notes\r\n",
        "    -----\r\n",
        "    If you got session issues, you can change the value.eval() to value.eval(session=sess)\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `Saving dictionary using numpy <http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez>`_\r\n",
        "    \"\"\"\r\n",
        "    ## save params into a list\r\n",
        "    save_list_var = []\r\n",
        "    if sess:\r\n",
        "        save_list_var = sess.run(save_list)\r\n",
        "    else:\r\n",
        "        try:\r\n",
        "            for k, value in enumerate(save_list):\r\n",
        "                save_list_var.append(value.eval())\r\n",
        "        except:\r\n",
        "            print(\" Fail to save model, Hint: pass the session into this function, save_npz(network.all_params, name='model.npz', sess=sess)\")\r\n",
        "    np.savez(name, params=save_list_var)\r\n",
        "    save_list_var = None\r\n",
        "    del save_list_var\r\n",
        "    print(\"[*] %s saved\" % name)\r\n",
        "\r\n",
        "    ## save params into a dictionary\r\n",
        "    # rename_dict = {}\r\n",
        "    # for k, value in enumerate(save_dict):\r\n",
        "    #     rename_dict.update({'param'+str(k) : value.eval()})\r\n",
        "    # np.savez(name, **rename_dict)\r\n",
        "    # print('Model is saved to: %s' % name)\r\n",
        "\r\n",
        "def load_npz(path='', name='model.npz'):\r\n",
        "    \"\"\"Load the parameters of a Model saved by tl.files.save_npz().\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string\r\n",
        "        Folder path to .npz file.\r\n",
        "    name : a string or None\r\n",
        "        The name of the .npz file.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    params : list\r\n",
        "        A list of parameters in order.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - See save_npz and assign_params\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `Saving dictionary using numpy <http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez>`_\r\n",
        "    \"\"\"\r\n",
        "    ## if save_npz save params into a dictionary\r\n",
        "    # d = np.load( path+name )\r\n",
        "    # params = []\r\n",
        "    # print('Load Model')\r\n",
        "    # for key, val in sorted( d.items() ):\r\n",
        "    #     params.append(val)\r\n",
        "    #     print('Loading %s, %s' % (key, str(val.shape)))\r\n",
        "    # return params\r\n",
        "    ## if save_npz save params into a list\r\n",
        "    d = np.load( path+name )\r\n",
        "    # for val in sorted( d.items() ):\r\n",
        "    #     params = val\r\n",
        "    #     return params\r\n",
        "    return d['params']\r\n",
        "    # print(d.items()[0][1]['params'])\r\n",
        "    # exit()\r\n",
        "    # return d.items()[0][1]['params']\r\n",
        "\r\n",
        "def assign_params(sess, params, network):\r\n",
        "    \"\"\"Assign the given parameters to the TensorLayer network.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : TensorFlow Session\r\n",
        "    params : a list\r\n",
        "        A list of parameters in order.\r\n",
        "    network : a :class:`Layer` class\r\n",
        "        The network to be assigned\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> Save your network as follow:\r\n",
        "    >>> tl.files.save_npz(network.all_params, name='model_test.npz')\r\n",
        "    >>> network.print_params()\r\n",
        "    ...\r\n",
        "    ... Next time, load and assign your network as follow:\r\n",
        "    >>> sess.run(tf.initialize_all_variables()) # re-initialize, then save and assign\r\n",
        "    >>> load_params = tl.files.load_npz(name='model_test.npz')\r\n",
        "    >>> tl.files.assign_params(sess, load_params, network)\r\n",
        "    >>> network.print_params()\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `Assign value to a TensorFlow variable <http://stackoverflow.com/questions/34220532/how-to-assign-value-to-a-tensorflow-variable>`_\r\n",
        "    \"\"\"\r\n",
        "    ops = []\r\n",
        "    for idx, param in enumerate(params):\r\n",
        "        ops.append(network.all_params[idx].assign(param))\r\n",
        "    sess.run(ops)\r\n",
        "\r\n",
        "def load_and_assign_npz(sess=None, name=None, network=None):\r\n",
        "    \"\"\"Load model from npz and assign to a network.\r\n",
        "    Parameters\r\n",
        "    -------------\r\n",
        "    sess : TensorFlow Session\r\n",
        "    name : string\r\n",
        "        Model path.\r\n",
        "    network : a :class:`Layer` class\r\n",
        "        The network to be assigned\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    Returns False if faild to model is not exist.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> tl.files.load_and_assign_npz(sess=sess, name='net.npz', network=net)\r\n",
        "    \"\"\"\r\n",
        "    assert network is not None\r\n",
        "    assert sess is not None\r\n",
        "    if not os.path.exists(name):\r\n",
        "        print(\"[!] Load {} failed!\".format(name))\r\n",
        "        return False\r\n",
        "    else:\r\n",
        "        params = load_npz(name=name)\r\n",
        "        assign_params(sess, params, network)\r\n",
        "        print(\"[*] Load {} SUCCESS!\".format(name))\r\n",
        "        return network\r\n",
        "\r\n",
        "# Load and save variables\r\n",
        "def save_any_to_npy(save_dict={}, name='file.npy'):\r\n",
        "    \"\"\"Save variables to .npy file.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> tl.files.save_any_to_npy(save_dict={'data': ['a','b']}, name='test.npy')\r\n",
        "    >>> data = tl.files.load_npy_to_any(name='test.npy')\r\n",
        "    >>> print(data)\r\n",
        "    ... {'data': ['a','b']}\r\n",
        "    \"\"\"\r\n",
        "    np.save(name, save_dict)\r\n",
        "\r\n",
        "def load_npy_to_any(path='', name='file.npy'):\r\n",
        "    \"\"\"Load .npy file.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    - see save_any_to_npy()\r\n",
        "    \"\"\"\r\n",
        "    file_path = os.path.join(path, name)\r\n",
        "    try:\r\n",
        "        npy = np.load(file_path).item()\r\n",
        "    except:\r\n",
        "        npy = np.load(file_path)\r\n",
        "    finally:\r\n",
        "        try:\r\n",
        "            return npy\r\n",
        "        except:\r\n",
        "            print(\"[!] Fail to load %s\" % file_path)\r\n",
        "            exit()\r\n",
        "\r\n",
        "\r\n",
        "# Visualizing npz files\r\n",
        "def npz_to_W_pdf(path=None, regx='w1pre_[0-9]+\\.(npz)'):\r\n",
        "    \"\"\"Convert the first weight matrix of .npz file to .pdf by using tl.visualize.W().\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string or None\r\n",
        "        A folder path to npz files.\r\n",
        "    regx : a string\r\n",
        "        Regx for the file name.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> Convert the first weight matrix of w1_pre...npz file to w1_pre...pdf.\r\n",
        "    >>> tl.files.npz_to_W_pdf(path='/Users/.../npz_file/', regx='w1pre_[0-9]+\\.(npz)')\r\n",
        "    \"\"\"\r\n",
        "    file_list = load_file_list(path=path, regx=regx)\r\n",
        "    for f in file_list:\r\n",
        "        W = load_npz(path, f)[0]\r\n",
        "        print(\"%s --> %s\" % (f, f.split('.')[0]+'.pdf'))\r\n",
        "        visualize.W(W, second=10, saveable=True, name=f.split('.')[0], fig_idx=2012)\r\n",
        "\r\n",
        "\r\n",
        "## Helper functions\r\n",
        "def load_file_list(path=None, regx='\\.npz', printable=True):\r\n",
        "    \"\"\"Return a file list in a folder by given a path and regular expression.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string or None\r\n",
        "        A folder path.\r\n",
        "    regx : a string\r\n",
        "        The regx of file name.\r\n",
        "    printable : boolean, whether to print the files infomation.\r\n",
        "    Examples\r\n",
        "    ----------\r\n",
        "    >>> file_list = tl.files.load_file_list(path=None, regx='w1pre_[0-9]+\\.(npz)')\r\n",
        "    \"\"\"\r\n",
        "    if path == False:\r\n",
        "        path = os.getcwd()\r\n",
        "    file_list = os.listdir(path)\r\n",
        "    return_list = []\r\n",
        "    for idx, f in enumerate(file_list):\r\n",
        "        if re.search(regx, f):\r\n",
        "            return_list.append(f)\r\n",
        "    # return_list.sort()\r\n",
        "    if printable:\r\n",
        "        print('Match file list = %s' % return_list)\r\n",
        "        print('Number of files = %d' % len(return_list))\r\n",
        "    return return_list\r\n",
        "\r\n",
        "def load_folder_list(path=\"\"):\r\n",
        "    \"\"\"Return a folder list in a folder by given a folder path.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string or None\r\n",
        "        A folder path.\r\n",
        "    \"\"\"\r\n",
        "    return [os.path.join(path,o) for o in os.listdir(path) if os.path.isdir(os.path.join(path,o))]\r\n",
        "\r\n",
        "def exists_or_mkdir(path, verbose=True):\r\n",
        "    \"\"\"Check a folder by given name, if not exist, create the folder and return False,\r\n",
        "    if directory exists, return True.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    path : a string\r\n",
        "        A folder path.\r\n",
        "    verbose : boolean\r\n",
        "        If True, prints results, deaults is True\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    True if folder exist, otherwise, returns False and create the folder\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> tl.files.exists_or_mkdir(\"checkpoints/train\")\r\n",
        "    \"\"\"\r\n",
        "    if not os.path.exists(path):\r\n",
        "        if verbose:\r\n",
        "            print(\"[*] creates %s ...\" % path)\r\n",
        "        os.makedirs(path)\r\n",
        "        return False\r\n",
        "    else:\r\n",
        "        if verbose:\r\n",
        "            print(\"[!] %s exists ...\" % path)\r\n",
        "        return True\r\n",
        "\r\n",
        "def maybe_download_and_extract(filename, working_directory, url_source, extract=False, expected_bytes=None):\r\n",
        "    \"\"\"Checks if file exists in working_directory otherwise tries to dowload the file,\r\n",
        "    and optionally also tries to extract the file if format is \".zip\" or \".tar\"\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    filename : string\r\n",
        "        The name of the (to be) dowloaded file.\r\n",
        "    working_directory : string\r\n",
        "        A folder path to search for the file in and dowload the file to\r\n",
        "    url : string\r\n",
        "        The URL to download the file from\r\n",
        "    extract : bool, defaults to False\r\n",
        "        If True, tries to uncompress the dowloaded file is \".tar.gz/.tar.bz2\" or \".zip\" file\r\n",
        "    expected_bytes : int/None\r\n",
        "        If set tries to verify that the downloaded file is of the specified size, otherwise raises an Exception,\r\n",
        "        defaults to None which corresponds to no check being performed\r\n",
        "    Returns\r\n",
        "    ----------\r\n",
        "    filepath to dowloaded (uncompressed) file\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> down_file = tl.files.maybe_download_and_extract(filename = 'train-images-idx3-ubyte.gz',\r\n",
        "                                                        working_directory = 'data/',\r\n",
        "                                                        url_source = 'http://yann.lecun.com/exdb/mnist/')\r\n",
        "    >>> tl.files.maybe_download_and_extract(filename = 'ADEChallengeData2016.zip',\r\n",
        "                                            working_directory = 'data/',\r\n",
        "                                            url_source = 'http://sceneparsing.csail.mit.edu/data/',\r\n",
        "                                            extract=True)\r\n",
        "    \"\"\"\r\n",
        "    # We first define a download function, supporting both Python 2 and 3.\r\n",
        "    def _download(filename, working_directory, url_source):\r\n",
        "        def _dlProgress(count, blockSize, totalSize):\r\n",
        "            if(totalSize != 0):\r\n",
        "                percent = float(count * blockSize) / float(totalSize) * 100.0\r\n",
        "                sys.stdout.write(\"\\r\" \"Downloading \" + filename + \"...%d%%\" % percent)\r\n",
        "                sys.stdout.flush()\r\n",
        "        if sys.version_info[0] == 2:\r\n",
        "            from urllib import urlretrieve\r\n",
        "        else:\r\n",
        "            from urllib.request import urlretrieve\r\n",
        "        filepath = os.path.join(working_directory, filename)\r\n",
        "        urlretrieve(url_source+filename, filepath, reporthook=_dlProgress)\r\n",
        "\r\n",
        "    exists_or_mkdir(working_directory, verbose=False)\r\n",
        "    filepath = os.path.join(working_directory, filename)\r\n",
        "\r\n",
        "    if not os.path.exists(filepath):\r\n",
        "        _download(filename, working_directory, url_source)\r\n",
        "        print()\r\n",
        "        statinfo = os.stat(filepath)\r\n",
        "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\r\n",
        "        if(not(expected_bytes is None) and (expected_bytes != statinfo.st_size)):\r\n",
        "            raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?')\r\n",
        "        if(extract):\r\n",
        "            if tarfile.is_tarfile(filepath):\r\n",
        "                print('Trying to extract tar file')\r\n",
        "                tarfile.open(filepath, 'r').extractall(working_directory)\r\n",
        "                print('... Success!')\r\n",
        "            elif zipfile.is_zipfile(filepath):\r\n",
        "                print('Trying to extract zip file')\r\n",
        "                with zipfile.ZipFile(filepath) as zf:\r\n",
        "                    zf.extractall(working_directory)\r\n",
        "                print('... Success!')\r\n",
        "            else:\r\n",
        "                print(\"Unknown compression_format only .tar.gz/.tar.bz2/.tar and .zip supported\")\r\n",
        "    return filepath"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7a088a18037c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYnEEDoxd88Y"
      },
      "source": [
        "import numpy as np\r\n",
        "from six.moves import xrange\r\n",
        "\r\n",
        "def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):\r\n",
        "    \"\"\"Generate a generator that input a group of example in numpy.array and\r\n",
        "    their labels, return the examples and labels by the given batchsize.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    inputs : numpy.array\r\n",
        "        (X) The input features, every row is a example.\r\n",
        "    targets : numpy.array\r\n",
        "        (y) The labels of inputs, every row is a example.\r\n",
        "    batch_size : int\r\n",
        "        The batch size.\r\n",
        "    shuffle : boolean\r\n",
        "        Indicating whether to use a shuffling queue, shuffle the dataset before return.\r\n",
        "    Hints\r\n",
        "    -------\r\n",
        "    - If you have two inputs, e.g. X1 (1000, 100) and X2 (1000, 80), you can ``np.hstack((X1, X2))\r\n",
        "    into (1000, 180) and feed into ``inputs``, then you can split a batch of X1 and X2.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> y = np.asarray([0,1,2,3,4,5])\r\n",
        "    >>> for batch in tl.iterate.minibatches(inputs=X, targets=y, batch_size=2, shuffle=False):\r\n",
        "    >>>     print(batch)\r\n",
        "    ... (array([['a', 'a'],\r\n",
        "    ...        ['b', 'b']],\r\n",
        "    ...         dtype='<U1'), array([0, 1]))\r\n",
        "    ... (array([['c', 'c'],\r\n",
        "    ...        ['d', 'd']],\r\n",
        "    ...         dtype='<U1'), array([2, 3]))\r\n",
        "    ... (array([['e', 'e'],\r\n",
        "    ...        ['f', 'f']],\r\n",
        "    ...         dtype='<U1'), array([4, 5]))\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    if shuffle:\r\n",
        "        indices = np.arange(len(inputs))\r\n",
        "        np.random.shuffle(indices)\r\n",
        "    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):\r\n",
        "        if shuffle:\r\n",
        "            excerpt = indices[start_idx:start_idx + batch_size]\r\n",
        "        else:\r\n",
        "            excerpt = slice(start_idx, start_idx + batch_size)\r\n",
        "        yield inputs[excerpt], targets[excerpt]\r\n",
        "\r\n",
        "def seq_minibatches(inputs, targets, batch_size, seq_length, stride=1):\r\n",
        "    \"\"\"Generate a generator that return a batch of sequence inputs and targets.\r\n",
        "    If ``batch_size = 100, seq_length = 5``, one return will have ``500`` rows (examples).\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - Synced sequence input and output.\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> y = np.asarray([0, 1, 2, 3, 4, 5])\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=y, batch_size=2, seq_length=2, stride=1):\r\n",
        "    >>>     print(batch)\r\n",
        "    ... (array([['a', 'a'],\r\n",
        "    ...        ['b', 'b'],\r\n",
        "    ...         ['b', 'b'],\r\n",
        "    ...         ['c', 'c']],\r\n",
        "    ...         dtype='<U1'), array([0, 1, 1, 2]))\r\n",
        "    ... (array([['c', 'c'],\r\n",
        "    ...         ['d', 'd'],\r\n",
        "    ...         ['d', 'd'],\r\n",
        "    ...         ['e', 'e']],\r\n",
        "    ...         dtype='<U1'), array([2, 3, 3, 4]))\r\n",
        "    ...\r\n",
        "    ...\r\n",
        "    - Many to One\r\n",
        "    >>> return_last = True\r\n",
        "    >>> num_steps = 2\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> Y = np.asarray([0,1,2,3,4,5])\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=Y, batch_size=2, seq_length=num_steps, stride=1):\r\n",
        "    >>>     x, y = batch\r\n",
        "    >>>     if return_last:\r\n",
        "    >>>         tmp_y = y.reshape((-1, num_steps) + y.shape[1:])\r\n",
        "    >>>     y = tmp_y[:, -1]\r\n",
        "    >>>     print(x, y)\r\n",
        "    ... [['a' 'a']\r\n",
        "    ... ['b' 'b']\r\n",
        "    ... ['b' 'b']\r\n",
        "    ... ['c' 'c']] [1 2]\r\n",
        "    ... [['c' 'c']\r\n",
        "    ... ['d' 'd']\r\n",
        "    ... ['d' 'd']\r\n",
        "    ... ['e' 'e']] [3 4]\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    n_loads = (batch_size * stride) + (seq_length - stride)\r\n",
        "    for start_idx in range(0, len(inputs) - n_loads + 1, (batch_size * stride)):\r\n",
        "        seq_inputs = np.zeros((batch_size, seq_length) + inputs.shape[1:],\r\n",
        "                              dtype=inputs.dtype)\r\n",
        "        seq_targets = np.zeros((batch_size, seq_length) + targets.shape[1:],\r\n",
        "                               dtype=targets.dtype)\r\n",
        "        for b_idx in xrange(batch_size):\r\n",
        "            start_seq_idx = start_idx + (b_idx * stride)\r\n",
        "            end_seq_idx = start_seq_idx + seq_length\r\n",
        "            seq_inputs[b_idx] = inputs[start_seq_idx:end_seq_idx]\r\n",
        "            seq_targets[b_idx] = targets[start_seq_idx:end_seq_idx]\r\n",
        "        flatten_inputs = seq_inputs.reshape((-1,) + inputs.shape[1:])\r\n",
        "        flatten_targets = seq_targets.reshape((-1,) + targets.shape[1:])\r\n",
        "        yield flatten_inputs, flatten_targets\r\n",
        "\r\n",
        "def seq_minibatches2(inputs, targets, batch_size, num_steps):\r\n",
        "    \"\"\"Generate a generator that iterates on two list of words. Yields (Returns) the source contexts and\r\n",
        "    the target context by the given batch_size and num_steps (sequence_length),\r\n",
        "    see ``PTB tutorial``. In TensorFlow's tutorial, this generates the batch_size pointers into the raw\r\n",
        "    PTB data, and allows minibatch iteration along these pointers.\r\n",
        "    - Hint, if the input data are images, you can modify the code as follow.\r\n",
        "    .. code-block:: python\r\n",
        "        from\r\n",
        "        data = np.zeros([batch_size, batch_len)\r\n",
        "        to\r\n",
        "        data = np.zeros([batch_size, batch_len, inputs.shape[1], inputs.shape[2], inputs.shape[3]])\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    inputs : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    targets : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    batch_size : int\r\n",
        "            the batch size.\r\n",
        "    num_steps : int\r\n",
        "            the number of unrolls. i.e. sequence_length\r\n",
        "    Yields\r\n",
        "    ------\r\n",
        "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\r\n",
        "    Raises\r\n",
        "    ------\r\n",
        "    ValueError : if batch_size or num_steps are too high.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X = [i for i in range(20)]\r\n",
        "    >>> Y = [i for i in range(20,40)]\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches2(X, Y, batch_size=2, num_steps=3):\r\n",
        "    ...     x, y = batch\r\n",
        "    ...     print(x, y)\r\n",
        "    ...\r\n",
        "    ... [[  0.   1.   2.]\r\n",
        "    ... [ 10.  11.  12.]]\r\n",
        "    ... [[ 20.  21.  22.]\r\n",
        "    ... [ 30.  31.  32.]]\r\n",
        "    ...\r\n",
        "    ... [[  3.   4.   5.]\r\n",
        "    ... [ 13.  14.  15.]]\r\n",
        "    ... [[ 23.  24.  25.]\r\n",
        "    ... [ 33.  34.  35.]]\r\n",
        "    ...\r\n",
        "    ... [[  6.   7.   8.]\r\n",
        "    ... [ 16.  17.  18.]]\r\n",
        "    ... [[ 26.  27.  28.]\r\n",
        "    ... [ 36.  37.  38.]]\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - ``tensorflow/models/rnn/ptb/reader.py``\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    data_len = len(inputs)\r\n",
        "    batch_len = data_len // batch_size\r\n",
        "    # data = np.zeros([batch_size, batch_len])\r\n",
        "    data = np.zeros((batch_size, batch_len) + inputs.shape[1:],\r\n",
        "                          dtype=inputs.dtype)\r\n",
        "    data2 = np.zeros([batch_size, batch_len])\r\n",
        "\r\n",
        "    for i in range(batch_size):\r\n",
        "        data[i] = inputs[batch_len * i:batch_len * (i + 1)]\r\n",
        "        data2[i] = targets[batch_len * i:batch_len * (i + 1)]\r\n",
        "\r\n",
        "    epoch_size = (batch_len - 1) // num_steps\r\n",
        "\r\n",
        "    if epoch_size == 0:\r\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\r\n",
        "\r\n",
        "    for i in range(epoch_size):\r\n",
        "        x = data[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        x2 = data2[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        yield (x, x2)\r\n",
        "\r\n",
        "\r\n",
        "def ptb_iterator(raw_data, batch_size, num_steps):\r\n",
        "    \"\"\"\r\n",
        "    Generate a generator that iterates on a list of words, see PTB tutorial. Yields (Returns) the source contexts and\r\n",
        "    the target context by the given batch_size and num_steps (sequence_length).\\n\r\n",
        "    see ``PTB tutorial``.\r\n",
        "    e.g. x = [0, 1, 2]  y = [1, 2, 3] , when batch_size = 1, num_steps = 3,\r\n",
        "    raw_data = [i for i in range(100)]\r\n",
        "    In TensorFlow's tutorial, this generates batch_size pointers into the raw\r\n",
        "    PTB data, and allows minibatch iteration along these pointers.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    raw_data : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    batch_size : int\r\n",
        "            the batch size.\r\n",
        "    num_steps : int\r\n",
        "            the number of unrolls. i.e. sequence_length\r\n",
        "    Yields\r\n",
        "    ------\r\n",
        "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\r\n",
        "    The second element of the tuple is the same data time-shifted to the\r\n",
        "    right by one.\r\n",
        "    Raises\r\n",
        "    ------\r\n",
        "    ValueError : if batch_size or num_steps are too high.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> train_data = [i for i in range(20)]\r\n",
        "    >>> for batch in tl.iterate.ptb_iterator(train_data, batch_size=2, num_steps=3):\r\n",
        "    >>>     x, y = batch\r\n",
        "    >>>     print(x, y)\r\n",
        "    ... [[ 0  1  2] <---x                       1st subset/ iteration\r\n",
        "    ...  [10 11 12]]\r\n",
        "    ... [[ 1  2  3] <---y\r\n",
        "    ...  [11 12 13]]\r\n",
        "    ...\r\n",
        "    ... [[ 3  4  5]  <--- 1st batch input       2nd subset/ iteration\r\n",
        "    ...  [13 14 15]] <--- 2nd batch input\r\n",
        "    ... [[ 4  5  6]  <--- 1st batch target\r\n",
        "    ...  [14 15 16]] <--- 2nd batch target\r\n",
        "    ...\r\n",
        "    ... [[ 6  7  8]                             3rd subset/ iteration\r\n",
        "    ...  [16 17 18]]\r\n",
        "    ... [[ 7  8  9]\r\n",
        "    ...  [17 18 19]]\r\n",
        "    Code References\r\n",
        "    ----------------\r\n",
        "    - ``tensorflow/models/rnn/ptb/reader.py``\r\n",
        "    \"\"\"\r\n",
        "    raw_data = np.array(raw_data, dtype=np.int32)\r\n",
        "\r\n",
        "    data_len = len(raw_data)\r\n",
        "    batch_len = data_len // batch_size\r\n",
        "    data = np.zeros([batch_size, batch_len], dtype=np.int32)\r\n",
        "    for i in range(batch_size):\r\n",
        "        data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\r\n",
        "\r\n",
        "    epoch_size = (batch_len - 1) // num_steps\r\n",
        "\r\n",
        "    if epoch_size == 0:\r\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\r\n",
        "\r\n",
        "    for i in range(epoch_size):\r\n",
        "        x = data[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        y = data[:, i*num_steps+1:(i+1)*num_steps+1]\r\n",
        "        yield (x, y)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# def minibatches_for_sequence2D(inputs, targets, batch_size, sequence_length, stride=1):\r\n",
        "#     \"\"\"\r\n",
        "#     Input a group of example in 2D numpy.array and their labels.\r\n",
        "#     Return the examples and labels by the given batchsize, sequence_length.\r\n",
        "#     Use for RNN.\r\n",
        "#\r\n",
        "#     Parameters\r\n",
        "#     ----------\r\n",
        "#     inputs : numpy.array\r\n",
        "#         (X) The input features, every row is a example.\r\n",
        "#     targets : numpy.array\r\n",
        "#         (y) The labels of inputs, every row is a example.\r\n",
        "#     batchsize : int\r\n",
        "#         The batch size must be a multiple of sequence_length: int(batch_size % sequence_length) == 0\r\n",
        "#     sequence_length : int\r\n",
        "#         The sequence length\r\n",
        "#     stride : int\r\n",
        "#         The stride step\r\n",
        "#\r\n",
        "#     Examples\r\n",
        "#     --------\r\n",
        "#     >>> sequence_length = 2\r\n",
        "#     >>> batch_size = 4\r\n",
        "#     >>> stride = 1\r\n",
        "#     >>> X_train = np.asarray([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18],[19,20,21],[22,23,24]])\r\n",
        "#     >>> y_train = np.asarray(['0','1','2','3','4','5','6','7'])\r\n",
        "#     >>> print('X_train = %s' % X_train)\r\n",
        "#     >>> print('y_train = %s' % y_train)\r\n",
        "#     >>> for batch in minibatches_for_sequence2D(X_train, y_train, batch_size=batch_size, sequence_length=sequence_length, stride=stride):\r\n",
        "#     >>>     inputs, targets = batch\r\n",
        "#     >>>     print(inputs)\r\n",
        "#     >>>     print(targets)\r\n",
        "#     ... [[ 1.  2.  3.]\r\n",
        "#     ... [ 4.  5.  6.]\r\n",
        "#     ... [ 4.  5.  6.]\r\n",
        "#     ... [ 7.  8.  9.]]\r\n",
        "#     ... [1 2]\r\n",
        "#     ... [[  4.   5.   6.]\r\n",
        "#     ... [  7.   8.   9.]\r\n",
        "#     ... [  7.   8.   9.]\r\n",
        "#     ... [ 10.  11.  12.]]\r\n",
        "#     ... [2 3]\r\n",
        "#     ... ...\r\n",
        "#     ... [[ 16.  17.  18.]\r\n",
        "#     ... [ 19.  20.  21.]\r\n",
        "#     ... [ 19.  20.  21.]\r\n",
        "#     ... [ 22.  23.  24.]]\r\n",
        "#     ... [6 7]\r\n",
        "#     \"\"\"\r\n",
        "#     print('len(targets)=%d batch_size=%d sequence_length=%d stride=%d' % (len(targets), batch_size, sequence_length, stride))\r\n",
        "#     assert len(inputs) == len(targets), '1 feature vector have 1 target vector/value' #* sequence_length\r\n",
        "#     # assert int(batch_size % sequence_length) == 0, 'batch_size % sequence_length must == 0\\\r\n",
        "#     # batch_size is number of examples rather than number of targets'\r\n",
        "#\r\n",
        "#     # print(inputs.shape, len(inputs), len(inputs[0]))\r\n",
        "#\r\n",
        "#     n_targets = int(batch_size/sequence_length)\r\n",
        "#     # n_targets = int(np.ceil(batch_size/sequence_length))\r\n",
        "#     X = np.empty(shape=(0,len(inputs[0])), dtype=np.float32)\r\n",
        "#     y = np.zeros(shape=(1, n_targets), dtype=np.int32)\r\n",
        "#\r\n",
        "#     for idx in range(sequence_length, len(inputs), stride):  # go through all example during 1 epoch\r\n",
        "#         for n in range(n_targets):   # for num of target\r\n",
        "#             X = np.concatenate((X, inputs[idx-sequence_length+n:idx+n]))\r\n",
        "#             y[0][n] = targets[idx-1+n]\r\n",
        "#             # y = np.vstack((y, targets[idx-1+n]))\r\n",
        "#         yield X, y[0]\r\n",
        "#         X = np.empty(shape=(0,len(inputs[0])))\r\n",
        "#         # y = np.empty(shape=(1,0))\r\n",
        "#\r\n",
        "#\r\n",
        "# def minibatches_for_sequence4D(inputs, targets, batch_size, sequence_length, stride=1): #\r\n",
        "#     \"\"\"\r\n",
        "#     Input a group of example in 4D numpy.array and their labels.\r\n",
        "#     Return the examples and labels by the given batchsize, sequence_length.\r\n",
        "#     Use for RNN.\r\n",
        "#\r\n",
        "#     Parameters\r\n",
        "#     ----------\r\n",
        "#     inputs : numpy.array\r\n",
        "#         (X) The input features, every row is a example.\r\n",
        "#     targets : numpy.array\r\n",
        "#         (y) The labels of inputs, every row is a example.\r\n",
        "#     batchsize : int\r\n",
        "#         The batch size must be a multiple of sequence_length: int(batch_size % sequence_length) == 0\r\n",
        "#     sequence_length : int\r\n",
        "#         The sequence length\r\n",
        "#     stride : int\r\n",
        "#         The stride step\r\n",
        "#\r\n",
        "#     Examples\r\n",
        "#     --------\r\n",
        "#     >>> sequence_length = 2\r\n",
        "#     >>> batch_size = 2\r\n",
        "#     >>> stride = 1\r\n",
        "#     >>> X_train = np.asarray([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18],[19,20,21],[22,23,24]])\r\n",
        "#     >>> y_train = np.asarray(['0','1','2','3','4','5','6','7'])\r\n",
        "#     >>> X_train = np.expand_dims(X_train, axis=1)\r\n",
        "#     >>> X_train = np.expand_dims(X_train, axis=3)\r\n",
        "#     >>> for batch in minibatches_for_sequence4D(X_train, y_train, batch_size=batch_size, sequence_length=sequence_length, stride=stride):\r\n",
        "#     >>>     inputs, targets = batch\r\n",
        "#     >>>     print(inputs)\r\n",
        "#     >>>     print(targets)\r\n",
        "#     ... [[[[ 1.]\r\n",
        "#     ...    [ 2.]\r\n",
        "#     ...    [ 3.]]]\r\n",
        "#     ... [[[ 4.]\r\n",
        "#     ...   [ 5.]\r\n",
        "#     ...   [ 6.]]]]\r\n",
        "#     ... [1]\r\n",
        "#     ... [[[[ 4.]\r\n",
        "#     ...    [ 5.]\r\n",
        "#     ...    [ 6.]]]\r\n",
        "#     ... [[[ 7.]\r\n",
        "#     ...   [ 8.]\r\n",
        "#     ...   [ 9.]]]]\r\n",
        "#     ... [2]\r\n",
        "#     ... ...\r\n",
        "#     ... [[[[ 19.]\r\n",
        "#     ...    [ 20.]\r\n",
        "#     ...    [ 21.]]]\r\n",
        "#     ... [[[ 22.]\r\n",
        "#     ...   [ 23.]\r\n",
        "#     ...   [ 24.]]]]\r\n",
        "#     ... [7]\r\n",
        "#     \"\"\"\r\n",
        "#     print('len(targets)=%d batch_size=%d sequence_length=%d stride=%d' % (len(targets), batch_size, sequence_length, stride))\r\n",
        "#     assert len(inputs) == len(targets), '1 feature vector have 1 target vector/value' #* sequence_length\r\n",
        "#     # assert int(batch_size % sequence_length) == 0, 'in LSTM, batch_size % sequence_length must == 0\\\r\n",
        "#     # batch_size is number of X_train rather than number of targets'\r\n",
        "#     assert stride >= 1, 'stride must be >=1, at least move 1 step for each iternation'\r\n",
        "#\r\n",
        "#     n_example, n_channels, width, height = inputs.shape\r\n",
        "#     print('n_example=%d n_channels=%d width=%d height=%d' % (n_example, n_channels, width, height))\r\n",
        "#\r\n",
        "#     n_targets = int(np.ceil(batch_size/sequence_length)) # 实际为 batchsize/sequence_length + 1\r\n",
        "#     print(n_targets)\r\n",
        "#     X = np.zeros(shape=(batch_size, n_channels, width, height), dtype=np.float32)\r\n",
        "#     # X = np.zeros(shape=(n_targets, sequence_length, n_channels, width, height), dtype=np.float32)\r\n",
        "#     y = np.zeros(shape=(1,n_targets), dtype=np.int32)\r\n",
        "#     # y = np.empty(shape=(0,1), dtype=np.float32)\r\n",
        "#     # time.sleep(2)\r\n",
        "#     for idx in range(sequence_length, n_example-n_targets+2, stride):  # go through all example during 1 epoch\r\n",
        "#         for n in range(n_targets):   # for num of target\r\n",
        "#             # print(idx+n, inputs[idx-sequence_length+n : idx+n].shape)\r\n",
        "#             X[n*sequence_length : (n+1)*sequence_length] = inputs[idx+n-sequence_length : idx+n]\r\n",
        "#             # X[n] = inputs[idx-sequence_length+n:idx+n]\r\n",
        "#             y[0][n] = targets[idx+n-1]\r\n",
        "#             # y = np.vstack((y, targets[idx-1+n]))\r\n",
        "#         # y = targets[idx: idx+n_targets]\r\n",
        "#         yield X, y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heroC4SDeX0E"
      },
      "source": [
        "import numpy as np\r\n",
        "from six.moves import xrange\r\n",
        "\r\n",
        "def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):\r\n",
        "    \"\"\"Generate a generator that input a group of example in numpy.array and\r\n",
        "    their labels, return the examples and labels by the given batchsize.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    inputs : numpy.array\r\n",
        "        (X) The input features, every row is a example.\r\n",
        "    targets : numpy.array\r\n",
        "        (y) The labels of inputs, every row is a example.\r\n",
        "    batch_size : int\r\n",
        "        The batch size.\r\n",
        "    shuffle : boolean\r\n",
        "        Indicating whether to use a shuffling queue, shuffle the dataset before return.\r\n",
        "    Hints\r\n",
        "    -------\r\n",
        "    - If you have two inputs, e.g. X1 (1000, 100) and X2 (1000, 80), you can ``np.hstack((X1, X2))\r\n",
        "    into (1000, 180) and feed into ``inputs``, then you can split a batch of X1 and X2.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> y = np.asarray([0,1,2,3,4,5])\r\n",
        "    >>> for batch in tl.iterate.minibatches(inputs=X, targets=y, batch_size=2, shuffle=False):\r\n",
        "    >>>     print(batch)\r\n",
        "    ... (array([['a', 'a'],\r\n",
        "    ...        ['b', 'b']],\r\n",
        "    ...         dtype='<U1'), array([0, 1]))\r\n",
        "    ... (array([['c', 'c'],\r\n",
        "    ...        ['d', 'd']],\r\n",
        "    ...         dtype='<U1'), array([2, 3]))\r\n",
        "    ... (array([['e', 'e'],\r\n",
        "    ...        ['f', 'f']],\r\n",
        "    ...         dtype='<U1'), array([4, 5]))\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    if shuffle:\r\n",
        "        indices = np.arange(len(inputs))\r\n",
        "        np.random.shuffle(indices)\r\n",
        "    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):\r\n",
        "        if shuffle:\r\n",
        "            excerpt = indices[start_idx:start_idx + batch_size]\r\n",
        "        else:\r\n",
        "            excerpt = slice(start_idx, start_idx + batch_size)\r\n",
        "        yield inputs[excerpt], targets[excerpt]\r\n",
        "\r\n",
        "def seq_minibatches(inputs, targets, batch_size, seq_length, stride=1):\r\n",
        "    \"\"\"Generate a generator that return a batch of sequence inputs and targets.\r\n",
        "    If ``batch_size = 100, seq_length = 5``, one return will have ``500`` rows (examples).\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - Synced sequence input and output.\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> y = np.asarray([0, 1, 2, 3, 4, 5])\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=y, batch_size=2, seq_length=2, stride=1):\r\n",
        "    >>>     print(batch)\r\n",
        "    ... (array([['a', 'a'],\r\n",
        "    ...        ['b', 'b'],\r\n",
        "    ...         ['b', 'b'],\r\n",
        "    ...         ['c', 'c']],\r\n",
        "    ...         dtype='<U1'), array([0, 1, 1, 2]))\r\n",
        "    ... (array([['c', 'c'],\r\n",
        "    ...         ['d', 'd'],\r\n",
        "    ...         ['d', 'd'],\r\n",
        "    ...         ['e', 'e']],\r\n",
        "    ...         dtype='<U1'), array([2, 3, 3, 4]))\r\n",
        "    ...\r\n",
        "    ...\r\n",
        "    - Many to One\r\n",
        "    >>> return_last = True\r\n",
        "    >>> num_steps = 2\r\n",
        "    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\r\n",
        "    >>> Y = np.asarray([0,1,2,3,4,5])\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=Y, batch_size=2, seq_length=num_steps, stride=1):\r\n",
        "    >>>     x, y = batch\r\n",
        "    >>>     if return_last:\r\n",
        "    >>>         tmp_y = y.reshape((-1, num_steps) + y.shape[1:])\r\n",
        "    >>>     y = tmp_y[:, -1]\r\n",
        "    >>>     print(x, y)\r\n",
        "    ... [['a' 'a']\r\n",
        "    ... ['b' 'b']\r\n",
        "    ... ['b' 'b']\r\n",
        "    ... ['c' 'c']] [1 2]\r\n",
        "    ... [['c' 'c']\r\n",
        "    ... ['d' 'd']\r\n",
        "    ... ['d' 'd']\r\n",
        "    ... ['e' 'e']] [3 4]\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    n_loads = (batch_size * stride) + (seq_length - stride)\r\n",
        "    for start_idx in range(0, len(inputs) - n_loads + 1, (batch_size * stride)):\r\n",
        "        seq_inputs = np.zeros((batch_size, seq_length) + inputs.shape[1:],\r\n",
        "                              dtype=inputs.dtype)\r\n",
        "        seq_targets = np.zeros((batch_size, seq_length) + targets.shape[1:],\r\n",
        "                               dtype=targets.dtype)\r\n",
        "        for b_idx in xrange(batch_size):\r\n",
        "            start_seq_idx = start_idx + (b_idx * stride)\r\n",
        "            end_seq_idx = start_seq_idx + seq_length\r\n",
        "            seq_inputs[b_idx] = inputs[start_seq_idx:end_seq_idx]\r\n",
        "            seq_targets[b_idx] = targets[start_seq_idx:end_seq_idx]\r\n",
        "        flatten_inputs = seq_inputs.reshape((-1,) + inputs.shape[1:])\r\n",
        "        flatten_targets = seq_targets.reshape((-1,) + targets.shape[1:])\r\n",
        "        yield flatten_inputs, flatten_targets\r\n",
        "\r\n",
        "def seq_minibatches2(inputs, targets, batch_size, num_steps):\r\n",
        "    \"\"\"Generate a generator that iterates on two list of words. Yields (Returns) the source contexts and\r\n",
        "    the target context by the given batch_size and num_steps (sequence_length),\r\n",
        "    see ``PTB tutorial``. In TensorFlow's tutorial, this generates the batch_size pointers into the raw\r\n",
        "    PTB data, and allows minibatch iteration along these pointers.\r\n",
        "    - Hint, if the input data are images, you can modify the code as follow.\r\n",
        "    .. code-block:: python\r\n",
        "        from\r\n",
        "        data = np.zeros([batch_size, batch_len)\r\n",
        "        to\r\n",
        "        data = np.zeros([batch_size, batch_len, inputs.shape[1], inputs.shape[2], inputs.shape[3]])\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    inputs : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    targets : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    batch_size : int\r\n",
        "            the batch size.\r\n",
        "    num_steps : int\r\n",
        "            the number of unrolls. i.e. sequence_length\r\n",
        "    Yields\r\n",
        "    ------\r\n",
        "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\r\n",
        "    Raises\r\n",
        "    ------\r\n",
        "    ValueError : if batch_size or num_steps are too high.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X = [i for i in range(20)]\r\n",
        "    >>> Y = [i for i in range(20,40)]\r\n",
        "    >>> for batch in tl.iterate.seq_minibatches2(X, Y, batch_size=2, num_steps=3):\r\n",
        "    ...     x, y = batch\r\n",
        "    ...     print(x, y)\r\n",
        "    ...\r\n",
        "    ... [[  0.   1.   2.]\r\n",
        "    ... [ 10.  11.  12.]]\r\n",
        "    ... [[ 20.  21.  22.]\r\n",
        "    ... [ 30.  31.  32.]]\r\n",
        "    ...\r\n",
        "    ... [[  3.   4.   5.]\r\n",
        "    ... [ 13.  14.  15.]]\r\n",
        "    ... [[ 23.  24.  25.]\r\n",
        "    ... [ 33.  34.  35.]]\r\n",
        "    ...\r\n",
        "    ... [[  6.   7.   8.]\r\n",
        "    ... [ 16.  17.  18.]]\r\n",
        "    ... [[ 26.  27.  28.]\r\n",
        "    ... [ 36.  37.  38.]]\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - ``tensorflow/models/rnn/ptb/reader.py``\r\n",
        "    \"\"\"\r\n",
        "    assert len(inputs) == len(targets)\r\n",
        "    data_len = len(inputs)\r\n",
        "    batch_len = data_len // batch_size\r\n",
        "    # data = np.zeros([batch_size, batch_len])\r\n",
        "    data = np.zeros((batch_size, batch_len) + inputs.shape[1:],\r\n",
        "                          dtype=inputs.dtype)\r\n",
        "    data2 = np.zeros([batch_size, batch_len])\r\n",
        "\r\n",
        "    for i in range(batch_size):\r\n",
        "        data[i] = inputs[batch_len * i:batch_len * (i + 1)]\r\n",
        "        data2[i] = targets[batch_len * i:batch_len * (i + 1)]\r\n",
        "\r\n",
        "    epoch_size = (batch_len - 1) // num_steps\r\n",
        "\r\n",
        "    if epoch_size == 0:\r\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\r\n",
        "\r\n",
        "    for i in range(epoch_size):\r\n",
        "        x = data[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        x2 = data2[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        yield (x, x2)\r\n",
        "\r\n",
        "\r\n",
        "def ptb_iterator(raw_data, batch_size, num_steps):\r\n",
        "    \"\"\"\r\n",
        "    Generate a generator that iterates on a list of words, see PTB tutorial. Yields (Returns) the source contexts and\r\n",
        "    the target context by the given batch_size and num_steps (sequence_length).\\n\r\n",
        "    see ``PTB tutorial``.\r\n",
        "    e.g. x = [0, 1, 2]  y = [1, 2, 3] , when batch_size = 1, num_steps = 3,\r\n",
        "    raw_data = [i for i in range(100)]\r\n",
        "    In TensorFlow's tutorial, this generates batch_size pointers into the raw\r\n",
        "    PTB data, and allows minibatch iteration along these pointers.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    raw_data : a list\r\n",
        "            the context in list format; note that context usually be\r\n",
        "            represented by splitting by space, and then convert to unique\r\n",
        "            word IDs.\r\n",
        "    batch_size : int\r\n",
        "            the batch size.\r\n",
        "    num_steps : int\r\n",
        "            the number of unrolls. i.e. sequence_length\r\n",
        "    Yields\r\n",
        "    ------\r\n",
        "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\r\n",
        "    The second element of the tuple is the same data time-shifted to the\r\n",
        "    right by one.\r\n",
        "    Raises\r\n",
        "    ------\r\n",
        "    ValueError : if batch_size or num_steps are too high.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> train_data = [i for i in range(20)]\r\n",
        "    >>> for batch in tl.iterate.ptb_iterator(train_data, batch_size=2, num_steps=3):\r\n",
        "    >>>     x, y = batch\r\n",
        "    >>>     print(x, y)\r\n",
        "    ... [[ 0  1  2] <---x                       1st subset/ iteration\r\n",
        "    ...  [10 11 12]]\r\n",
        "    ... [[ 1  2  3] <---y\r\n",
        "    ...  [11 12 13]]\r\n",
        "    ...\r\n",
        "    ... [[ 3  4  5]  <--- 1st batch input       2nd subset/ iteration\r\n",
        "    ...  [13 14 15]] <--- 2nd batch input\r\n",
        "    ... [[ 4  5  6]  <--- 1st batch target\r\n",
        "    ...  [14 15 16]] <--- 2nd batch target\r\n",
        "    ...\r\n",
        "    ... [[ 6  7  8]                             3rd subset/ iteration\r\n",
        "    ...  [16 17 18]]\r\n",
        "    ... [[ 7  8  9]\r\n",
        "    ...  [17 18 19]]\r\n",
        "    Code References\r\n",
        "    ----------------\r\n",
        "    - ``tensorflow/models/rnn/ptb/reader.py``\r\n",
        "    \"\"\"\r\n",
        "    raw_data = np.array(raw_data, dtype=np.int32)\r\n",
        "\r\n",
        "    data_len = len(raw_data)\r\n",
        "    batch_len = data_len // batch_size\r\n",
        "    data = np.zeros([batch_size, batch_len], dtype=np.int32)\r\n",
        "    for i in range(batch_size):\r\n",
        "        data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\r\n",
        "\r\n",
        "    epoch_size = (batch_len - 1) // num_steps\r\n",
        "\r\n",
        "    if epoch_size == 0:\r\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\r\n",
        "\r\n",
        "    for i in range(epoch_size):\r\n",
        "        x = data[:, i*num_steps:(i+1)*num_steps]\r\n",
        "        y = data[:, i*num_steps+1:(i+1)*num_steps+1]\r\n",
        "        yield (x, y)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# def minibatches_for_sequence2D(inputs, targets, batch_size, sequence_length, stride=1):\r\n",
        "#     \"\"\"\r\n",
        "#     Input a group of example in 2D numpy.array and their labels.\r\n",
        "#     Return the examples and labels by the given batchsize, sequence_length.\r\n",
        "#     Use for RNN.\r\n",
        "#\r\n",
        "#     Parameters\r\n",
        "#     ----------\r\n",
        "#     inputs : numpy.array\r\n",
        "#         (X) The input features, every row is a example.\r\n",
        "#     targets : numpy.array\r\n",
        "#         (y) The labels of inputs, every row is a example.\r\n",
        "#     batchsize : int\r\n",
        "#         The batch size must be a multiple of sequence_length: int(batch_size % sequence_length) == 0\r\n",
        "#     sequence_length : int\r\n",
        "#         The sequence length\r\n",
        "#     stride : int\r\n",
        "#         The stride step\r\n",
        "#\r\n",
        "#     Examples\r\n",
        "#     --------\r\n",
        "#     >>> sequence_length = 2\r\n",
        "#     >>> batch_size = 4\r\n",
        "#     >>> stride = 1\r\n",
        "#     >>> X_train = np.asarray([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18],[19,20,21],[22,23,24]])\r\n",
        "#     >>> y_train = np.asarray(['0','1','2','3','4','5','6','7'])\r\n",
        "#     >>> print('X_train = %s' % X_train)\r\n",
        "#     >>> print('y_train = %s' % y_train)\r\n",
        "#     >>> for batch in minibatches_for_sequence2D(X_train, y_train, batch_size=batch_size, sequence_length=sequence_length, stride=stride):\r\n",
        "#     >>>     inputs, targets = batch\r\n",
        "#     >>>     print(inputs)\r\n",
        "#     >>>     print(targets)\r\n",
        "#     ... [[ 1.  2.  3.]\r\n",
        "#     ... [ 4.  5.  6.]\r\n",
        "#     ... [ 4.  5.  6.]\r\n",
        "#     ... [ 7.  8.  9.]]\r\n",
        "#     ... [1 2]\r\n",
        "#     ... [[  4.   5.   6.]\r\n",
        "#     ... [  7.   8.   9.]\r\n",
        "#     ... [  7.   8.   9.]\r\n",
        "#     ... [ 10.  11.  12.]]\r\n",
        "#     ... [2 3]\r\n",
        "#     ... ...\r\n",
        "#     ... [[ 16.  17.  18.]\r\n",
        "#     ... [ 19.  20.  21.]\r\n",
        "#     ... [ 19.  20.  21.]\r\n",
        "#     ... [ 22.  23.  24.]]\r\n",
        "#     ... [6 7]\r\n",
        "#     \"\"\"\r\n",
        "#     print('len(targets)=%d batch_size=%d sequence_length=%d stride=%d' % (len(targets), batch_size, sequence_length, stride))\r\n",
        "#     assert len(inputs) == len(targets), '1 feature vector have 1 target vector/value' #* sequence_length\r\n",
        "#     # assert int(batch_size % sequence_length) == 0, 'batch_size % sequence_length must == 0\\\r\n",
        "#     # batch_size is number of examples rather than number of targets'\r\n",
        "#\r\n",
        "#     # print(inputs.shape, len(inputs), len(inputs[0]))\r\n",
        "#\r\n",
        "#     n_targets = int(batch_size/sequence_length)\r\n",
        "#     # n_targets = int(np.ceil(batch_size/sequence_length))\r\n",
        "#     X = np.empty(shape=(0,len(inputs[0])), dtype=np.float32)\r\n",
        "#     y = np.zeros(shape=(1, n_targets), dtype=np.int32)\r\n",
        "#\r\n",
        "#     for idx in range(sequence_length, len(inputs), stride):  # go through all example during 1 epoch\r\n",
        "#         for n in range(n_targets):   # for num of target\r\n",
        "#             X = np.concatenate((X, inputs[idx-sequence_length+n:idx+n]))\r\n",
        "#             y[0][n] = targets[idx-1+n]\r\n",
        "#             # y = np.vstack((y, targets[idx-1+n]))\r\n",
        "#         yield X, y[0]\r\n",
        "#         X = np.empty(shape=(0,len(inputs[0])))\r\n",
        "#         # y = np.empty(shape=(1,0))\r\n",
        "#\r\n",
        "#\r\n",
        "# def minibatches_for_sequence4D(inputs, targets, batch_size, sequence_length, stride=1): #\r\n",
        "#     \"\"\"\r\n",
        "#     Input a group of example in 4D numpy.array and their labels.\r\n",
        "#     Return the examples and labels by the given batchsize, sequence_length.\r\n",
        "#     Use for RNN.\r\n",
        "#\r\n",
        "#     Parameters\r\n",
        "#     ----------\r\n",
        "#     inputs : numpy.array\r\n",
        "#         (X) The input features, every row is a example.\r\n",
        "#     targets : numpy.array\r\n",
        "#         (y) The labels of inputs, every row is a example.\r\n",
        "#     batchsize : int\r\n",
        "#         The batch size must be a multiple of sequence_length: int(batch_size % sequence_length) == 0\r\n",
        "#     sequence_length : int\r\n",
        "#         The sequence length\r\n",
        "#     stride : int\r\n",
        "#         The stride step\r\n",
        "#\r\n",
        "#     Examples\r\n",
        "#     --------\r\n",
        "#     >>> sequence_length = 2\r\n",
        "#     >>> batch_size = 2\r\n",
        "#     >>> stride = 1\r\n",
        "#     >>> X_train = np.asarray([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,14,15],[16,17,18],[19,20,21],[22,23,24]])\r\n",
        "#     >>> y_train = np.asarray(['0','1','2','3','4','5','6','7'])\r\n",
        "#     >>> X_train = np.expand_dims(X_train, axis=1)\r\n",
        "#     >>> X_train = np.expand_dims(X_train, axis=3)\r\n",
        "#     >>> for batch in minibatches_for_sequence4D(X_train, y_train, batch_size=batch_size, sequence_length=sequence_length, stride=stride):\r\n",
        "#     >>>     inputs, targets = batch\r\n",
        "#     >>>     print(inputs)\r\n",
        "#     >>>     print(targets)\r\n",
        "#     ... [[[[ 1.]\r\n",
        "#     ...    [ 2.]\r\n",
        "#     ...    [ 3.]]]\r\n",
        "#     ... [[[ 4.]\r\n",
        "#     ...   [ 5.]\r\n",
        "#     ...   [ 6.]]]]\r\n",
        "#     ... [1]\r\n",
        "#     ... [[[[ 4.]\r\n",
        "#     ...    [ 5.]\r\n",
        "#     ...    [ 6.]]]\r\n",
        "#     ... [[[ 7.]\r\n",
        "#     ...   [ 8.]\r\n",
        "#     ...   [ 9.]]]]\r\n",
        "#     ... [2]\r\n",
        "#     ... ...\r\n",
        "#     ... [[[[ 19.]\r\n",
        "#     ...    [ 20.]\r\n",
        "#     ...    [ 21.]]]\r\n",
        "#     ... [[[ 22.]\r\n",
        "#     ...   [ 23.]\r\n",
        "#     ...   [ 24.]]]]\r\n",
        "#     ... [7]\r\n",
        "#     \"\"\"\r\n",
        "#     print('len(targets)=%d batch_size=%d sequence_length=%d stride=%d' % (len(targets), batch_size, sequence_length, stride))\r\n",
        "#     assert len(inputs) == len(targets), '1 feature vector have 1 target vector/value' #* sequence_length\r\n",
        "#     # assert int(batch_size % sequence_length) == 0, 'in LSTM, batch_size % sequence_length must == 0\\\r\n",
        "#     # batch_size is number of X_train rather than number of targets'\r\n",
        "#     assert stride >= 1, 'stride must be >=1, at least move 1 step for each iternation'\r\n",
        "#\r\n",
        "#     n_example, n_channels, width, height = inputs.shape\r\n",
        "#     print('n_example=%d n_channels=%d width=%d height=%d' % (n_example, n_channels, width, height))\r\n",
        "#\r\n",
        "#     n_targets = int(np.ceil(batch_size/sequence_length)) # 实际为 batchsize/sequence_length + 1\r\n",
        "#     print(n_targets)\r\n",
        "#     X = np.zeros(shape=(batch_size, n_channels, width, height), dtype=np.float32)\r\n",
        "#     # X = np.zeros(shape=(n_targets, sequence_length, n_channels, width, height), dtype=np.float32)\r\n",
        "#     y = np.zeros(shape=(1,n_targets), dtype=np.int32)\r\n",
        "#     # y = np.empty(shape=(0,1), dtype=np.float32)\r\n",
        "#     # time.sleep(2)\r\n",
        "#     for idx in range(sequence_length, n_example-n_targets+2, stride):  # go through all example during 1 epoch\r\n",
        "#         for n in range(n_targets):   # for num of target\r\n",
        "#             # print(idx+n, inputs[idx-sequence_length+n : idx+n].shape)\r\n",
        "#             X[n*sequence_length : (n+1)*sequence_length] = inputs[idx+n-sequence_length : idx+n]\r\n",
        "#             # X[n] = inputs[idx-sequence_length+n:idx+n]\r\n",
        "#             y[0][n] = targets[idx+n-1]\r\n",
        "#             # y = np.vstack((y, targets[idx-1+n]))\r\n",
        "#         # y = targets[idx: idx+n_targets]\r\n",
        "#         yield X, y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_2zxnVheZcD"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "from sys import platform as _platform\r\n",
        "import collections\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "from six.moves import xrange\r\n",
        "from tensorflow.python.platform import gfile\r\n",
        "import re\r\n",
        "\r\n",
        "## Iteration functions\r\n",
        "def generate_skip_gram_batch(data, batch_size, num_skips, skip_window, data_index=0):\r\n",
        "    \"\"\"Generate a training batch for the Skip-Gram model.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    data : a list\r\n",
        "        To present context.\r\n",
        "    batch_size : an int\r\n",
        "        Batch size to return.\r\n",
        "    num_skips : an int\r\n",
        "        How many times to reuse an input to generate a label.\r\n",
        "    skip_window : an int\r\n",
        "        How many words to consider left and right.\r\n",
        "    data_index : an int\r\n",
        "        Index of the context location.\r\n",
        "        without using yield, this code use data_index to instead.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    batch : a list\r\n",
        "        Inputs\r\n",
        "    labels : a list\r\n",
        "        Labels\r\n",
        "    data_index : an int\r\n",
        "        Index of the context location.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> Setting num_skips=2, skip_window=1, use the right and left words.\r\n",
        "    >>> In the same way, num_skips=4, skip_window=2 means use the nearby 4 words.\r\n",
        "    >>> data = [1,2,3,4,5,6,7,8,9,10,11]\r\n",
        "    >>> batch, labels, data_index = tl.nlp.generate_skip_gram_batch(data=data, batch_size=8, num_skips=2, skip_window=1, data_index=0)\r\n",
        "    >>> print(batch)\r\n",
        "    ... [2 2 3 3 4 4 5 5]\r\n",
        "    >>> print(labels)\r\n",
        "    ... [[3]\r\n",
        "    ... [1]\r\n",
        "    ... [4]\r\n",
        "    ... [2]\r\n",
        "    ... [5]\r\n",
        "    ... [3]\r\n",
        "    ... [4]\r\n",
        "    ... [6]]\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `TensorFlow word2vec tutorial <https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html#vector-representations-of-words>`_\r\n",
        "    \"\"\"\r\n",
        "    # global data_index   # you can put data_index outside the function, then\r\n",
        "    #       modify the global data_index in the function without return it.\r\n",
        "    # note: without using yield, this code use data_index to instead.\r\n",
        "    assert batch_size % num_skips == 0\r\n",
        "    assert num_skips <= 2 * skip_window\r\n",
        "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\r\n",
        "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\r\n",
        "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\r\n",
        "    buffer = collections.deque(maxlen=span)\r\n",
        "    for _ in range(span):\r\n",
        "        buffer.append(data[data_index])\r\n",
        "        data_index = (data_index + 1) % len(data)\r\n",
        "    for i in range(batch_size // num_skips):\r\n",
        "        target = skip_window  # target label at the center of the buffer\r\n",
        "        targets_to_avoid = [ skip_window ]\r\n",
        "        for j in range(num_skips):\r\n",
        "            while target in targets_to_avoid:\r\n",
        "                target = random.randint(0, span - 1)\r\n",
        "            targets_to_avoid.append(target)\r\n",
        "            batch[i * num_skips + j] = buffer[skip_window]\r\n",
        "            labels[i * num_skips + j, 0] = buffer[target]\r\n",
        "        buffer.append(data[data_index])\r\n",
        "        data_index = (data_index + 1) % len(data)\r\n",
        "    return batch, labels, data_index\r\n",
        "\r\n",
        "\r\n",
        "## Sampling functions\r\n",
        "def sample(a=[], temperature=1.0):\r\n",
        "    \"\"\"Sample an index from a probability array.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    a : a list\r\n",
        "        List of probabilities.\r\n",
        "    temperature : float or None\r\n",
        "        The higher the more uniform.\\n\r\n",
        "        When a = [0.1, 0.2, 0.7],\\n\r\n",
        "            temperature = 0.7, the distribution will be sharpen [ 0.05048273  0.13588945  0.81362782]\\n\r\n",
        "            temperature = 1.0, the distribution will be the same [0.1    0.2    0.7]\\n\r\n",
        "            temperature = 1.5, the distribution will be filtered [ 0.16008435  0.25411807  0.58579758]\\n\r\n",
        "        If None, it will be ``np.argmax(a)``\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    No matter what is the temperature and input list, the sum of all probabilities will be one.\r\n",
        "    Even if input list = [1, 100, 200], the sum of all probabilities will still be one.\r\n",
        "    For large vocabulary_size, choice a higher temperature to avoid error.\r\n",
        "    \"\"\"\r\n",
        "    b = np.copy(a)\r\n",
        "    try:\r\n",
        "        if temperature == 1:\r\n",
        "            return np.argmax(np.random.multinomial(1, a, 1))\r\n",
        "        if temperature is None:\r\n",
        "            return np.argmax(a)\r\n",
        "        else:\r\n",
        "            a = np.log(a) / temperature\r\n",
        "            a = np.exp(a) / np.sum(np.exp(a))\r\n",
        "            return np.argmax(np.random.multinomial(1, a, 1))\r\n",
        "    except:\r\n",
        "        # np.set_printoptions(threshold=np.nan)\r\n",
        "        # print(a)\r\n",
        "        # print(np.sum(a))\r\n",
        "        # print(np.max(a))\r\n",
        "        # print(np.min(a))\r\n",
        "        # exit()\r\n",
        "        message = \"For large vocabulary_size, choice a higher temperature\\\r\n",
        "         to avoid log error. Hint : use ``sample_top``. \"\r\n",
        "        warnings.warn(message, Warning)\r\n",
        "        # print(a)\r\n",
        "        # print(b)\r\n",
        "        return np.argmax(np.random.multinomial(1, b, 1))\r\n",
        "\r\n",
        "def sample_top(a=[], top_k=10):\r\n",
        "    \"\"\"Sample from ``top_k`` probabilities.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    a : a list\r\n",
        "        List of probabilities.\r\n",
        "    top_k : int\r\n",
        "        Number of candidates to be considered.\r\n",
        "    \"\"\"\r\n",
        "    idx = np.argpartition(a, -top_k)[-top_k:]\r\n",
        "    probs = a[idx]\r\n",
        "    # print(\"new\", probs)\r\n",
        "    probs = probs / np.sum(probs)\r\n",
        "    choice = np.random.choice(idx, p=probs)\r\n",
        "    return choice\r\n",
        "    ## old implementation\r\n",
        "    # a = np.array(a)\r\n",
        "    # idx = np.argsort(a)[::-1]\r\n",
        "    # idx = idx[:top_k]\r\n",
        "    # # a = a[idx]\r\n",
        "    # probs = a[idx]\r\n",
        "    # print(\"prev\", probs)\r\n",
        "    # # probs = probs / np.sum(probs)\r\n",
        "    # # choice = np.random.choice(idx, p=probs)\r\n",
        "    # # return choice\r\n",
        "\r\n",
        "\r\n",
        "## Vector representations of words (Advanced)  UNDOCUMENT\r\n",
        "class SimpleVocabulary(object):\r\n",
        "  \"\"\"Simple vocabulary wrapper, see create_vocab().\r\n",
        "  Parameters\r\n",
        "  ------------\r\n",
        "  vocab : A dictionary of word to word_id.\r\n",
        "  unk_id : Id of the special 'unknown' word.\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  def __init__(self, vocab, unk_id):\r\n",
        "    \"\"\"Initializes the vocabulary.\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "    self._vocab = vocab\r\n",
        "    self._unk_id = unk_id\r\n",
        "\r\n",
        "  def word_to_id(self, word):\r\n",
        "    \"\"\"Returns the integer id of a word string.\"\"\"\r\n",
        "    if word in self._vocab:\r\n",
        "      return self._vocab[word]\r\n",
        "    else:\r\n",
        "      return self._unk_id\r\n",
        "\r\n",
        "class Vocabulary(object):\r\n",
        "  \"\"\"Create Vocabulary class from a given vocabulary and its id-word, word-id convert,\r\n",
        "  see create_vocab() and ``tutorial_tfrecord3.py``.\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  vocab_file : File containing the vocabulary, where the words are the first\r\n",
        "        whitespace-separated token on each line (other tokens are ignored) and\r\n",
        "        the word ids are the corresponding line numbers.\r\n",
        "  start_word : Special word denoting sentence start.\r\n",
        "  end_word : Special word denoting sentence end.\r\n",
        "  unk_word : Special word denoting unknown words.\r\n",
        "  Properties\r\n",
        "  ------------\r\n",
        "  vocab : a dictionary from word to id.\r\n",
        "  reverse_vocab : a list from id to word.\r\n",
        "  start_id : int of start id\r\n",
        "  end_id : int of end id\r\n",
        "  unk_id : int of unk id\r\n",
        "  pad_id : int of padding id\r\n",
        "  Vocab_files\r\n",
        "  -------------\r\n",
        "  >>> Look as follow, includes `start_word` , `end_word` but no `unk_word` .\r\n",
        "  >>> a 969108\r\n",
        "  >>> <S> 586368\r\n",
        "  >>> </S> 586368\r\n",
        "  >>> . 440479\r\n",
        "  >>> on 213612\r\n",
        "  >>> of 202290\r\n",
        "  >>> the 196219\r\n",
        "  >>> in 182598\r\n",
        "  >>> with 152984\r\n",
        "  >>> and 139109\r\n",
        "  >>> is 97322\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  def __init__(self,\r\n",
        "               vocab_file,\r\n",
        "               start_word=\"<S>\",\r\n",
        "               end_word=\"</S>\",\r\n",
        "               unk_word=\"<UNK>\",\r\n",
        "               pad_word=\"<PAD>\"):\r\n",
        "    if not tf.gfile.Exists(vocab_file):\r\n",
        "      tf.logging.fatal(\"Vocab file %s not found.\", vocab_file)\r\n",
        "    tf.logging.info(\"Initializing vocabulary from file: %s\", vocab_file)\r\n",
        "\r\n",
        "    with tf.gfile.GFile(vocab_file, mode=\"r\") as f:\r\n",
        "      reverse_vocab = list(f.readlines())\r\n",
        "    reverse_vocab = [line.split()[0] for line in reverse_vocab]\r\n",
        "    assert start_word in reverse_vocab\r\n",
        "    assert end_word in reverse_vocab\r\n",
        "    if unk_word not in reverse_vocab:\r\n",
        "      reverse_vocab.append(unk_word)\r\n",
        "    vocab = dict([(x, y) for (y, x) in enumerate(reverse_vocab)])\r\n",
        "\r\n",
        "    print(\"  [TL] Vocabulary from %s : %s %s %s\" % (vocab_file, start_word, end_word, unk_word))\r\n",
        "    print(\"    vocabulary with %d words (includes start_word, end_word, unk_word)\" % len(vocab))\r\n",
        "    # tf.logging.info(\"     vocabulary with %d words\" % len(vocab))\r\n",
        "\r\n",
        "    self.vocab = vocab  # vocab[word] = id\r\n",
        "    self.reverse_vocab = reverse_vocab  # reverse_vocab[id] = word\r\n",
        "\r\n",
        "    # Save special word ids.\r\n",
        "    self.start_id = vocab[start_word]\r\n",
        "    self.end_id = vocab[end_word]\r\n",
        "    self.unk_id = vocab[unk_word]\r\n",
        "    self.pad_id = vocab[pad_word]\r\n",
        "    print(\"      start_id: %d\" % self.start_id)\r\n",
        "    print(\"      end_id: %d\" % self.end_id)\r\n",
        "    print(\"      unk_id: %d\" % self.unk_id)\r\n",
        "    print(\"      pad_id: %d\" % self.pad_id)\r\n",
        "\r\n",
        "  def word_to_id(self, word):\r\n",
        "    \"\"\"Returns the integer word id of a word string.\"\"\"\r\n",
        "    if word in self.vocab:\r\n",
        "      return self.vocab[word]\r\n",
        "    else:\r\n",
        "      return self.unk_id\r\n",
        "\r\n",
        "  def id_to_word(self, word_id):\r\n",
        "    \"\"\"Returns the word string of an integer word id.\"\"\"\r\n",
        "    if word_id >= len(self.reverse_vocab):\r\n",
        "      return self.reverse_vocab[self.unk_id]\r\n",
        "    else:\r\n",
        "      return self.reverse_vocab[word_id]\r\n",
        "\r\n",
        "def process_sentence(sentence, start_word=\"<S>\", end_word=\"</S>\"):\r\n",
        "    \"\"\"Converts a sentence string into a list of string words, add start_word and end_word,\r\n",
        "    see ``create_vocab()`` and ``tutorial_tfrecord3.py``.\r\n",
        "    Parameter\r\n",
        "    ---------\r\n",
        "    sentence : a sentence in string.\r\n",
        "    start_word : a string or None, if None, non start word will be appended.\r\n",
        "    end_word : a string or None, if None, non end word will be appended.\r\n",
        "    Returns\r\n",
        "    ---------\r\n",
        "    A list of strings; the processed caption.\r\n",
        "    Examples\r\n",
        "    -----------\r\n",
        "    >>> c = \"how are you?\"\r\n",
        "    >>> c = tl.nlp.process_sentence(c)\r\n",
        "    >>> print(c)\r\n",
        "    ... ['<S>', 'how', 'are', 'you', '?', '</S>']\r\n",
        "    \"\"\"\r\n",
        "    try:\r\n",
        "        import nltk\r\n",
        "    except:\r\n",
        "        raise Exception(\"Hint : NLTK is required.\")\r\n",
        "    if start_word is not None:\r\n",
        "        process_sentence = [start_word]\r\n",
        "    else:\r\n",
        "        process_sentence = []\r\n",
        "    process_sentence.extend(nltk.tokenize.word_tokenize(sentence.lower()))\r\n",
        "    if end_word is not None:\r\n",
        "        process_sentence.append(end_word)\r\n",
        "    return process_sentence\r\n",
        "\r\n",
        "def create_vocab(sentences, word_counts_output_file, min_word_count=1):\r\n",
        "    \"\"\"Creates the vocabulary of word to word_id, see create_vocab() and ``tutorial_tfrecord3.py``.\r\n",
        "    The vocabulary is saved to disk in a text file of word counts. The id of each\r\n",
        "    word in the file is its corresponding 0-based line number.\r\n",
        "    Parameters\r\n",
        "    ------------\r\n",
        "    sentences : a list of lists of strings.\r\n",
        "    word_counts_output_file : A string\r\n",
        "        The file name.\r\n",
        "    min_word_count : a int\r\n",
        "        Minimum number of occurrences for a word.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    - tl.nlp.SimpleVocabulary object.\r\n",
        "    Mores\r\n",
        "    -----\r\n",
        "    - ``tl.nlp.build_vocab()``\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> captions = [\"one two , three\", \"four five five\"]\r\n",
        "    >>> processed_capts = []\r\n",
        "    >>> for c in captions:\r\n",
        "    >>>     c = tl.nlp.process_sentence(c, start_word=\"<S>\", end_word=\"</S>\")\r\n",
        "    >>>     processed_capts.append(c)\r\n",
        "    >>> print(processed_capts)\r\n",
        "    ...[['<S>', 'one', 'two', ',', 'three', '</S>'], ['<S>', 'four', 'five', 'five', '</S>']]\r\n",
        "    >>> tl.nlp.create_vocab(processed_capts, word_counts_output_file='vocab.txt', min_word_count=1)\r\n",
        "    ...   [TL] Creating vocabulary.\r\n",
        "    ...   Total words: 8\r\n",
        "    ...   Words in vocabulary: 8\r\n",
        "    ...   Wrote vocabulary file: vocab.txt\r\n",
        "    >>> vocab = tl.nlp.Vocabulary('vocab.txt', start_word=\"<S>\", end_word=\"</S>\", unk_word=\"<UNK>\")\r\n",
        "    ...   [TL] Instantiate Vocabulary from vocab.txt : <S> </S> <UNK>\r\n",
        "    ...   vocabulary with 9 words (includes unk_word)\r\n",
        "    \"\"\"\r\n",
        "    from collections import Counter\r\n",
        "    print(\"  [TL] Creating vocabulary.\")\r\n",
        "    counter = Counter()\r\n",
        "    for c in sentences:\r\n",
        "        counter.update(c)\r\n",
        "        # print('c',c)\r\n",
        "    print(\"    Total words: %d\" % len(counter))\r\n",
        "\r\n",
        "    # Filter uncommon words and sort by descending count.\r\n",
        "    word_counts = [x for x in counter.items() if x[1] >= min_word_count]\r\n",
        "    word_counts.sort(key=lambda x: x[1], reverse=True)\r\n",
        "    word_counts = [(\"<PAD>\", 0)] + word_counts # 1st id should be reserved for padding\r\n",
        "    # print(word_counts)\r\n",
        "    print(\"    Words in vocabulary: %d\" % len(word_counts))\r\n",
        "\r\n",
        "    # Write out the word counts file.\r\n",
        "    with tf.gfile.FastGFile(word_counts_output_file, \"w\") as f:\r\n",
        "        f.write(\"\\n\".join([\"%s %d\" % (w, c) for w, c in word_counts]))\r\n",
        "    print(\"    Wrote vocabulary file: %s\" % word_counts_output_file)\r\n",
        "\r\n",
        "    # Create the vocabulary dictionary.\r\n",
        "    reverse_vocab = [x[0] for x in word_counts]\r\n",
        "    unk_id = len(reverse_vocab)\r\n",
        "    vocab_dict = dict([(x, y) for (y, x) in enumerate(reverse_vocab)])\r\n",
        "    vocab = SimpleVocabulary(vocab_dict, unk_id)\r\n",
        "\r\n",
        "    return vocab\r\n",
        "\r\n",
        "\r\n",
        "## Vector representations of words\r\n",
        "def simple_read_words(filename=\"nietzsche.txt\"):\r\n",
        "    \"\"\"Read context from file without any preprocessing.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    filename : a string\r\n",
        "        A file path (like .txt file)\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    The context in a string\r\n",
        "    \"\"\"\r\n",
        "    with open(\"nietzsche.txt\", \"r\") as f:\r\n",
        "        words = f.read()\r\n",
        "        return words\r\n",
        "\r\n",
        "def read_words(filename=\"nietzsche.txt\", replace = ['\\n', '<eos>']):\r\n",
        "    \"\"\"File to list format context. Note that, this script can not handle punctuations.\r\n",
        "    For customized read_words method, see ``tutorial_generate_text.py``.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    filename : a string\r\n",
        "        A file path (like .txt file),\r\n",
        "    replace : a list\r\n",
        "        [original string, target string], to disable replace use ['', '']\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    The context in a list, split by space by default, and use ``'<eos>'`` to represent ``'\\n'``,\r\n",
        "    e.g. ``[... 'how', 'useful', 'it', \"'s\" ... ]``.\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\r\n",
        "    \"\"\"\r\n",
        "    with tf.gfile.GFile(filename, \"r\") as f:\r\n",
        "        try:    # python 3.4 or older\r\n",
        "            context_list = f.read().replace(*replace).split()\r\n",
        "        except: # python 3.5\r\n",
        "            f.seek(0)\r\n",
        "            replace = [x.encode('utf-8') for x in replace]\r\n",
        "            context_list = f.read().replace(*replace).split()\r\n",
        "        return context_list\r\n",
        "\r\n",
        "def read_analogies_file(eval_file='questions-words.txt', word2id={}):\r\n",
        "    \"\"\"Reads through an analogy question file, return its id format.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    eval_data : a string\r\n",
        "        The file name.\r\n",
        "    word2id : a dictionary\r\n",
        "        Mapping words to unique IDs.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    analogy_questions : a [n, 4] numpy array containing the analogy question's\r\n",
        "             word ids.\r\n",
        "             questions_skipped: questions skipped due to unknown words.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> eval_file should be in this format :\r\n",
        "    >>> : capital-common-countries\r\n",
        "    >>> Athens Greece Baghdad Iraq\r\n",
        "    >>> Athens Greece Bangkok Thailand\r\n",
        "    >>> Athens Greece Beijing China\r\n",
        "    >>> Athens Greece Berlin Germany\r\n",
        "    >>> Athens Greece Bern Switzerland\r\n",
        "    >>> Athens Greece Cairo Egypt\r\n",
        "    >>> Athens Greece Canberra Australia\r\n",
        "    >>> Athens Greece Hanoi Vietnam\r\n",
        "    >>> Athens Greece Havana Cuba\r\n",
        "    ...\r\n",
        "    >>> words = tl.files.load_matt_mahoney_text8_dataset()\r\n",
        "    >>> data, count, dictionary, reverse_dictionary = \\\r\n",
        "                tl.nlp.build_words_dataset(words, vocabulary_size, True)\r\n",
        "    >>> analogy_questions = tl.nlp.read_analogies_file( \\\r\n",
        "                eval_file='questions-words.txt', word2id=dictionary)\r\n",
        "    >>> print(analogy_questions)\r\n",
        "    ... [[ 3068  1248  7161  1581]\r\n",
        "    ... [ 3068  1248 28683  5642]\r\n",
        "    ... [ 3068  1248  3878   486]\r\n",
        "    ... ...,\r\n",
        "    ... [ 1216  4309 19982 25506]\r\n",
        "    ... [ 1216  4309  3194  8650]\r\n",
        "    ... [ 1216  4309   140   312]]\r\n",
        "    \"\"\"\r\n",
        "    questions = []\r\n",
        "    questions_skipped = 0\r\n",
        "    with open(eval_file, \"rb\") as analogy_f:\r\n",
        "      for line in analogy_f:\r\n",
        "          if line.startswith(b\":\"):  # Skip comments.\r\n",
        "                continue\r\n",
        "          words = line.strip().lower().split(b\" \")  # lowercase\r\n",
        "          ids = [word2id.get(w.strip()) for w in words]\r\n",
        "          if None in ids or len(ids) != 4:\r\n",
        "              questions_skipped += 1\r\n",
        "          else:\r\n",
        "              questions.append(np.array(ids))\r\n",
        "    print(\"Eval analogy file: \", eval_file)\r\n",
        "    print(\"Questions: \", len(questions))\r\n",
        "    print(\"Skipped: \", questions_skipped)\r\n",
        "    analogy_questions = np.array(questions, dtype=np.int32)\r\n",
        "    return analogy_questions\r\n",
        "\r\n",
        "def build_vocab(data):\r\n",
        "    \"\"\"Build vocabulary.\r\n",
        "    Given the context in list format.\r\n",
        "    Return the vocabulary, which is a dictionary for word to id.\r\n",
        "    e.g. {'campbell': 2587, 'atlantic': 2247, 'aoun': 6746 .... }\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    data : a list of string\r\n",
        "        the context in list format\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    word_to_id : a dictionary\r\n",
        "        mapping words to unique IDs. e.g. {'campbell': 2587, 'atlantic': 2247, 'aoun': 6746 .... }\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> data_path = os.getcwd() + '/simple-examples/data'\r\n",
        "    >>> train_path = os.path.join(data_path, \"ptb.train.txt\")\r\n",
        "    >>> word_to_id = build_vocab(read_txt_words(train_path))\r\n",
        "    \"\"\"\r\n",
        "    # data = _read_words(filename)\r\n",
        "    counter = collections.Counter(data)\r\n",
        "    # print('counter', counter)   # dictionary for the occurrence number of each word, e.g. 'banknote': 1, 'photography': 1, 'kia': 1\r\n",
        "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\r\n",
        "    # print('count_pairs',count_pairs)  # convert dictionary to list of tuple, e.g. ('ssangyong', 1), ('swapo', 1), ('wachter', 1)\r\n",
        "    words, _ = list(zip(*count_pairs))\r\n",
        "    word_to_id = dict(zip(words, range(len(words))))\r\n",
        "    # print(words)    # list of words\r\n",
        "    # print(word_to_id) # dictionary for word to id, e.g. 'campbell': 2587, 'atlantic': 2247, 'aoun': 6746\r\n",
        "    return word_to_id\r\n",
        "\r\n",
        "def build_reverse_dictionary(word_to_id):\r\n",
        "    \"\"\"Given a dictionary for converting word to integer id.\r\n",
        "    Returns a reverse dictionary for converting a id to word.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    word_to_id : dictionary\r\n",
        "        mapping words to unique ids\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    reverse_dictionary : a dictionary\r\n",
        "        mapping ids to words\r\n",
        "    \"\"\"\r\n",
        "    reverse_dictionary = dict(zip(word_to_id.values(), word_to_id.keys()))\r\n",
        "    return reverse_dictionary\r\n",
        "\r\n",
        "def build_words_dataset(words=[], vocabulary_size=50000, printable=True, unk_key = 'UNK'):\r\n",
        "    \"\"\"Build the words dictionary and replace rare words with 'UNK' token.\r\n",
        "    The most common word has the smallest integer id.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    words : a list of string or byte\r\n",
        "        The context in list format. You may need to do preprocessing on the words,\r\n",
        "        such as lower case, remove marks etc.\r\n",
        "    vocabulary_size : an int\r\n",
        "        The maximum vocabulary size, limiting the vocabulary size.\r\n",
        "        Then the script replaces rare words with 'UNK' token.\r\n",
        "    printable : boolean\r\n",
        "        Whether to print the read vocabulary size of the given words.\r\n",
        "    unk_key : a string\r\n",
        "        Unknown words = unk_key\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    data : a list of integer\r\n",
        "        The context in a list of ids\r\n",
        "    count : a list of tuple and list\r\n",
        "        count[0] is a list : the number of rare words\\n\r\n",
        "        count[1:] are tuples : the number of occurrence of each word\\n\r\n",
        "        e.g. [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\r\n",
        "    dictionary : a dictionary\r\n",
        "        word_to_id, mapping words to unique IDs.\r\n",
        "    reverse_dictionary : a dictionary\r\n",
        "        id_to_word, mapping id to unique word.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> words = tl.files.load_matt_mahoney_text8_dataset()\r\n",
        "    >>> vocabulary_size = 50000\r\n",
        "    >>> data, count, dictionary, reverse_dictionary = tl.nlp.build_words_dataset(words, vocabulary_size)\r\n",
        "    Code References\r\n",
        "    -----------------\r\n",
        "    - `tensorflow/examples/tutorials/word2vec/word2vec_basic.py <https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/word2vec/word2vec_basic.py>`_\r\n",
        "    \"\"\"\r\n",
        "    import collections\r\n",
        "    count = [[unk_key, -1]]\r\n",
        "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\r\n",
        "    dictionary = dict()\r\n",
        "    for word, _ in count:\r\n",
        "        dictionary[word] = len(dictionary)\r\n",
        "    data = list()\r\n",
        "    unk_count = 0\r\n",
        "    for word in words:\r\n",
        "        if word in dictionary:\r\n",
        "            index = dictionary[word]\r\n",
        "        else:\r\n",
        "            index = 0  # dictionary['UNK']\r\n",
        "            unk_count += 1\r\n",
        "        data.append(index)\r\n",
        "    count[0][1] = unk_count\r\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\r\n",
        "    if printable:\r\n",
        "        print('Real vocabulary size    %d' % len(collections.Counter(words).keys()))\r\n",
        "        print('Limited vocabulary size {}'.format(vocabulary_size))\r\n",
        "    assert len(collections.Counter(words).keys()) >= vocabulary_size , \\\r\n",
        "            \"the limited vocabulary_size must be less than or equal to the read vocabulary_size\"\r\n",
        "    return data, count, dictionary, reverse_dictionary\r\n",
        "\r\n",
        "def words_to_word_ids(data=[], word_to_id={}, unk_key = 'UNK'):\r\n",
        "    \"\"\"Given a context (words) in list format and the vocabulary,\r\n",
        "    Returns a list of IDs to represent the context.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    data : a list of string or byte\r\n",
        "        the context in list format\r\n",
        "    word_to_id : a dictionary\r\n",
        "        mapping words to unique IDs.\r\n",
        "    unk_key : a string\r\n",
        "        Unknown words = unk_key\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    A list of IDs to represent the context.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> words = tl.files.load_matt_mahoney_text8_dataset()\r\n",
        "    >>> vocabulary_size = 50000\r\n",
        "    >>> data, count, dictionary, reverse_dictionary = \\\r\n",
        "    ...         tl.nlp.build_words_dataset(words, vocabulary_size, True)\r\n",
        "    >>> context = [b'hello', b'how', b'are', b'you']\r\n",
        "    >>> ids = tl.nlp.words_to_word_ids(words, dictionary)\r\n",
        "    >>> context = tl.nlp.word_ids_to_words(ids, reverse_dictionary)\r\n",
        "    >>> print(ids)\r\n",
        "    ... [6434, 311, 26, 207]\r\n",
        "    >>> print(context)\r\n",
        "    ... [b'hello', b'how', b'are', b'you']\r\n",
        "    Code References\r\n",
        "    ---------------\r\n",
        "    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\r\n",
        "    \"\"\"\r\n",
        "    # if isinstance(data[0], six.string_types):\r\n",
        "    #     print(type(data[0]))\r\n",
        "    #     # exit()\r\n",
        "    #     print(data[0])\r\n",
        "    #     print(word_to_id)\r\n",
        "    #     return [word_to_id[str(word)] for word in data]\r\n",
        "    # else:\r\n",
        "\r\n",
        "    word_ids = []\r\n",
        "    for word in data:\r\n",
        "        if word_to_id.get(word) is not None:\r\n",
        "            word_ids.append(word_to_id[word])\r\n",
        "        else:\r\n",
        "            word_ids.append(word_to_id[unk_key])\r\n",
        "    return word_ids\r\n",
        "    # return [word_to_id[word] for word in data]    # this one\r\n",
        "\r\n",
        "    # if isinstance(data[0], str):\r\n",
        "    #     # print('is a string object')\r\n",
        "    #     return [word_to_id[word] for word in data]\r\n",
        "    # else:#if isinstance(s, bytes):\r\n",
        "    #     # print('is a unicode object')\r\n",
        "    #     # print(data[0])\r\n",
        "    #     return [word_to_id[str(word)] f\r\n",
        "\r\n",
        "def word_ids_to_words(data, id_to_word):\r\n",
        "    \"\"\"Given a context (ids) in list format and the vocabulary,\r\n",
        "    Returns a list of words to represent the context.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    data : a list of integer\r\n",
        "        the context in list format\r\n",
        "    id_to_word : a dictionary\r\n",
        "        mapping id to unique word.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    A list of string or byte to represent the context.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> see words_to_word_ids\r\n",
        "    \"\"\"\r\n",
        "    return [id_to_word[i] for i in data]\r\n",
        "\r\n",
        "def save_vocab(count=[], name='vocab.txt'):\r\n",
        "    \"\"\"Save the vocabulary to a file so the model can be reloaded.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    count : a list of tuple and list\r\n",
        "        count[0] is a list : the number of rare words\\n\r\n",
        "        count[1:] are tuples : the number of occurrence of each word\\n\r\n",
        "        e.g. [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> words = tl.files.load_matt_mahoney_text8_dataset()\r\n",
        "    >>> vocabulary_size = 50000\r\n",
        "    >>> data, count, dictionary, reverse_dictionary = \\\r\n",
        "    ...     tl.nlp.build_words_dataset(words, vocabulary_size, True)\r\n",
        "    >>> tl.nlp.save_vocab(count, name='vocab_text8.txt')\r\n",
        "    >>> vocab_text8.txt\r\n",
        "    ... UNK 418391\r\n",
        "    ... the 1061396\r\n",
        "    ... of 593677\r\n",
        "    ... and 416629\r\n",
        "    ... one 411764\r\n",
        "    ... in 372201\r\n",
        "    ... a 325873\r\n",
        "    ... to 316376\r\n",
        "    \"\"\"\r\n",
        "    pwd = os.getcwd()\r\n",
        "    vocabulary_size = len(count)\r\n",
        "    with open(os.path.join(pwd, name), \"w\") as f:\r\n",
        "        for i in xrange(vocabulary_size):\r\n",
        "            f.write(\"%s %d\\n\" % (tf.compat.as_text(count[i][0]), count[i][1]))\r\n",
        "    print(\"%d vocab saved to %s in %s\" % (vocabulary_size, name, pwd))\r\n",
        "\r\n",
        "## Functions for translation\r\n",
        "def basic_tokenizer(sentence, _WORD_SPLIT=re.compile(b\"([.,!?\\\"':;)(])\")):\r\n",
        "  \"\"\"Very basic tokenizer: split the sentence into a list of tokens.\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  sentence : tensorflow.python.platform.gfile.GFile Object\r\n",
        "  _WORD_SPLIT : regular expression for word spliting.\r\n",
        "  Examples\r\n",
        "  --------\r\n",
        "  >>> see create_vocabulary\r\n",
        "  >>> from tensorflow.python.platform import gfile\r\n",
        "  >>> train_path = \"wmt/giga-fren.release2\"\r\n",
        "  >>> with gfile.GFile(train_path + \".en\", mode=\"rb\") as f:\r\n",
        "  >>>    for line in f:\r\n",
        "  >>>       tokens = tl.nlp.basic_tokenizer(line)\r\n",
        "  >>>       print(tokens)\r\n",
        "  >>>       exit()\r\n",
        "  ... [b'Changing', b'Lives', b'|', b'Changing', b'Society', b'|', b'How',\r\n",
        "  ...   b'It', b'Works', b'|', b'Technology', b'Drives', b'Change', b'Home',\r\n",
        "  ...   b'|', b'Concepts', b'|', b'Teachers', b'|', b'Search', b'|', b'Overview',\r\n",
        "  ...   b'|', b'Credits', b'|', b'HHCC', b'Web', b'|', b'Reference', b'|',\r\n",
        "  ...   b'Feedback', b'Virtual', b'Museum', b'of', b'Canada', b'Home', b'Page']\r\n",
        "  References\r\n",
        "  ----------\r\n",
        "  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\r\n",
        "  \"\"\"\r\n",
        "  words = []\r\n",
        "  sentence = tf.compat.as_bytes(sentence)\r\n",
        "  for space_separated_fragment in sentence.strip().split():\r\n",
        "    words.extend(re.split(_WORD_SPLIT, space_separated_fragment))\r\n",
        "  return [w for w in words if w]\r\n",
        "\r\n",
        "def create_vocabulary(vocabulary_path, data_path, max_vocabulary_size,\r\n",
        "                      tokenizer=None, normalize_digits=True,\r\n",
        "                      _DIGIT_RE=re.compile(br\"\\d\"),\r\n",
        "                      _START_VOCAB=[b\"_PAD\", b\"_GO\", b\"_EOS\", b\"_UNK\"]):\r\n",
        "  \"\"\"Create vocabulary file (if it does not exist yet) from data file.\r\n",
        "  Data file is assumed to contain one sentence per line. Each sentence is\r\n",
        "  tokenized and digits are normalized (if normalize_digits is set).\r\n",
        "  Vocabulary contains the most-frequent tokens up to max_vocabulary_size.\r\n",
        "  We write it to vocabulary_path in a one-token-per-line format, so that later\r\n",
        "  token in the first line gets id=0, second line gets id=1, and so on.\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  vocabulary_path : path where the vocabulary will be created.\r\n",
        "  data_path : data file that will be used to create vocabulary.\r\n",
        "  max_vocabulary_size : limit on the size of the created vocabulary.\r\n",
        "  tokenizer : a function to use to tokenize each data sentence.\r\n",
        "        if None, basic_tokenizer will be used.\r\n",
        "  normalize_digits : Boolean\r\n",
        "        if true, all digits are replaced by 0s.\r\n",
        "  References\r\n",
        "  ----------\r\n",
        "  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\r\n",
        "  \"\"\"\r\n",
        "  if not gfile.Exists(vocabulary_path):\r\n",
        "    print(\"Creating vocabulary %s from data %s\" % (vocabulary_path, data_path))\r\n",
        "    vocab = {}\r\n",
        "    with gfile.GFile(data_path, mode=\"rb\") as f:\r\n",
        "      counter = 0\r\n",
        "      for line in f:\r\n",
        "        counter += 1\r\n",
        "        if counter % 100000 == 0:\r\n",
        "          print(\"  processing line %d\" % counter)\r\n",
        "        tokens = tokenizer(line) if tokenizer else basic_tokenizer(line)\r\n",
        "        for w in tokens:\r\n",
        "          word = re.sub(_DIGIT_RE, b\"0\", w) if normalize_digits else w\r\n",
        "          if word in vocab:\r\n",
        "            vocab[word] += 1\r\n",
        "          else:\r\n",
        "            vocab[word] = 1\r\n",
        "      vocab_list = _START_VOCAB + sorted(vocab, key=vocab.get, reverse=True)\r\n",
        "      if len(vocab_list) > max_vocabulary_size:\r\n",
        "        vocab_list = vocab_list[:max_vocabulary_size]\r\n",
        "      with gfile.GFile(vocabulary_path, mode=\"wb\") as vocab_file:\r\n",
        "        for w in vocab_list:\r\n",
        "          vocab_file.write(w + b\"\\n\")\r\n",
        "  else:\r\n",
        "    print(\"Vocabulary %s from data %s exists\" % (vocabulary_path, data_path))\r\n",
        "\r\n",
        "def initialize_vocabulary(vocabulary_path):\r\n",
        "  \"\"\"Initialize vocabulary from file, return the word_to_id (dictionary)\r\n",
        "  and id_to_word (list).\r\n",
        "  We assume the vocabulary is stored one-item-per-line, so a file:\\n\r\n",
        "    dog\\n\r\n",
        "    cat\\n\r\n",
        "  will result in a vocabulary {\"dog\": 0, \"cat\": 1}, and this function will\r\n",
        "  also return the reversed-vocabulary [\"dog\", \"cat\"].\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  vocabulary_path : path to the file containing the vocabulary.\r\n",
        "  Returns\r\n",
        "  --------\r\n",
        "  vocab : a dictionary\r\n",
        "        Word to id. A dictionary mapping string to integers.\r\n",
        "  rev_vocab : a list\r\n",
        "        Id to word. The reversed vocabulary (a list, which reverses the vocabulary mapping).\r\n",
        "  Examples\r\n",
        "  ---------\r\n",
        "  >>> Assume 'test' contains\r\n",
        "  ... dog\r\n",
        "  ... cat\r\n",
        "  ... bird\r\n",
        "  >>> vocab, rev_vocab = tl.nlp.initialize_vocabulary(\"test\")\r\n",
        "  >>> print(vocab)\r\n",
        "  >>> {b'cat': 1, b'dog': 0, b'bird': 2}\r\n",
        "  >>> print(rev_vocab)\r\n",
        "  >>> [b'dog', b'cat', b'bird']\r\n",
        "  Raises\r\n",
        "  -------\r\n",
        "  ValueError : if the provided vocabulary_path does not exist.\r\n",
        "  \"\"\"\r\n",
        "  if gfile.Exists(vocabulary_path):\r\n",
        "    rev_vocab = []\r\n",
        "    with gfile.GFile(vocabulary_path, mode=\"rb\") as f:\r\n",
        "      rev_vocab.extend(f.readlines())\r\n",
        "    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]\r\n",
        "    vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\r\n",
        "    return vocab, rev_vocab\r\n",
        "  else:\r\n",
        "    raise ValueError(\"Vocabulary file %s not found.\", vocabulary_path)\r\n",
        "\r\n",
        "def sentence_to_token_ids(sentence, vocabulary,\r\n",
        "                          tokenizer=None, normalize_digits=True,\r\n",
        "                          UNK_ID=3, _DIGIT_RE=re.compile(br\"\\d\")):\r\n",
        "  \"\"\"Convert a string to list of integers representing token-ids.\r\n",
        "  For example, a sentence \"I have a dog\" may become tokenized into\r\n",
        "  [\"I\", \"have\", \"a\", \"dog\"] and with vocabulary {\"I\": 1, \"have\": 2,\r\n",
        "  \"a\": 4, \"dog\": 7\"} this function will return [1, 2, 4, 7].\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  sentence :  tensorflow.python.platform.gfile.GFile Object\r\n",
        "        The sentence in bytes format to convert to token-ids.\\n\r\n",
        "        see basic_tokenizer(), data_to_token_ids()\r\n",
        "  vocabulary : a dictionary mapping tokens to integers.\r\n",
        "  tokenizer : a function to use to tokenize each sentence;\r\n",
        "        If None, basic_tokenizer will be used.\r\n",
        "  normalize_digits : Boolean\r\n",
        "        If true, all digits are replaced by 0s.\r\n",
        "  Returns\r\n",
        "  --------\r\n",
        "  A list of integers, the token-ids for the sentence.\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  if tokenizer:\r\n",
        "    words = tokenizer(sentence)\r\n",
        "  else:\r\n",
        "    words = basic_tokenizer(sentence)\r\n",
        "  if not normalize_digits:\r\n",
        "    return [vocabulary.get(w, UNK_ID) for w in words]\r\n",
        "  # Normalize digits by 0 before looking words up in the vocabulary.\r\n",
        "  return [vocabulary.get(re.sub(_DIGIT_RE, b\"0\", w), UNK_ID) for w in words]\r\n",
        "\r\n",
        "def data_to_token_ids(data_path, target_path, vocabulary_path,\r\n",
        "                      tokenizer=None, normalize_digits=True,\r\n",
        "                      UNK_ID=3, _DIGIT_RE=re.compile(br\"\\d\")):\r\n",
        "  \"\"\"Tokenize data file and turn into token-ids using given vocabulary file.\r\n",
        "  This function loads data line-by-line from data_path, calls the above\r\n",
        "  sentence_to_token_ids, and saves the result to target_path. See comment\r\n",
        "  for sentence_to_token_ids on the details of token-ids format.\r\n",
        "  Parameters\r\n",
        "  -----------\r\n",
        "  data_path : path to the data file in one-sentence-per-line format.\r\n",
        "  target_path : path where the file with token-ids will be created.\r\n",
        "  vocabulary_path : path to the vocabulary file.\r\n",
        "  tokenizer : a function to use to tokenize each sentence;\r\n",
        "      if None, basic_tokenizer will be used.\r\n",
        "  normalize_digits : Boolean; if true, all digits are replaced by 0s.\r\n",
        "  References\r\n",
        "  ----------\r\n",
        "  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\r\n",
        "  \"\"\"\r\n",
        "  if not gfile.Exists(target_path):\r\n",
        "    print(\"Tokenizing data in %s\" % data_path)\r\n",
        "    vocab, _ = initialize_vocabulary(vocabulary_path)\r\n",
        "    with gfile.GFile(data_path, mode=\"rb\") as data_file:\r\n",
        "      with gfile.GFile(target_path, mode=\"w\") as tokens_file:\r\n",
        "        counter = 0\r\n",
        "        for line in data_file:\r\n",
        "          counter += 1\r\n",
        "          if counter % 100000 == 0:\r\n",
        "            print(\"  tokenizing line %d\" % counter)\r\n",
        "          token_ids = sentence_to_token_ids(line, vocab, tokenizer,\r\n",
        "                                            normalize_digits, UNK_ID=UNK_ID,\r\n",
        "                                            _DIGIT_RE=_DIGIT_RE)\r\n",
        "          tokens_file.write(\" \".join([str(tok) for tok in token_ids]) + \"\\n\")\r\n",
        "  else:\r\n",
        "    print(\"Target path %s exists\" % target_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyz5DTJWehXF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import sys\r\n",
        "from sys import platform as _platform\r\n",
        "\r\n",
        "\r\n",
        "def exit_tf(sess=None):\r\n",
        "    \"\"\"Close tensorboard and nvidia-process if available\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : a session instance of TensorFlow\r\n",
        "        TensorFlow session\r\n",
        "    \"\"\"\r\n",
        "    text = \"[tl] Close tensorboard and nvidia-process if available\"\r\n",
        "    sess.close()\r\n",
        "    # import time\r\n",
        "    # time.sleep(2)\r\n",
        "    if _platform == \"linux\" or _platform == \"linux2\":\r\n",
        "        print('linux: %s' % text)\r\n",
        "        os.system('nvidia-smi')\r\n",
        "        os.system('fuser 6006/tcp -k')  # kill tensorboard 6006\r\n",
        "        os.system(\"nvidia-smi | grep python |awk '{print $3}'|xargs kill\") # kill all nvidia-smi python process\r\n",
        "    elif _platform == \"darwin\":\r\n",
        "        print('OS X: %s' % text)\r\n",
        "        os.system(\"lsof -i tcp:6006 | grep -v PID | awk '{print $2}' | xargs kill\") # kill tensorboard 6006\r\n",
        "    elif _platform == \"win32\":\r\n",
        "        print('Windows: %s' % text)\r\n",
        "    else:\r\n",
        "        print(_platform)\r\n",
        "    exit()\r\n",
        "\r\n",
        "def clear_all(printable=True):\r\n",
        "    \"\"\"Clears all the placeholder variables of keep prob,\r\n",
        "    including keeping probabilities of all dropout, denoising, dropconnect etc.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    printable : boolean\r\n",
        "        If True, print all deleted variables.\r\n",
        "    \"\"\"\r\n",
        "    print('clear all .....................................')\r\n",
        "    gl = globals().copy()\r\n",
        "    for var in gl:\r\n",
        "        if var[0] == '_': continue\r\n",
        "        if 'func' in str(globals()[var]): continue\r\n",
        "        if 'module' in str(globals()[var]): continue\r\n",
        "        if 'class' in str(globals()[var]): continue\r\n",
        "\r\n",
        "        if printable:\r\n",
        "            print(\" clear_all ------- %s\" % str(globals()[var]))\r\n",
        "\r\n",
        "        del globals()[var]\r\n",
        "\r\n",
        "# def clear_all2(vars, printable=True):\r\n",
        "#     \"\"\"\r\n",
        "#     The :function:`clear_all()` Clears all the placeholder variables of keep prob,\r\n",
        "#     including keeping probabilities of all dropout, denoising, dropconnect\r\n",
        "#     Parameters\r\n",
        "#     ----------\r\n",
        "#     printable : if True, print all deleted variables.\r\n",
        "#     \"\"\"\r\n",
        "#     print('clear all .....................................')\r\n",
        "#     for var in vars:\r\n",
        "#         if var[0] == '_': continue\r\n",
        "#         if 'func' in str(var): continue\r\n",
        "#         if 'module' in str(var): continue\r\n",
        "#         if 'class' in str(var): continue\r\n",
        "#\r\n",
        "#         if printable:\r\n",
        "#             print(\" clear_all ------- %s\" % str(var))\r\n",
        "#\r\n",
        "#         del var\r\n",
        "\r\n",
        "def set_gpu_fraction(sess=None, gpu_fraction=0.3):\r\n",
        "    \"\"\"Set the GPU memory fraction for the application.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : a session instance of TensorFlow\r\n",
        "        TensorFlow session\r\n",
        "    gpu_fraction : a float\r\n",
        "        Fraction of GPU memory, (0 ~ 1]\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `TensorFlow using GPU <https://www.tensorflow.org/versions/r0.9/how_tos/using_gpu/index.html>`_\r\n",
        "    \"\"\"\r\n",
        "    print(\"  tensorlayer: GPU MEM Fraction %f\" % gpu_fraction)\r\n",
        "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\r\n",
        "    sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\r\n",
        "    return sess\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def disable_print():\r\n",
        "    \"\"\"Disable console output, ``suppress_stdout`` is recommended.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> print(\"You can see me\")\r\n",
        "    >>> tl.ops.disable_print()\r\n",
        "    >>> print(\" You can't see me\")\r\n",
        "    >>> tl.ops.enable_print()\r\n",
        "    >>> print(\"You can see me\")\r\n",
        "    \"\"\"\r\n",
        "    # sys.stdout = os.devnull   # this one kill the process\r\n",
        "    sys.stdout = None\r\n",
        "    sys.stderr = os.devnull\r\n",
        "\r\n",
        "def enable_print():\r\n",
        "    \"\"\"Enable console output, ``suppress_stdout`` is recommended.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - see tl.ops.disable_print()\r\n",
        "    \"\"\"\r\n",
        "    sys.stdout = sys.__stdout__\r\n",
        "    sys.stderr = sys.__stderr__\r\n",
        "\r\n",
        "\r\n",
        "# class temporary_disable_print:\r\n",
        "#     \"\"\"Temporarily disable console output.\r\n",
        "#\r\n",
        "#     Examples\r\n",
        "#     ---------\r\n",
        "#     >>> print(\"You can see me\")\r\n",
        "#     >>> with tl.ops.temporary_disable_print() as t:\r\n",
        "#     >>>     print(\"You can't see me\")\r\n",
        "#     >>> print(\"You can see me\")\r\n",
        "#     \"\"\"\r\n",
        "#     def __init__(self):\r\n",
        "#         pass\r\n",
        "#     def __enter__(self):\r\n",
        "#         sys.stdout = None\r\n",
        "#         sys.stderr = os.devnull\r\n",
        "#     def __exit__(self, type, value, traceback):\r\n",
        "#         sys.stdout = sys.__stdout__\r\n",
        "#         sys.stderr = sys.__stderr__\r\n",
        "#         return isinstance(value, TypeError)\r\n",
        "\r\n",
        "\r\n",
        "from contextlib import contextmanager\r\n",
        "@contextmanager\r\n",
        "def suppress_stdout():\r\n",
        "    \"\"\"Temporarily disable console output.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> print(\"You can see me\")\r\n",
        "    >>> with tl.ops.suppress_stdout():\r\n",
        "    >>>     print(\"You can't see me\")\r\n",
        "    >>> print(\"You can see me\")\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `stackoverflow <http://stackoverflow.com/questions/2125702/how-to-suppress-console-output-in-python>`_\r\n",
        "    \"\"\"\r\n",
        "    with open(os.devnull, \"w\") as devnull:\r\n",
        "        old_stdout = sys.stdout\r\n",
        "        sys.stdout = devnull\r\n",
        "        try:\r\n",
        "            yield\r\n",
        "        finally:\r\n",
        "            sys.stdout = old_stdout\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_site_packages_directory():\r\n",
        "    \"\"\"Print and return the site-packages directory.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> loc = tl.ops.get_site_packages_directory()\r\n",
        "    \"\"\"\r\n",
        "    import site\r\n",
        "    try:\r\n",
        "        loc = site.getsitepackages()\r\n",
        "        print(\"  tl.ops : site-packages in \", loc)\r\n",
        "        return loc\r\n",
        "    except:\r\n",
        "        print(\"  tl.ops : Cannot find package dir from virtual environment\")\r\n",
        "        return False\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def empty_trash():\r\n",
        "    \"\"\"Empty trash folder.\r\n",
        "    \"\"\"\r\n",
        "    text = \"[tl] Empty the trash\"\r\n",
        "    if _platform == \"linux\" or _platform == \"linux2\":\r\n",
        "        print('linux: %s' % text)\r\n",
        "        os.system(\"rm -rf ~/.local/share/Trash/*\")\r\n",
        "    elif _platform == \"darwin\":\r\n",
        "        print('OS X: %s' % text)\r\n",
        "        os.system(\"sudo rm -rf ~/.Trash/*\")\r\n",
        "    elif _platform == \"win32\":\r\n",
        "        print('Windows: %s' % text)\r\n",
        "        try:\r\n",
        "            os.system(\"rd /s c:\\$Recycle.Bin\")  # Windows 7 or Server 2008\r\n",
        "        except:\r\n",
        "            pass\r\n",
        "        try:\r\n",
        "            os.system(\"rd /s c:\\recycler\")  #  Windows XP, Vista, or Server 2003\r\n",
        "        except:\r\n",
        "            pass\r\n",
        "    else:\r\n",
        "        print(_platform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8-PMz9cfenJ3",
        "outputId": "c8e3160b-3bcd-4167-9d9e-53f85b21f1c2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorlayer as tl\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import time\r\n",
        "import numbers\r\n",
        "import random\r\n",
        "import os\r\n",
        "import re\r\n",
        "import sys\r\n",
        "\r\n",
        "import threading\r\n",
        "# import Queue  # <-- donot work for py3\r\n",
        "is_py2 = sys.version[0] == '2'\r\n",
        "if is_py2:\r\n",
        "    import Queue as queue\r\n",
        "else:\r\n",
        "    import queue as queue\r\n",
        "\r\n",
        "from six.moves import range\r\n",
        "import scipy\r\n",
        "from scipy import linalg\r\n",
        "import scipy.ndimage as ndi\r\n",
        "\r\n",
        "from skimage import transform\r\n",
        "from skimage import exposure\r\n",
        "import skimage\r\n",
        "\r\n",
        "# linalg https://docs.scipy.org/doc/scipy/reference/linalg.html\r\n",
        "# ndimage https://docs.scipy.org/doc/scipy/reference/ndimage.html\r\n",
        "\r\n",
        "## Threading\r\n",
        "def threading_data(data=None, fn=None, **kwargs):\r\n",
        "    \"\"\"Return a batch of result by given data.\r\n",
        "    Usually be used for data augmentation.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    data : numpy array or zip of numpy array, see Examples below.\r\n",
        "    fn : the function for data processing.\r\n",
        "    more args : the args for fn, see Examples below.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - Single array\r\n",
        "    >>> X --> [batch_size, row, col, 1] greyscale\r\n",
        "    >>> results = threading_data(X, zoom, zoom_range=[0.5, 1], is_random=True)\r\n",
        "    ... results --> [batch_size, row, col, channel]\r\n",
        "    >>> tl.visualize.images2d(images=np.asarray(results), second=0.01, saveable=True, name='after', dtype=None)\r\n",
        "    >>> tl.visualize.images2d(images=np.asarray(X), second=0.01, saveable=True, name='before', dtype=None)\r\n",
        "    - List of array (e.g. functions with ``multi``)\r\n",
        "    >>> X, Y --> [batch_size, row, col, 1]  greyscale\r\n",
        "    >>> data = threading_data([_ for _ in zip(X, Y)], zoom_multi, zoom_range=[0.5, 1], is_random=True)\r\n",
        "    ... data --> [batch_size, 2, row, col, 1]\r\n",
        "    >>> X_, Y_ = data.transpose((1,0,2,3,4))\r\n",
        "    ... X_, Y_ --> [batch_size, row, col, 1]\r\n",
        "    >>> tl.visualize.images2d(images=np.asarray(X_), second=0.01, saveable=True, name='after', dtype=None)\r\n",
        "    >>> tl.visualize.images2d(images=np.asarray(Y_), second=0.01, saveable=True, name='before', dtype=None)\r\n",
        "    - Customized function for image segmentation\r\n",
        "    >>> def distort_img(data):\r\n",
        "    ...     x, y = data\r\n",
        "    ...     x, y = flip_axis_multi([x, y], axis=0, is_random=True)\r\n",
        "    ...     x, y = flip_axis_multi([x, y], axis=1, is_random=True)\r\n",
        "    ...     x, y = crop_multi([x, y], 100, 100, is_random=True)\r\n",
        "    ...     return x, y\r\n",
        "    >>> X, Y --> [batch_size, row, col, channel]\r\n",
        "    >>> data = threading_data([_ for _ in zip(X, Y)], distort_img)\r\n",
        "    >>> X_, Y_ = data.transpose((1,0,2,3,4))\r\n",
        "    References\r\n",
        "    ----------\r\n",
        "    - `python queue <https://pymotw.com/2/Queue/index.html#module-Queue>`_\r\n",
        "    - `run with limited queue <http://effbot.org/librarybook/queue.htm>`_\r\n",
        "    \"\"\"\r\n",
        "    ## plot function info\r\n",
        "    # for name, value in kwargs.items():\r\n",
        "    #     print('{0} = {1}'.format(name, value))\r\n",
        "    # exit()\r\n",
        "    # define function for threading\r\n",
        "    def apply_fn(results, i, data, kwargs):\r\n",
        "        results[i] = fn(data, **kwargs)\r\n",
        "\r\n",
        "    ## start multi-threaded reading.\r\n",
        "    results = [None] * len(data) ## preallocate result list\r\n",
        "    threads = []\r\n",
        "    for i in range(len(data)):\r\n",
        "        t = threading.Thread(\r\n",
        "                        name='threading_and_return',\r\n",
        "                        target=apply_fn,\r\n",
        "                        args=(results, i, data[i], kwargs)\r\n",
        "                        )\r\n",
        "        t.start()\r\n",
        "        threads.append(t)\r\n",
        "\r\n",
        "    ## <Milo> wait for all threads to complete\r\n",
        "    for t in threads:\r\n",
        "        t.join()\r\n",
        "\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "    ## old implementation\r\n",
        "    # define function for threading\r\n",
        "    # def function(q, i, data, kwargs):\r\n",
        "    #     result = fn(data, **kwargs)\r\n",
        "    #     q.put([i, result])\r\n",
        "    # ## start threading\r\n",
        "    # q = queue.Queue()\r\n",
        "    # threads = []\r\n",
        "    # for i in range(len(data)):\r\n",
        "    #     t = threading.Thread(\r\n",
        "    #                     name='threading_and_return',\r\n",
        "    #                     target=function,\r\n",
        "    #                     args=(q, i, data[i], kwargs)\r\n",
        "    #                     )\r\n",
        "    #     t.start()\r\n",
        "    #     threads.append(t)\r\n",
        "    #\r\n",
        "    # ## <Milo> wait for all threads to complete\r\n",
        "    # for t in threads:\r\n",
        "    #     t.join()\r\n",
        "    #\r\n",
        "    # ## get results\r\n",
        "    # results = []\r\n",
        "    # for i in range(len(data)):\r\n",
        "    #     result = q.get()\r\n",
        "    #     results.append(result)\r\n",
        "    # results = sorted(results)\r\n",
        "    # for i in range(len(results)):\r\n",
        "    #     results[i] = results[i][1]\r\n",
        "    # return np.asarray(results)\r\n",
        "\r\n",
        "\r\n",
        "## Image\r\n",
        "def rotation(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                    fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Rotate an image randomly or non-randomly.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    rg : int or float\r\n",
        "        Degree to rotate, usually 0 ~ 180.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly rotate.\r\n",
        "    row_index, col_index, channel_index : int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    fill_mode : string\r\n",
        "        Method to fill missing pixel, default ‘nearest’, more options ‘constant’, ‘reflect’ or ‘wrap’\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    cval : scalar, optional\r\n",
        "        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> x --> [row, col, 1] greyscale\r\n",
        "    >>> x = rotation(x, rg=40, is_random=False)\r\n",
        "    >>> tl.visualize.frame(x[:,:,0], second=0.01, saveable=True, name='temp',cmap='gray')\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\r\n",
        "    else:\r\n",
        "        theta = np.pi /180 * rg\r\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\r\n",
        "                                [np.sin(theta), np.cos(theta), 0],\r\n",
        "                                [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x.shape[row_index], x.shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\r\n",
        "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\r\n",
        "    return x\r\n",
        "\r\n",
        "def rotation_multi(x, rg=20, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                    fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Rotate multiple images with the same arguments, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``rotation``.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> x, y --> [row, col, 1]  greyscale\r\n",
        "    >>> x, y = rotation_multi([x, y], rg=90, is_random=False)\r\n",
        "    >>> tl.visualize.frame(x[:,:,0], second=0.01, saveable=True, name='x',cmap='gray')\r\n",
        "    >>> tl.visualize.frame(y[:,:,0], second=0.01, saveable=True, name='y',cmap='gray')\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        theta = np.pi / 180 * np.random.uniform(-rg, rg)\r\n",
        "    else:\r\n",
        "        theta = np.pi /180 * rg\r\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\r\n",
        "                                [np.sin(theta), np.cos(theta), 0],\r\n",
        "                                [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x[0].shape[row_index], x[0].shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(rotation_matrix, h, w)\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        results.append( apply_transform(data, transform_matrix, channel_index, fill_mode, cval))\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# crop\r\n",
        "def crop(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\r\n",
        "    \"\"\"Randomly or centrally crop an image.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    wrg : float\r\n",
        "        Size of weight.\r\n",
        "    hrg : float\r\n",
        "        Size of height.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly crop, else central crop.\r\n",
        "    row_index, col_index, channel_index : int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    \"\"\"\r\n",
        "    h, w = x.shape[row_index], x.shape[col_index]\r\n",
        "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\r\n",
        "    if is_random:\r\n",
        "        h_offset = int(np.random.uniform(0, h-hrg) -1)\r\n",
        "        w_offset = int(np.random.uniform(0, w-wrg) -1)\r\n",
        "        # print(h_offset, w_offset, x[h_offset: hrg+h_offset ,w_offset: wrg+w_offset].shape)\r\n",
        "        return x[h_offset: hrg+h_offset ,w_offset: wrg+w_offset]\r\n",
        "    else:   # central crop\r\n",
        "        h_offset = int(np.floor((h - hrg)/2.))\r\n",
        "        w_offset = int(np.floor((w - wrg)/2.))\r\n",
        "        h_end = h_offset + hrg\r\n",
        "        w_end = w_offset + wrg\r\n",
        "        return x[h_offset: h_end, w_offset: w_end]\r\n",
        "        # old implementation\r\n",
        "        # h_offset = (h - hrg)/2\r\n",
        "        # w_offset = (w - wrg)/2\r\n",
        "        # # print(x[h_offset: h-h_offset ,w_offset: w-w_offset].shape)\r\n",
        "        # return x[h_offset: h-h_offset ,w_offset: w-w_offset]\r\n",
        "        # central crop\r\n",
        "\r\n",
        "\r\n",
        "def crop_multi(x, wrg, hrg, is_random=False, row_index=0, col_index=1, channel_index=2):\r\n",
        "    \"\"\"Randomly or centrally crop multiple images.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``crop``.\r\n",
        "    \"\"\"\r\n",
        "    h, w = x[0].shape[row_index], x[0].shape[col_index]\r\n",
        "    assert (h > hrg) and (w > wrg), \"The size of cropping should smaller than the original image\"\r\n",
        "    if is_random:\r\n",
        "        h_offset = int(np.random.uniform(0, h-hrg) -1)\r\n",
        "        w_offset = int(np.random.uniform(0, w-wrg) -1)\r\n",
        "        results = []\r\n",
        "        for data in x:\r\n",
        "            results.append( data[h_offset: hrg+h_offset ,w_offset: wrg+w_offset])\r\n",
        "        return np.asarray(results)\r\n",
        "    else:\r\n",
        "        # central crop\r\n",
        "        h_offset = (h - hrg)/2\r\n",
        "        w_offset = (w - wrg)/2\r\n",
        "        results = []\r\n",
        "        for data in x:\r\n",
        "            results.append( data[h_offset: h-h_offset ,w_offset: w-w_offset] )\r\n",
        "        return np.asarray(results)\r\n",
        "\r\n",
        "# flip\r\n",
        "def flip_axis(x, axis, is_random=False):\r\n",
        "    \"\"\"Flip the axis of an image, such as flip left and right, up and down, randomly or non-randomly,\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    axis : int\r\n",
        "        - 0, flip up and down\r\n",
        "        - 1, flip left and right\r\n",
        "        - 2, flip channel\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly flip.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        factor = np.random.uniform(-1, 1)\r\n",
        "        if factor > 0:\r\n",
        "            x = np.asarray(x).swapaxes(axis, 0)\r\n",
        "            x = x[::-1, ...]\r\n",
        "            x = x.swapaxes(0, axis)\r\n",
        "            return x\r\n",
        "        else:\r\n",
        "            return x\r\n",
        "    else:\r\n",
        "        x = np.asarray(x).swapaxes(axis, 0)\r\n",
        "        x = x[::-1, ...]\r\n",
        "        x = x.swapaxes(0, axis)\r\n",
        "        return x\r\n",
        "\r\n",
        "def flip_axis_multi(x, axis, is_random=False):\r\n",
        "    \"\"\"Flip the axises of multiple images together, such as flip left and right, up and down, randomly or non-randomly,\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``flip_axis``.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        factor = np.random.uniform(-1, 1)\r\n",
        "        if factor > 0:\r\n",
        "            # x = np.asarray(x).swapaxes(axis, 0)\r\n",
        "            # x = x[::-1, ...]\r\n",
        "            # x = x.swapaxes(0, axis)\r\n",
        "            # return x\r\n",
        "            results = []\r\n",
        "            for data in x:\r\n",
        "                data = np.asarray(data).swapaxes(axis, 0)\r\n",
        "                data = data[::-1, ...]\r\n",
        "                data = data.swapaxes(0, axis)\r\n",
        "                results.append( data )\r\n",
        "            return np.asarray(results)\r\n",
        "        else:\r\n",
        "            return np.asarray(x)\r\n",
        "    else:\r\n",
        "        # x = np.asarray(x).swapaxes(axis, 0)\r\n",
        "        # x = x[::-1, ...]\r\n",
        "        # x = x.swapaxes(0, axis)\r\n",
        "        # return x\r\n",
        "        results = []\r\n",
        "        for data in x:\r\n",
        "            data = np.asarray(data).swapaxes(axis, 0)\r\n",
        "            data = data[::-1, ...]\r\n",
        "            data = data.swapaxes(0, axis)\r\n",
        "            results.append( data )\r\n",
        "        return np.asarray(results)\r\n",
        "\r\n",
        "# shift\r\n",
        "def shift(x, wrg=0.1, hrg=0.1, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                 fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Shift an image randomly or non-randomly.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    wrg : float\r\n",
        "        Percentage of shift in axis x, usually -0.25 ~ 0.25.\r\n",
        "    hrg : float\r\n",
        "        Percentage of shift in axis y, usually -0.25 ~ 0.25.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly shift.\r\n",
        "    row_index, col_index, channel_index : int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    fill_mode : string\r\n",
        "        Method to fill missing pixel, default ‘nearest’, more options ‘constant’, ‘reflect’ or ‘wrap’.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    cval : scalar, optional\r\n",
        "        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    \"\"\"\r\n",
        "    h, w = x.shape[row_index], x.shape[col_index]\r\n",
        "    if is_random:\r\n",
        "        tx = np.random.uniform(-hrg, hrg) * h\r\n",
        "        ty = np.random.uniform(-wrg, wrg) * w\r\n",
        "    else:\r\n",
        "        tx, ty = hrg * h, wrg * w\r\n",
        "    translation_matrix = np.array([[1, 0, tx],\r\n",
        "                                   [0, 1, ty],\r\n",
        "                                   [0, 0, 1]])\r\n",
        "\r\n",
        "    transform_matrix = translation_matrix  # no need to do offset\r\n",
        "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\r\n",
        "    return x\r\n",
        "\r\n",
        "def shift_multi(x, wrg=0.1, hrg=0.1, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                 fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Shift images with the same arguments, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``shift``.\r\n",
        "    \"\"\"\r\n",
        "    h, w = x[0].shape[row_index], x[0].shape[col_index]\r\n",
        "    if is_random:\r\n",
        "        tx = np.random.uniform(-hrg, hrg) * h\r\n",
        "        ty = np.random.uniform(-wrg, wrg) * w\r\n",
        "    else:\r\n",
        "        tx, ty = hrg * h, wrg * w\r\n",
        "    translation_matrix = np.array([[1, 0, tx],\r\n",
        "                                   [0, 1, ty],\r\n",
        "                                   [0, 0, 1]])\r\n",
        "\r\n",
        "    transform_matrix = translation_matrix  # no need to do offset\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        results.append( apply_transform(data, transform_matrix, channel_index, fill_mode, cval))\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# shear\r\n",
        "def shear(x, intensity=0.1, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                 fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Shear an image randomly or non-randomly.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    intensity : float\r\n",
        "        Percentage of shear, usually -0.5 ~ 0.5 (is_random==True), 0 ~ 0.5 (is_random==False),\r\n",
        "        you can have a quick try by shear(X, 1).\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly shear.\r\n",
        "    row_index, col_index, channel_index : int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    fill_mode : string\r\n",
        "        Method to fill missing pixel, default ‘nearest’, more options ‘constant’, ‘reflect’ or ‘wrap’.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    cval : scalar, optional\r\n",
        "        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        shear = np.random.uniform(-intensity, intensity)\r\n",
        "    else:\r\n",
        "        shear = intensity\r\n",
        "    shear_matrix = np.array([[1, -np.sin(shear), 0],\r\n",
        "                             [0, np.cos(shear), 0],\r\n",
        "                             [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x.shape[row_index], x.shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\r\n",
        "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\r\n",
        "    return x\r\n",
        "\r\n",
        "def shear_multi(x, intensity=0.1, is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                 fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Shear images with the same arguments, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``shear``.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        shear = np.random.uniform(-intensity, intensity)\r\n",
        "    else:\r\n",
        "        shear = intensity\r\n",
        "    shear_matrix = np.array([[1, -np.sin(shear), 0],\r\n",
        "                             [0, np.cos(shear), 0],\r\n",
        "                             [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x[0].shape[row_index], x[0].shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(shear_matrix, h, w)\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        results.append( apply_transform(data, transform_matrix, channel_index, fill_mode, cval))\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# swirl\r\n",
        "def swirl(x, center=None, strength=1, radius=100, rotation=0, output_shape=None, order=1, mode='constant', cval=0, clip=True, preserve_range=False, is_random=False):\r\n",
        "    \"\"\"Swirl an image randomly or non-randomly, see `scikit-image swirl API <http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.swirl>`_\r\n",
        "    and `example <http://scikit-image.org/docs/dev/auto_examples/plot_swirl.html>`_.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    center : (row, column) tuple or (2,) ndarray, optional\r\n",
        "        Center coordinate of transformation.\r\n",
        "    strength : float, optional\r\n",
        "        The amount of swirling applied.\r\n",
        "    radius : float, optional\r\n",
        "        The extent of the swirl in pixels. The effect dies out rapidly beyond radius.\r\n",
        "    rotation : float, (degree) optional\r\n",
        "        Additional rotation applied to the image, usually [0, 360], relates to center.\r\n",
        "    output_shape : tuple (rows, cols), optional\r\n",
        "        Shape of the output image generated. By default the shape of the input image is preserved.\r\n",
        "    order : int, optional\r\n",
        "        The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See skimage.transform.warp for detail.\r\n",
        "    mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional\r\n",
        "        Points outside the boundaries of the input are filled according to the given mode, with ‘constant’ used as the default. Modes match the behaviour of numpy.pad.\r\n",
        "    cval : float, optional\r\n",
        "        Used in conjunction with mode ‘constant’, the value outside the image boundaries.\r\n",
        "    clip : bool, optional\r\n",
        "        Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.\r\n",
        "    preserve_range : bool, optional\r\n",
        "        Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of img_as_float.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, random swirl.\r\n",
        "            - random center = [(0 ~ x.shape[0]), (0 ~ x.shape[1])]\r\n",
        "            - random strength = [0, strength]\r\n",
        "            - random radius = [1e-10, radius]\r\n",
        "            - random rotation = [-rotation, rotation]\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> x --> [row, col, 1] greyscale\r\n",
        "    >>> x = swirl(x, strength=4, radius=100)\r\n",
        "    \"\"\"\r\n",
        "    assert radius != 0, Exception(\"Invalid radius value\")\r\n",
        "    rotation = np.pi / 180 * rotation\r\n",
        "    if is_random:\r\n",
        "        center_h = int(np.random.uniform(0, x.shape[0]))\r\n",
        "        center_w = int(np.random.uniform(0, x.shape[1]))\r\n",
        "        center = (center_h, center_w)\r\n",
        "        strength = np.random.uniform(0, strength)\r\n",
        "        radius = np.random.uniform(1e-10, radius)\r\n",
        "        rotation = np.random.uniform(-rotation, rotation)\r\n",
        "\r\n",
        "    max_v = np.max(x)\r\n",
        "    if max_v > 1:   # Note: the input of this fn should be [-1, 1], rescale is required.\r\n",
        "        x = x / max_v\r\n",
        "    swirled = skimage.transform.swirl(x, center=center, strength=strength, radius=radius, rotation=rotation,\r\n",
        "        output_shape=output_shape, order=order, mode=mode, cval=cval, clip=clip, preserve_range=preserve_range)\r\n",
        "    if max_v > 1:\r\n",
        "        swirled = swirled * max_v\r\n",
        "    return swirled\r\n",
        "\r\n",
        "def swirl_multi(x, center=None, strength=1, radius=100, rotation=0, output_shape=None, order=1, mode='constant', cval=0, clip=True, preserve_range=False, is_random=False):\r\n",
        "    \"\"\"Swirl multiple images with the same arguments, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``swirl``.\r\n",
        "    \"\"\"\r\n",
        "    assert radius != 0, Exception(\"Invalid radius value\")\r\n",
        "    rotation = np.pi / 180 * rotation\r\n",
        "    if is_random:\r\n",
        "        center_h = int(np.random.uniform(0, x[0].shape[0]))\r\n",
        "        center_w = int(np.random.uniform(0, x[0].shape[1]))\r\n",
        "        center = (center_h, center_w)\r\n",
        "        strength = np.random.uniform(0, strength)\r\n",
        "        radius = np.random.uniform(1e-10, radius)\r\n",
        "        rotation = np.random.uniform(-rotation, rotation)\r\n",
        "\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        max_v = np.max(data)\r\n",
        "        if max_v > 1:   # Note: the input of this fn should be [-1, 1], rescale is required.\r\n",
        "            data = data / max_v\r\n",
        "        swirled = skimage.transform.swirl(data, center=center, strength=strength, radius=radius, rotation=rotation,\r\n",
        "            output_shape=output_shape, order=order, mode=mode, cval=cval, clip=clip, preserve_range=preserve_range)\r\n",
        "        if max_v > 1:\r\n",
        "            swirled = swirled * max_v\r\n",
        "        results.append( swirled )\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# elastic_transform\r\n",
        "\r\n",
        "from scipy.ndimage.interpolation import map_coordinates\r\n",
        "from scipy.ndimage.filters import gaussian_filter\r\n",
        "def elastic_transform(x, alpha, sigma, mode=\"constant\", cval=0, is_random=False):\r\n",
        "    \"\"\"Elastic deformation of images as described in `[Simard2003] <http://deeplearning.cs.cmu.edu/pdfs/Simard.pdf>`_ .\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array, a greyscale image.\r\n",
        "    alpha : scalar factor.\r\n",
        "    sigma : scalar or sequence of scalars, the smaller the sigma, the more transformation.\r\n",
        "        Standard deviation for Gaussian kernel. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.\r\n",
        "    mode : default constant, see `scipy.ndimage.filters.gaussian_filter <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.filters.gaussian_filter.html>`_.\r\n",
        "    cval : float, optional. Used in conjunction with mode ‘constant’, the value outside the image boundaries.\r\n",
        "    is_random : boolean, default False\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> x = elastic_transform(x, alpha = x.shape[1] * 3, sigma = x.shape[1] * 0.07)\r\n",
        "    References\r\n",
        "    ------------\r\n",
        "    - `Github <https://gist.github.com/chsasank/4d8f68caf01f041a6453e67fb30f8f5a>`_.\r\n",
        "    - `Kaggle <https://www.kaggle.com/pscion/ultrasound-nerve-segmentation/elastic-transform-for-data-augmentation-0878921a>`_\r\n",
        "    \"\"\"\r\n",
        "    if is_random is False:\r\n",
        "        random_state = np.random.RandomState(None)\r\n",
        "    else:\r\n",
        "        random_state = np.random.RandomState(int(time.time()))\r\n",
        "    #\r\n",
        "    is_3d = False\r\n",
        "    if len(x.shape) == 3 and x.shape[-1] == 1:\r\n",
        "        x = x[:,:,0]\r\n",
        "        is_3d = True\r\n",
        "    elif len(x.shape) == 3 and x.shape[-1] != 1:\r\n",
        "        raise Exception(\"Only support greyscale image\")\r\n",
        "    assert len(x.shape)==2\r\n",
        "\r\n",
        "    shape = x.shape\r\n",
        "\r\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=mode, cval=cval) * alpha\r\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=mode, cval=cval) * alpha\r\n",
        "\r\n",
        "    x_, y_ = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\r\n",
        "    indices = np.reshape(x_ + dx, (-1, 1)), np.reshape(y_ + dy, (-1, 1))\r\n",
        "    if is_3d:\r\n",
        "        return map_coordinates(x, indices, order=1).reshape((shape[0], shape[1], 1))\r\n",
        "    else:\r\n",
        "        return map_coordinates(x, indices, order=1).reshape(shape)\r\n",
        "\r\n",
        "def elastic_transform_multi(x, alpha, sigma, mode=\"constant\", cval=0, is_random=False):\r\n",
        "    \"\"\"Elastic deformation of images as described in `[Simard2003] <http://deeplearning.cs.cmu.edu/pdfs/Simard.pdf>`_.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "    others : see ``elastic_transform``.\r\n",
        "    \"\"\"\r\n",
        "    if is_random is False:\r\n",
        "        random_state = np.random.RandomState(None)\r\n",
        "    else:\r\n",
        "        random_state = np.random.RandomState(int(time.time()))\r\n",
        "\r\n",
        "    shape = x[0].shape\r\n",
        "    if len(shape) == 3:\r\n",
        "        shape = (shape[0], shape[1])\r\n",
        "    new_shape = random_state.rand(*shape)\r\n",
        "\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        is_3d = False\r\n",
        "        if len(data.shape) == 3 and data.shape[-1] == 1:\r\n",
        "            data = data[:,:,0]\r\n",
        "            is_3d = True\r\n",
        "        elif len(data.shape) == 3 and data.shape[-1] != 1:\r\n",
        "            raise Exception(\"Only support greyscale image\")\r\n",
        "        assert len(data.shape)==2\r\n",
        "\r\n",
        "        dx = gaussian_filter((new_shape * 2 - 1), sigma, mode=mode, cval=cval) * alpha\r\n",
        "        dy = gaussian_filter((new_shape * 2 - 1), sigma, mode=mode, cval=cval) * alpha\r\n",
        "\r\n",
        "        x_, y_ = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\r\n",
        "        indices = np.reshape(x_ + dx, (-1, 1)), np.reshape(y_ + dy, (-1, 1))\r\n",
        "        # print(data.shape)\r\n",
        "        if is_3d:\r\n",
        "            results.append( map_coordinates(data, indices, order=1).reshape((shape[0], shape[1], 1)))\r\n",
        "        else:\r\n",
        "            results.append( map_coordinates(data, indices, order=1).reshape(shape) )\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# zoom\r\n",
        "def zoom(x, zoom_range=(0.9, 1.1), is_random=False, row_index=0, col_index=1, channel_index=2,\r\n",
        "                fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Zoom in and out of a single image, randomly or non-randomly.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    zoom_range : list or tuple\r\n",
        "        - If is_random=False, (h, w) are the fixed zoom factor for row and column axies, factor small than one is zoom in.\r\n",
        "        - If is_random=True, (min zoom out, max zoom out) for x and y with different random zoom in/out factor.\r\n",
        "        e.g (0.5, 1) zoom in 1~2 times.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly zoom.\r\n",
        "    row_index, col_index, channel_index : int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    fill_mode : string\r\n",
        "        Method to fill missing pixel, default ‘nearest’, more options ‘constant’, ‘reflect’ or ‘wrap’.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    cval : scalar, optional\r\n",
        "        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    \"\"\"\r\n",
        "    if len(zoom_range) != 2:\r\n",
        "        raise Exception('zoom_range should be a tuple or list of two floats. '\r\n",
        "                        'Received arg: ', zoom_range)\r\n",
        "    if is_random:\r\n",
        "        if zoom_range[0] == 1 and zoom_range[1] == 1:\r\n",
        "            zx, zy = 1, 1\r\n",
        "            print(\" random_zoom : not zoom in/out\")\r\n",
        "        else:\r\n",
        "            zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\r\n",
        "    else:\r\n",
        "        zx, zy = zoom_range\r\n",
        "    # print(zx, zy)\r\n",
        "    zoom_matrix = np.array([[zx, 0, 0],\r\n",
        "                            [0, zy, 0],\r\n",
        "                            [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x.shape[row_index], x.shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\r\n",
        "    x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\r\n",
        "    return x\r\n",
        "\r\n",
        "def zoom_multi(x, zoom_range=(0.9, 1.1), is_random=False,\r\n",
        "        row_index=0, col_index=1, channel_index=2, fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Zoom in and out of images with the same arguments, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``zoom``.\r\n",
        "    \"\"\"\r\n",
        "    if len(zoom_range) != 2:\r\n",
        "        raise Exception('zoom_range should be a tuple or list of two floats. '\r\n",
        "                        'Received arg: ', zoom_range)\r\n",
        "\r\n",
        "    if is_random:\r\n",
        "        if zoom_range[0] == 1 and zoom_range[1] == 1:\r\n",
        "            zx, zy = 1, 1\r\n",
        "            print(\" random_zoom : not zoom in/out\")\r\n",
        "        else:\r\n",
        "            zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\r\n",
        "    else:\r\n",
        "        zx, zy = zoom_range\r\n",
        "\r\n",
        "    zoom_matrix = np.array([[zx, 0, 0],\r\n",
        "                            [0, zy, 0],\r\n",
        "                            [0, 0, 1]])\r\n",
        "\r\n",
        "    h, w = x[0].shape[row_index], x[0].shape[col_index]\r\n",
        "    transform_matrix = transform_matrix_offset_center(zoom_matrix, h, w)\r\n",
        "    # x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)\r\n",
        "    # return x\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        results.append( apply_transform(data, transform_matrix, channel_index, fill_mode, cval))\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# image = tf.image.random_brightness(image, max_delta=32. / 255.)\r\n",
        "# image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\r\n",
        "# image = tf.image.random_hue(image, max_delta=0.032)\r\n",
        "# image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\r\n",
        "\r\n",
        "# brightness\r\n",
        "def brightness(x, gamma=1, gain=1, is_random=False):\r\n",
        "    \"\"\"Change the brightness of a single image, randomly or non-randomly.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    gamma : float, small than 1 means brighter.\r\n",
        "        Non negative real number. Default value is 1.\r\n",
        "        - If is_random is True, gamma in a range of (1-gamma, 1+gamma).\r\n",
        "    gain : float\r\n",
        "        The constant multiplier. Default value is 1.\r\n",
        "    is_random : boolean, default False\r\n",
        "        - If True, randomly change brightness.\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `skimage.exposure.adjust_gamma <http://scikit-image.org/docs/dev/api/skimage.exposure.html>`_\r\n",
        "    - `chinese blog <http://www.cnblogs.com/denny402/p/5124402.html>`_\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        gamma = np.random.uniform(1-gamma, 1+gamma)\r\n",
        "    x = exposure.adjust_gamma(x, gamma, gain)\r\n",
        "    return x\r\n",
        "\r\n",
        "def brightness_multi(x, gamma=1, gain=1, is_random=False):\r\n",
        "    \"\"\"Change the brightness of multiply images, randomly or non-randomly.\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``brightness``.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        gamma = np.random.uniform(1-gamma, 1+gamma)\r\n",
        "\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        results.append( exposure.adjust_gamma(data, gamma, gain) )\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "\r\n",
        "# contrast\r\n",
        "def constant(x, cutoff=0.5, gain=10, inv=False, is_random=False):\r\n",
        "    # TODO\r\n",
        "    x = exposure.adjust_sigmoid(x, cutoff=cutoff, gain=gain, inv=inv)\r\n",
        "    return x\r\n",
        "\r\n",
        "def constant_multi():\r\n",
        "    #TODO\r\n",
        "    pass\r\n",
        "\r\n",
        "# resize\r\n",
        "def imresize(x, size=[100, 100], interp='bilinear', mode=None):\r\n",
        "    \"\"\"Resize an image by given output size and method. Warning, this function\r\n",
        "    will rescale the value to [0, 255].\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    size : int, float or tuple (h, w)\r\n",
        "        - int, Percentage of current size.\r\n",
        "        - float, Fraction of current size.\r\n",
        "        - tuple, Size of the output image.\r\n",
        "    interp : str, optional\r\n",
        "        Interpolation to use for re-sizing (‘nearest’, ‘lanczos’, ‘bilinear’, ‘bicubic’ or ‘cubic’).\r\n",
        "    mode : str, optional\r\n",
        "        The PIL image mode (‘P’, ‘L’, etc.) to convert arr before resizing.\r\n",
        "    Returns\r\n",
        "    --------\r\n",
        "    imresize : ndarray\r\n",
        "    The resized array of image.\r\n",
        "    References\r\n",
        "    ------------\r\n",
        "    - `scipy.misc.imresize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imresize.html>`_\r\n",
        "    \"\"\"\r\n",
        "    if x.shape[-1] == 1:\r\n",
        "        # greyscale\r\n",
        "        x = scipy.misc.imresize(x[:,:,0], size, interp=interp, mode=mode)\r\n",
        "        return x[:, :, np.newaxis]\r\n",
        "    elif x.shape[-1] == 3:\r\n",
        "        # rgb, bgr ..\r\n",
        "        return scipy.misc.imresize(x, size, interp=interp, mode=mode)\r\n",
        "    else:\r\n",
        "        raise Exception(\"Unsupported channel %d\" % x.shape[-1])\r\n",
        "\r\n",
        "# normailization\r\n",
        "def samplewise_norm(x, rescale=None, samplewise_center=False, samplewise_std_normalization=False,\r\n",
        "            channel_index=2, epsilon=1e-7):\r\n",
        "    \"\"\"Normalize an image by rescale, samplewise centering and samplewise centering in order.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    rescale : rescaling factor.\r\n",
        "            If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation)\r\n",
        "    samplewise_center : set each sample mean to 0.\r\n",
        "    samplewise_std_normalization : divide each input by its std.\r\n",
        "    epsilon : small position value for dividing standard deviation.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> x = samplewise_norm(x, samplewise_center=True, samplewise_std_normalization=True)\r\n",
        "    >>> print(x.shape, np.mean(x), np.std(x))\r\n",
        "    ... (160, 176, 1), 0.0, 1.0\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    When samplewise_center and samplewise_std_normalization are True.\r\n",
        "    - For greyscale image, every pixels are subtracted and divided by the mean and std of whole image.\r\n",
        "    - For RGB image, every pixels are subtracted and divided by the mean and std of this pixel i.e. the mean and std of a pixel is 0 and 1.\r\n",
        "    \"\"\"\r\n",
        "    if rescale:\r\n",
        "        x *= rescale\r\n",
        "\r\n",
        "    if x.shape[channel_index] == 1:\r\n",
        "        # greyscale\r\n",
        "        if samplewise_center:\r\n",
        "            x = x - np.mean(x)\r\n",
        "        if samplewise_std_normalization:\r\n",
        "            x = x / np.std(x)\r\n",
        "        return x\r\n",
        "    elif x.shape[channel_index] == 3:\r\n",
        "        # rgb\r\n",
        "        if samplewise_center:\r\n",
        "            x = x - np.mean(x, axis=channel_index, keepdims=True)\r\n",
        "        if samplewise_std_normalization:\r\n",
        "            x = x / (np.std(x, axis=channel_index, keepdims=True) + epsilon)\r\n",
        "        return x\r\n",
        "    else:\r\n",
        "        raise Exception(\"Unsupported channels %d\" % x.shape[channel_index])\r\n",
        "\r\n",
        "def featurewise_norm(x, mean=None, std=None, epsilon=1e-7):\r\n",
        "    \"\"\"Normalize every pixels by the same given mean and std, which are usually\r\n",
        "    compute from all examples.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    mean : value for subtraction.\r\n",
        "    std : value for division.\r\n",
        "    epsilon : small position value for dividing standard deviation.\r\n",
        "    \"\"\"\r\n",
        "    if mean:\r\n",
        "        x = x - mean\r\n",
        "    if std:\r\n",
        "        x = x / (std + epsilon)\r\n",
        "    return x\r\n",
        "\r\n",
        "# whitening\r\n",
        "def get_zca_whitening_principal_components_img(X):\r\n",
        "    \"\"\"Return the ZCA whitening principal components matrix.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        Batch of image with dimension of [n_example, row, col, channel] (default).\r\n",
        "    \"\"\"\r\n",
        "    flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\r\n",
        "    print(\"zca : computing sigma ..\")\r\n",
        "    sigma = np.dot(flatX.T, flatX) / flatX.shape[0]\r\n",
        "    print(\"zca : computing U, S and V ..\")\r\n",
        "    U, S, V = linalg.svd(sigma)\r\n",
        "    print(\"zca : computing principal components ..\")\r\n",
        "    principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\r\n",
        "    return principal_components\r\n",
        "\r\n",
        "def zca_whitening(x, principal_components):\r\n",
        "    \"\"\"Apply ZCA whitening on an image by given principal components matrix.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    principal_components : matrix from ``get_zca_whitening_principal_components_img``.\r\n",
        "    \"\"\"\r\n",
        "    # flatx = np.reshape(x, (x.size))\r\n",
        "    print(principal_components.shape, x.shape)  # ((28160, 28160), (160, 176, 1))\r\n",
        "    # flatx = np.reshape(x, (x.shape))\r\n",
        "    # flatx = np.reshape(x, (x.shape[0], ))\r\n",
        "    print(flatx.shape)  # (160, 176, 1)\r\n",
        "    whitex = np.dot(flatx, principal_components)\r\n",
        "    x = np.reshape(whitex, (x.shape[0], x.shape[1], x.shape[2]))\r\n",
        "    return x\r\n",
        "\r\n",
        "# developing\r\n",
        "# def barrel_transform(x, intensity):\r\n",
        "#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py\r\n",
        "#     # TODO\r\n",
        "#     pass\r\n",
        "#\r\n",
        "# def barrel_transform_multi(x, intensity):\r\n",
        "#     # https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py\r\n",
        "#     # TODO\r\n",
        "#     pass\r\n",
        "\r\n",
        "# channel shift\r\n",
        "def channel_shift(x, intensity, is_random=False, channel_index=2):\r\n",
        "    \"\"\"Shift the channels of an image, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`_.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    intensity : float\r\n",
        "        Intensity of shifting.\r\n",
        "    is_random : boolean, default False\r\n",
        "        If True, randomly shift.\r\n",
        "    channel_index : int\r\n",
        "        Index of channel, default 2.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        factor = np.random.uniform(-intensity, intensity)\r\n",
        "    else:\r\n",
        "        factor = intensity\r\n",
        "    x = np.rollaxis(x, channel_index, 0)\r\n",
        "    min_x, max_x = np.min(x), np.max(x)\r\n",
        "    channel_images = [np.clip(x_channel + factor, min_x, max_x)\r\n",
        "                      for x_channel in x]\r\n",
        "    x = np.stack(channel_images, axis=0)\r\n",
        "    x = np.rollaxis(x, 0, channel_index+1)\r\n",
        "    return x\r\n",
        "    # x = np.rollaxis(x, channel_index, 0)\r\n",
        "    # min_x, max_x = np.min(x), np.max(x)\r\n",
        "    # channel_images = [np.clip(x_channel + np.random.uniform(-intensity, intensity), min_x, max_x)\r\n",
        "    #                   for x_channel in x]\r\n",
        "    # x = np.stack(channel_images, axis=0)\r\n",
        "    # x = np.rollaxis(x, 0, channel_index+1)\r\n",
        "    # return x\r\n",
        "\r\n",
        "def channel_shift_multi(x, intensity, channel_index=2):\r\n",
        "    \"\"\"Shift the channels of images with the same arguments, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`_ .\r\n",
        "    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : list of numpy array\r\n",
        "        List of images with dimension of [n_images, row, col, channel] (default).\r\n",
        "    others : see ``channel_shift``.\r\n",
        "    \"\"\"\r\n",
        "    if is_random:\r\n",
        "        factor = np.random.uniform(-intensity, intensity)\r\n",
        "    else:\r\n",
        "        factor = intensity\r\n",
        "\r\n",
        "    results = []\r\n",
        "    for data in x:\r\n",
        "        data = np.rollaxis(data, channel_index, 0)\r\n",
        "        min_x, max_x = np.min(data), np.max(data)\r\n",
        "        channel_images = [np.clip(x_channel + factor, min_x, max_x)\r\n",
        "                          for x_channel in x]\r\n",
        "        data = np.stack(channel_images, axis=0)\r\n",
        "        data = np.rollaxis(x, 0, channel_index+1)\r\n",
        "        results.append( data )\r\n",
        "    return np.asarray(results)\r\n",
        "\r\n",
        "# noise\r\n",
        "def drop(x, keep=0.5):\r\n",
        "    \"\"\"Randomly set some pixels to zero by a given keeping probability.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] or [row, col].\r\n",
        "    keep : float (0, 1)\r\n",
        "        The keeping probability, the lower more values will be set to zero.\r\n",
        "    \"\"\"\r\n",
        "    if len(x.shape) == 3:\r\n",
        "        if x.shape[-1]==3: # color\r\n",
        "            img_size = x.shape\r\n",
        "            mask = np.random.binomial(n=1, p=keep, size=x.shape[:-1])\r\n",
        "            for i in range(3):\r\n",
        "                x[:,:,i] = np.multiply(x[:,:,i] , mask)\r\n",
        "        elif x.shape[-1]==1: # greyscale image\r\n",
        "            img_size = x.shape\r\n",
        "            x = np.multiply(x , np.random.binomial(n=1, p=keep, size=img_size))\r\n",
        "        else:\r\n",
        "            raise Exception(\"Unsupported shape {}\".format(x.shape))\r\n",
        "    elif len(x.shape) == 2 or 1: # greyscale matrix (image) or vector\r\n",
        "        img_size = x.shape\r\n",
        "        x = np.multiply(x , np.random.binomial(n=1, p=keep, size=img_size))\r\n",
        "    else:\r\n",
        "        raise Exception(\"Unsupported shape {}\".format(x.shape))\r\n",
        "    return x\r\n",
        "\r\n",
        "# x = np.asarray([[1,2,3,4,5,6,7,8,9,10],[1,2,3,4,5,6,7,8,9,10]])\r\n",
        "# x = np.asarray([x,x,x,x,x,x])\r\n",
        "# x.shape = 10, 4, 3\r\n",
        "# # print(x)\r\n",
        "# # exit()\r\n",
        "# print(x.shape)\r\n",
        "# # exit()\r\n",
        "# print(drop(x, keep=1.))\r\n",
        "# exit()\r\n",
        "\r\n",
        "# manual transform\r\n",
        "def transform_matrix_offset_center(matrix, x, y):\r\n",
        "    \"\"\"Return transform matrix offset center.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    matrix : numpy array\r\n",
        "        Transform matrix\r\n",
        "    x, y : int\r\n",
        "        Size of image.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - See ``rotation``, ``shear``, ``zoom``.\r\n",
        "    \"\"\"\r\n",
        "    o_x = float(x) / 2 + 0.5\r\n",
        "    o_y = float(y) / 2 + 0.5\r\n",
        "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\r\n",
        "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\r\n",
        "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\r\n",
        "    return transform_matrix\r\n",
        "\r\n",
        "\r\n",
        "def apply_transform(x, transform_matrix, channel_index=2, fill_mode='nearest', cval=0.):\r\n",
        "    \"\"\"Return transformed images by given transform_matrix from ``transform_matrix_offset_center``.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : numpy array\r\n",
        "        Batch of images with dimension of 3, [batch_size, row, col, channel].\r\n",
        "    transform_matrix : numpy array\r\n",
        "        Transform matrix (offset center), can be generated by ``transform_matrix_offset_center``\r\n",
        "    channel_index : int\r\n",
        "        Index of channel, default 2.\r\n",
        "    fill_mode : string\r\n",
        "        Method to fill missing pixel, default ‘nearest’, more options ‘constant’, ‘reflect’ or ‘wrap’\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    cval : scalar, optional\r\n",
        "        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0\r\n",
        "        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - See ``rotation``, ``shift``, ``shear``, ``zoom``.\r\n",
        "    \"\"\"\r\n",
        "    x = np.rollaxis(x, channel_index, 0)\r\n",
        "    final_affine_matrix = transform_matrix[:2, :2]\r\n",
        "    final_offset = transform_matrix[:2, 2]\r\n",
        "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\r\n",
        "                      final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\r\n",
        "    x = np.stack(channel_images, axis=0)\r\n",
        "    x = np.rollaxis(x, 0, channel_index+1)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def projective_transform_by_points(x, src, dst, map_args={}, output_shape=None, order=1, mode='constant', cval=0.0, clip=True, preserve_range=False):\r\n",
        "    \"\"\"Projective transform by given coordinates, usually 4 coordinates. see `scikit-image <http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html>`_.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    x : numpy array\r\n",
        "        An image with dimension of [row, col, channel] (default).\r\n",
        "    src : list or numpy\r\n",
        "        The original coordinates, usually 4 coordinates of (x, y).\r\n",
        "    dst : list or numpy\r\n",
        "        The coordinates after transformation, the number of coordinates is the same with src.\r\n",
        "    map_args : dict, optional\r\n",
        "        Keyword arguments passed to inverse_map.\r\n",
        "    output_shape : tuple (rows, cols), optional\r\n",
        "        Shape of the output image generated. By default the shape of the input image is preserved. Note that, even for multi-band images, only rows and columns need to be specified.\r\n",
        "    order : int, optional\r\n",
        "        The order of interpolation. The order has to be in the range 0-5:\r\n",
        "        - 0 Nearest-neighbor\r\n",
        "        - 1 Bi-linear (default)\r\n",
        "        - 2 Bi-quadratic\r\n",
        "        - 3 Bi-cubic\r\n",
        "        - 4 Bi-quartic\r\n",
        "        - 5 Bi-quintic\r\n",
        "    mode : {‘constant’, ‘edge’, ‘symmetric’, ‘reflect’, ‘wrap’}, optional\r\n",
        "        Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of numpy.pad.\r\n",
        "    cval : float, optional\r\n",
        "        Used in conjunction with mode ‘constant’, the value outside the image boundaries.\r\n",
        "    clip : bool, optional\r\n",
        "        Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.\r\n",
        "    preserve_range : bool, optional\r\n",
        "        Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of img_as_float.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> Assume X is an image from CIFAR 10, i.e. shape == (32, 32, 3)\r\n",
        "    >>> src = [[0,0],[0,32],[32,0],[32,32]]\r\n",
        "    >>> dst = [[10,10],[0,32],[32,0],[32,32]]\r\n",
        "    >>> x = projective_transform_by_points(X, src, dst)\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `scikit-image : geometric transformations <http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html>`_\r\n",
        "    - `scikit-image : examples <http://scikit-image.org/docs/dev/auto_examples/index.html>`_\r\n",
        "    \"\"\"\r\n",
        "    if type(src) is list:   # convert to numpy\r\n",
        "        src = np.array(src)\r\n",
        "    if type(dst) is list:\r\n",
        "        dst = np.array(dst)\r\n",
        "    if np.max(x)>1:         # convert to [0, 1]\r\n",
        "        x = x/255\r\n",
        "\r\n",
        "    m = transform.ProjectiveTransform()\r\n",
        "    m.estimate(dst, src)\r\n",
        "    warped = transform.warp(x, m,  map_args=map_args, output_shape=output_shape, order=order, mode=mode, cval=cval, clip=clip, preserve_range=preserve_range)\r\n",
        "    return warped\r\n",
        "\r\n",
        "# Numpy and PIL\r\n",
        "def array_to_img(x, dim_ordering=(0,1,2), scale=True):\r\n",
        "    \"\"\"Converts a numpy array to PIL image object (uint8 format).\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : numpy array\r\n",
        "        A image with dimension of 3 and channels of 1 or 3.\r\n",
        "    dim_ordering : list or tuple of 3 int\r\n",
        "        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\r\n",
        "    scale : boolean, default is True\r\n",
        "        If True, converts image to [0, 255] from any range of value like [-1, 2].\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `PIL Image.fromarray <http://pillow.readthedocs.io/en/3.1.x/reference/Image.html?highlight=fromarray>`_\r\n",
        "    \"\"\"\r\n",
        "    from PIL import Image\r\n",
        "    # if dim_ordering == 'default':\r\n",
        "    #     dim_ordering = K.image_dim_ordering()\r\n",
        "    # if dim_ordering == 'th':  # theano\r\n",
        "    #     x = x.transpose(1, 2, 0)\r\n",
        "    x = x.transpose(dim_ordering)\r\n",
        "    if scale:\r\n",
        "        x += max(-np.min(x), 0)\r\n",
        "        x_max = np.max(x)\r\n",
        "        if x_max != 0:\r\n",
        "            # print(x_max)\r\n",
        "            # x /= x_max\r\n",
        "            x = x / x_max\r\n",
        "        x *= 255\r\n",
        "    if x.shape[2] == 3:\r\n",
        "        # RGB\r\n",
        "        return Image.fromarray(x.astype('uint8'), 'RGB')\r\n",
        "    elif x.shape[2] == 1:\r\n",
        "        # grayscale\r\n",
        "        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')\r\n",
        "    else:\r\n",
        "        raise Exception('Unsupported channel number: ', x.shape[2])\r\n",
        "\r\n",
        "\r\n",
        "## Sequence\r\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='post', truncating='pre', value=0.):\r\n",
        "    \"\"\"Pads each sequence to the same length:\r\n",
        "    the length of the longest sequence.\r\n",
        "    If maxlen is provided, any sequence longer\r\n",
        "    than maxlen is truncated to maxlen.\r\n",
        "    Truncation happens off either the beginning (default) or\r\n",
        "    the end of the sequence.\r\n",
        "    Supports post-padding and pre-padding (default).\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sequences : list of lists where each element is a sequence\r\n",
        "    maxlen : int, maximum length\r\n",
        "    dtype : type to cast the resulting sequence.\r\n",
        "    padding : 'pre' or 'post', pad either before or after each sequence.\r\n",
        "    truncating : 'pre' or 'post', remove values from sequences larger than\r\n",
        "        maxlen either in the beginning or in the end of the sequence\r\n",
        "    value : float, value to pad the sequences to the desired value.\r\n",
        "    Returns\r\n",
        "    ----------\r\n",
        "    x : numpy array with dimensions (number_of_sequences, maxlen)\r\n",
        "    Examples\r\n",
        "    ----------\r\n",
        "    >>> sequences = [[1,1,1,1,1],[2,2,2],[3,3]]\r\n",
        "    >>> sequences = pad_sequences(sequences, maxlen=None, dtype='int32',\r\n",
        "    ...                  padding='post', truncating='pre', value=0.)\r\n",
        "    ... [[1 1 1 1 1]\r\n",
        "    ...  [2 2 2 0 0]\r\n",
        "    ...  [3 3 0 0 0]]\r\n",
        "    \"\"\"\r\n",
        "    lengths = [len(s) for s in sequences]\r\n",
        "\r\n",
        "    nb_samples = len(sequences)\r\n",
        "    if maxlen is None:\r\n",
        "        maxlen = np.max(lengths)\r\n",
        "\r\n",
        "    # take the sample shape from the first non empty sequence\r\n",
        "    # checking for consistency in the main loop below.\r\n",
        "    sample_shape = tuple()\r\n",
        "    for s in sequences:\r\n",
        "        if len(s) > 0:\r\n",
        "            sample_shape = np.asarray(s).shape[1:]\r\n",
        "            break\r\n",
        "\r\n",
        "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\r\n",
        "    for idx, s in enumerate(sequences):\r\n",
        "        if len(s) == 0:\r\n",
        "            continue  # empty list was found\r\n",
        "        if truncating == 'pre':\r\n",
        "            trunc = s[-maxlen:]\r\n",
        "        elif truncating == 'post':\r\n",
        "            trunc = s[:maxlen]\r\n",
        "        else:\r\n",
        "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\r\n",
        "\r\n",
        "        # check `trunc` has expected shape\r\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\r\n",
        "        if trunc.shape[1:] != sample_shape:\r\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\r\n",
        "                             (trunc.shape[1:], idx, sample_shape))\r\n",
        "\r\n",
        "        if padding == 'post':\r\n",
        "            x[idx, :len(trunc)] = trunc\r\n",
        "        elif padding == 'pre':\r\n",
        "            x[idx, -len(trunc):] = trunc\r\n",
        "        else:\r\n",
        "            raise ValueError('Padding type \"%s\" not understood' % padding)\r\n",
        "    return x\r\n",
        "\r\n",
        "def process_sequences(sequences, end_id=0, pad_val=0, is_shorten=True, remain_end_id=False):\r\n",
        "    \"\"\"Set all tokens(ids) after END token to the padding value, and then shorten (option) it to the maximum sequence length in this batch.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    sequences : numpy array or list of list with token IDs.\r\n",
        "        e.g. [[4,3,5,3,2,2,2,2], [5,3,9,4,9,2,2,3]]\r\n",
        "    end_id : int, the special token for END.\r\n",
        "    pad_val : int, replace the end_id and the ids after end_id to this value.\r\n",
        "    is_shorten : boolean, default True.\r\n",
        "        Shorten the sequences.\r\n",
        "    remain_end_id : boolean, default False.\r\n",
        "        Keep an end_id in the end.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> sentences_ids = [[4, 3, 5, 3, 2, 2, 2, 2],  <-- end_id is 2\r\n",
        "    ...                  [5, 3, 9, 4, 9, 2, 2, 3]]  <-- end_id is 2\r\n",
        "    >>> sentences_ids = precess_sequences(sentences_ids, end_id=vocab.end_id, pad_val=0, is_shorten=True)\r\n",
        "    ... [[4, 3, 5, 3, 0], [5, 3, 9, 4, 9]]\r\n",
        "    \"\"\"\r\n",
        "    max_length = 0\r\n",
        "    for i_s, seq in enumerate(sequences):\r\n",
        "        is_end = False\r\n",
        "        for i_w, n in enumerate(seq):\r\n",
        "            if n == end_id and is_end == False: # 1st time to see end_id\r\n",
        "                is_end = True\r\n",
        "                if max_length < i_w:\r\n",
        "                    max_length = i_w\r\n",
        "                if remain_end_id is False:\r\n",
        "                    seq[i_w] = pad_val      # set end_id to pad_val\r\n",
        "            elif is_end == True:\r\n",
        "                seq[i_w] = pad_val\r\n",
        "\r\n",
        "    if remain_end_id is True:\r\n",
        "        max_length += 1\r\n",
        "    if is_shorten:\r\n",
        "        for i, seq in enumerate(sequences):\r\n",
        "            sequences[i] = seq[:max_length]\r\n",
        "    return sequences\r\n",
        "\r\n",
        "def sequences_add_start_id(sequences, start_id=0, remove_last=False):\r\n",
        "    \"\"\"Add special start token(id) in the beginning of each sequence.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> sentences_ids = [[4,3,5,3,2,2,2,2], [5,3,9,4,9,2,2,3]]\r\n",
        "    >>> sentences_ids = sequences_add_start_id(sentences_ids, start_id=2)\r\n",
        "    ... [[2, 4, 3, 5, 3, 2, 2, 2, 2], [2, 5, 3, 9, 4, 9, 2, 2, 3]]\r\n",
        "    >>> sentences_ids = sequences_add_start_id(sentences_ids, start_id=2, remove_last=True)\r\n",
        "    ... [[2, 4, 3, 5, 3, 2, 2, 2], [2, 5, 3, 9, 4, 9, 2, 2]]\r\n",
        "    - For Seq2seq\r\n",
        "    >>> input = [a, b, c]\r\n",
        "    >>> target = [x, y, z]\r\n",
        "    >>> decode_seq = [start_id, a, b] <-- sequences_add_start_id(input, start_id, True)\r\n",
        "    \"\"\"\r\n",
        "    sequences_out = [[] for _ in range(len(sequences))]#[[]] * len(sequences)\r\n",
        "    for i in range(len(sequences)):\r\n",
        "        if remove_last:\r\n",
        "            sequences_out[i] = [start_id] + sequences[i][:-1]\r\n",
        "        else:\r\n",
        "            sequences_out[i] = [start_id] + sequences[i]\r\n",
        "    return sequences_out\r\n",
        "\r\n",
        "def sequences_get_mask(sequences, pad_val=0):\r\n",
        "    \"\"\"Return mask for sequences.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> sentences_ids = [[4, 0, 5, 3, 0, 0],\r\n",
        "    ...                  [5, 3, 9, 4, 9, 0]]\r\n",
        "    >>> mask = sequences_get_mask(sentences_ids, pad_val=0)\r\n",
        "    ... [[1 1 1 1 0 0]\r\n",
        "    ...  [1 1 1 1 1 0]]\r\n",
        "    \"\"\"\r\n",
        "    mask = np.ones_like(sequences)\r\n",
        "    for i, seq in enumerate(sequences):\r\n",
        "        for i_w in reversed(range(len(seq))):\r\n",
        "            if seq[i_w] == pad_val:\r\n",
        "                mask[i, i_w] = 0\r\n",
        "            else:\r\n",
        "                break   # <-- exit the for loop, prepcess next sequence\r\n",
        "    return mask\r\n",
        "\r\n",
        "\r\n",
        "## Text\r\n",
        "# see tensorlayer.nlp\r\n",
        "\r\n",
        "\r\n",
        "## Tensor Opt\r\n",
        "def distorted_images(images=None, height=24, width=24):\r\n",
        "    \"\"\"Distort images for generating more training data.\r\n",
        "    Features\r\n",
        "    ---------\r\n",
        "    They are cropped to height * width pixels randomly.\r\n",
        "    They are approximately whitened to make the model insensitive to dynamic range.\r\n",
        "    Randomly flip the image from left to right.\r\n",
        "    Randomly distort the image brightness.\r\n",
        "    Randomly distort the image contrast.\r\n",
        "    Whiten (Normalize) the images.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    images : 4D Tensor\r\n",
        "        The tensor or placeholder of images\r\n",
        "    height : int\r\n",
        "        The height for random crop.\r\n",
        "    width : int\r\n",
        "        The width for random crop.\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    result : tuple of Tensor\r\n",
        "        (Tensor for distorted images, Tensor for while loop index)\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\r\n",
        "    >>> sess = tf.InteractiveSession()\r\n",
        "    >>> batch_size = 128\r\n",
        "    >>> x = tf.placeholder(tf.float32, shape=[batch_size, 32, 32, 3])\r\n",
        "    >>> distorted_images_op = tl.preprocess.distorted_images(images=x, height=24, width=24)\r\n",
        "    >>> sess.run(tf.initialize_all_variables())\r\n",
        "    >>> feed_dict={x: X_train[0:batch_size,:,:,:]}\r\n",
        "    >>> distorted_images, idx = sess.run(distorted_images_op, feed_dict=feed_dict)\r\n",
        "    >>> tl.visualize.images2d(X_train[0:9,:,:,:], second=2, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\r\n",
        "    >>> tl.visualize.images2d(distorted_images[1:10,:,:,:], second=10, saveable=False, name='distorted_images', dtype=None, fig_idx=23012)\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    - The first image in 'distorted_images' should be removed.\r\n",
        "    References\r\n",
        "    -----------\r\n",
        "    - `tensorflow.models.image.cifar10.cifar10_input <https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/models/image/cifar10/cifar10_input.py>`_\r\n",
        "    \"\"\"\r\n",
        "    print(\"This function is deprecated, please use tf.map_fn instead, e.g:\\n   \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_brightness(img, max_delta=32. / 255.), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_hue(img, max_delta=0.032), t_image)\")\r\n",
        "    exit()\r\n",
        "    # print(\" [Warning] distorted_images will be deprecated due to speed, see TFRecord tutorial for more info...\")\r\n",
        "    try:\r\n",
        "        batch_size = int(images._shape[0])\r\n",
        "    except:\r\n",
        "        raise Exception('unknow batch_size of images')\r\n",
        "    distorted_x = tf.Variable(tf.constant(0.1, shape=[1, height, width, 3]))\r\n",
        "    i = tf.Variable(tf.constant(0))\r\n",
        "\r\n",
        "    c = lambda distorted_x, i: tf.less(i, batch_size)\r\n",
        "\r\n",
        "    def body(distorted_x, i):\r\n",
        "        # 1. Randomly crop a [height, width] section of the image.\r\n",
        "        image = tf.random_crop(tf.gather(images, i), [height, width, 3])\r\n",
        "        # 2. Randomly flip the image horizontally.\r\n",
        "        image = tf.image.random_flip_left_right(image)\r\n",
        "        # 3. Randomly change brightness.\r\n",
        "        image = tf.image.random_brightness(image, max_delta=63)\r\n",
        "        # 4. Randomly change contrast.\r\n",
        "        image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\r\n",
        "        # 5. Subtract off the mean and divide by the variance of the pixels.\r\n",
        "        image = tf.image.per_image_whitening(image)\r\n",
        "        # 6. Append the image to a batch.\r\n",
        "        image = tf.expand_dims(image, 0)\r\n",
        "        return tf.concat(0, [distorted_x, image]), tf.add(i, 1)\r\n",
        "\r\n",
        "    result = tf.while_loop(cond=c, body=body, loop_vars=(distorted_x, i), parallel_iterations=16)\r\n",
        "    return result\r\n",
        "\r\n",
        "\r\n",
        "def crop_central_whiten_images(images=None, height=24, width=24):\r\n",
        "    \"\"\"Crop the central of image, and normailize it for test data.\r\n",
        "    They are cropped to central of height * width pixels.\r\n",
        "    Whiten (Normalize) the images.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    images : 4D Tensor\r\n",
        "        The tensor or placeholder of images\r\n",
        "    height : int\r\n",
        "        The height for central crop.\r\n",
        "    width : int\r\n",
        "        The width for central crop.\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    result : tuple Tensor\r\n",
        "        (Tensor for distorted images, Tensor for while loop index)\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\r\n",
        "    >>> sess = tf.InteractiveSession()\r\n",
        "    >>> batch_size = 128\r\n",
        "    >>> x = tf.placeholder(tf.float32, shape=[batch_size, 32, 32, 3])\r\n",
        "    >>> central_images_op = tl.preprocess.crop_central_whiten_images(images=x, height=24, width=24)\r\n",
        "    >>> sess.run(tf.initialize_all_variables())\r\n",
        "    >>> feed_dict={x: X_train[0:batch_size,:,:,:]}\r\n",
        "    >>> central_images, idx = sess.run(central_images_op, feed_dict=feed_dict)\r\n",
        "    >>> tl.visualize.images2d(X_train[0:9,:,:,:], second=2, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\r\n",
        "    >>> tl.visualize.images2d(central_images[1:10,:,:,:], second=10, saveable=False, name='central_images', dtype=None, fig_idx=23012)\r\n",
        "    Notes\r\n",
        "    ------\r\n",
        "    The first image in 'central_images' should be removed.\r\n",
        "    Code References\r\n",
        "    ----------------\r\n",
        "    - ``tensorflow.models.image.cifar10.cifar10_input``\r\n",
        "    \"\"\"\r\n",
        "    print(\"This function is deprecated, please use tf.map_fn instead, e.g:\\n   \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_brightness(img, max_delta=32. / 255.), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5), t_image)\\n \\\r\n",
        "            t_image = tf.map_fn(lambda img: tf.image.random_hue(img, max_delta=0.032), t_image)\")\r\n",
        "    exit()\r\n",
        "    # print(\" [Warning] crop_central_whiten_images will be deprecated due to speed, see TFRecord tutorial for more info...\")\r\n",
        "    try:\r\n",
        "        batch_size = int(images._shape[0])\r\n",
        "    except:\r\n",
        "        raise Exception('unknow batch_size of images')\r\n",
        "    central_x = tf.Variable(tf.constant(0.1, shape=[1, height, width, 3]))\r\n",
        "    i = tf.Variable(tf.constant(0))\r\n",
        "\r\n",
        "    c = lambda central_x, i: tf.less(i, batch_size)\r\n",
        "\r\n",
        "    def body(central_x, i):\r\n",
        "        # 1. Crop the central [height, width] of the image.\r\n",
        "        image = tf.image.resize_image_with_crop_or_pad(tf.gather(images, i), height, width)\r\n",
        "        # 2. Subtract off the mean and divide by the variance of the pixels.\r\n",
        "        image = tf.image.per_image_whitening(image)\r\n",
        "        # 5. Append the image to a batch.\r\n",
        "        image = tf.expand_dims(image, 0)\r\n",
        "        return tf.concat(0, [central_x, image]), tf.add(i, 1)\r\n",
        "\r\n",
        "    result = tf.while_loop(cond=c, body=body, loop_vars=(central_x, i), parallel_iterations=16)\r\n",
        "    return result\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bbe0e58225e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorlayer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMuXFFDZexKc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from six.moves import xrange\r\n",
        "\r\n",
        "def discount_episode_rewards(rewards=[], gamma=0.99, mode=0):\r\n",
        "    \"\"\" Take 1D float array of rewards and compute discounted rewards for an\r\n",
        "    episode. When encount a non-zero value, consider as the end a of an episode.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    rewards : numpy list\r\n",
        "        a list of rewards\r\n",
        "    gamma : float\r\n",
        "        discounted factor\r\n",
        "    mode : int\r\n",
        "        if mode == 0, reset the discount process when encount a non-zero reward (Ping-pong game).\r\n",
        "        if mode == 1, would not reset the discount process.\r\n",
        "    Examples\r\n",
        "    ----------\r\n",
        "    >>> rewards = np.asarray([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1])\r\n",
        "    >>> gamma = 0.9\r\n",
        "    >>> discount_rewards = tl.rein.discount_episode_rewards(rewards, gamma)\r\n",
        "    >>> print(discount_rewards)\r\n",
        "    ... [ 0.72899997  0.81        0.89999998  1.          0.72899997  0.81\r\n",
        "    ... 0.89999998  1.          0.72899997  0.81        0.89999998  1.        ]\r\n",
        "    >>> discount_rewards = tl.rein.discount_episode_rewards(rewards, gamma, mode=1)\r\n",
        "    >>> print(discount_rewards)\r\n",
        "    ... [ 1.52110755  1.69011939  1.87791049  2.08656716  1.20729685  1.34144104\r\n",
        "    ... 1.49048996  1.65610003  0.72899997  0.81        0.89999998  1.        ]\r\n",
        "    \"\"\"\r\n",
        "    discounted_r = np.zeros_like(rewards, dtype=np.float32)\r\n",
        "    running_add = 0\r\n",
        "    for t in reversed(xrange(0, rewards.size)):\r\n",
        "        if mode == 0:\r\n",
        "            if rewards[t] != 0: running_add = 0\r\n",
        "\r\n",
        "        running_add = running_add * gamma + rewards[t]\r\n",
        "        discounted_r[t] = running_add\r\n",
        "    return discounted_r\r\n",
        "\r\n",
        "\r\n",
        "def cross_entropy_reward_loss(logits, actions, rewards, name=None):\r\n",
        "    \"\"\" Calculate the loss for Policy Gradient Network.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    logits : tensor\r\n",
        "        The network outputs without softmax. This function implements softmax\r\n",
        "        inside.\r\n",
        "    actions : tensor/ placeholder\r\n",
        "        The agent actions.\r\n",
        "    rewards : tensor/ placeholder\r\n",
        "        The rewards.\r\n",
        "    Examples\r\n",
        "    ----------\r\n",
        "    >>> states_batch_pl = tf.placeholder(tf.float32, shape=[None, D])   # observation for training\r\n",
        "    >>> network = tl.layers.InputLayer(states_batch_pl, name='input_layer')\r\n",
        "    >>> network = tl.layers.DenseLayer(network, n_units=H, act = tf.nn.relu, name='relu1')\r\n",
        "    >>> network = tl.layers.DenseLayer(network, n_units=3, act = tl.activation.identity, name='output_layer')\r\n",
        "    >>> probs = network.outputs\r\n",
        "    >>> sampling_prob = tf.nn.softmax(probs)\r\n",
        "    >>> actions_batch_pl = tf.placeholder(tf.int32, shape=[None])\r\n",
        "    >>> discount_rewards_batch_pl = tf.placeholder(tf.float32, shape=[None])\r\n",
        "    >>> loss = cross_entropy_reward_loss(probs, actions_batch_pl, discount_rewards_batch_pl)\r\n",
        "    >>> train_op = tf.train.RMSPropOptimizer(learning_rate, decay_rate).minimize(loss)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    try: # TF 1.0\r\n",
        "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=actions, logits=logits, name=name)\r\n",
        "    except:\r\n",
        "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, targets=actions)\r\n",
        "        # cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, actions)\r\n",
        "\r\n",
        "    try: ## TF1.0\r\n",
        "        loss = tf.reduce_sum(tf.multiply(cross_entropy, rewards))\r\n",
        "    except: ## TF0.12\r\n",
        "        loss = tf.reduce_sum(tf.mul(cross_entropy, rewards))   # element-wise mul\r\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "XRmhGMjPe2TA",
        "outputId": "02f53e93-a9e3-4c2f-e287-6f7ba84a7ba2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorlayer as tl\r\n",
        "from . import iterate\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import math\r\n",
        "import random\r\n",
        "\r\n",
        "\r\n",
        "def fit(sess, network, train_op, cost, X_train, y_train, x, y_, acc=None, batch_size=100,\r\n",
        "        n_epoch=100, print_freq=5, X_val=None, y_val=None, eval_train=True,\r\n",
        "        tensorboard=False, tensorboard_epoch_freq=5, tensorboard_weight_histograms=True, tensorboard_graph_vis=True):\r\n",
        "    \"\"\"Traing a given non time-series network by the given cost function, training data, batch_size, n_epoch etc.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : TensorFlow session\r\n",
        "        sess = tf.InteractiveSession()\r\n",
        "    network : a TensorLayer layer\r\n",
        "        the network will be trained\r\n",
        "    train_op : a TensorFlow optimizer\r\n",
        "        like tf.train.AdamOptimizer\r\n",
        "    X_train : numpy array\r\n",
        "        the input of training data\r\n",
        "    y_train : numpy array\r\n",
        "        the target of training data\r\n",
        "    x : placeholder\r\n",
        "        for inputs\r\n",
        "    y_ : placeholder\r\n",
        "        for targets\r\n",
        "    acc : the TensorFlow expression of accuracy (or other metric) or None\r\n",
        "        if None, would not display the metric\r\n",
        "    batch_size : int\r\n",
        "        batch size for training and evaluating\r\n",
        "    n_epoch : int\r\n",
        "        the number of training epochs\r\n",
        "    print_freq : int\r\n",
        "        display the training information every ``print_freq`` epochs\r\n",
        "    X_val : numpy array or None\r\n",
        "        the input of validation data\r\n",
        "    y_val : numpy array or None\r\n",
        "        the target of validation data\r\n",
        "    eval_train : boolean\r\n",
        "        if X_val and y_val are not None, it refects whether to evaluate the training data\r\n",
        "    tensorboard : boolean\r\n",
        "        if True summary data will be stored to the log/ direcory for visualization with tensorboard.\r\n",
        "        See also detailed tensorboard_X settings for specific configurations of features. (default False)\r\n",
        "        Also runs tl.layers.initialize_global_variables(sess) internally in fit() to setup the summary nodes, see Note:\r\n",
        "    tensorboard_epoch_freq : int\r\n",
        "        how many epochs between storing tensorboard checkpoint for visualization to log/ directory (default 5)\r\n",
        "    tensorboard_weight_histograms : boolean\r\n",
        "        if True updates tensorboard data in the logs/ directory for visulaization\r\n",
        "        of the weight histograms every tensorboard_epoch_freq epoch (default True)\r\n",
        "    tensorboard_graph_vis : boolean\r\n",
        "        if True stores the graph in the tensorboard summaries saved to log/ (default True)\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see tutorial_mnist_simple.py\r\n",
        "    >>> tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_,\r\n",
        "    ...            acc=acc, batch_size=500, n_epoch=200, print_freq=5,\r\n",
        "    ...            X_val=X_val, y_val=y_val, eval_train=False)\r\n",
        "    >>> tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_,\r\n",
        "    ...            acc=acc, batch_size=500, n_epoch=200, print_freq=5,\r\n",
        "    ...            X_val=X_val, y_val=y_val, eval_train=False,\r\n",
        "    ...            tensorboard=True, tensorboard_weight_histograms=True, tensorboard_graph_vis=True)\r\n",
        "    Note\r\n",
        "    --------\r\n",
        "        If tensorboard=True, the global_variables_initializer will be run inside the fit function\r\n",
        "        in order to initalize the automatically generated summary nodes used for tensorboard visualization,\r\n",
        "        thus tf.global_variables_initializer().run() before the fit() call will be undefined.\r\n",
        "    \"\"\"\r\n",
        "    assert X_train.shape[0] >= batch_size, \"Number of training examples should be bigger than the batch size\"\r\n",
        "\r\n",
        "    if(tensorboard):\r\n",
        "        print(\"Setting up tensorboard ...\")\r\n",
        "        #Set up tensorboard summaries and saver\r\n",
        "        tl.files.exists_or_mkdir('logs/')\r\n",
        "\r\n",
        "        #Only write summaries for more recent TensorFlow versions\r\n",
        "        if hasattr(tf, 'summary') and hasattr(tf.summary, 'FileWriter'):\r\n",
        "            if tensorboard_graph_vis:\r\n",
        "                train_writer = tf.summary.FileWriter('logs/train',sess.graph)\r\n",
        "                val_writer = tf.summary.FileWriter('logs/validation',sess.graph)\r\n",
        "            else:\r\n",
        "                train_writer = tf.summary.FileWriter('logs/train')\r\n",
        "                val_writer = tf.summary.FileWriter('logs/validation')\r\n",
        "\r\n",
        "        #Set up summary nodes\r\n",
        "        if(tensorboard_weight_histograms):\r\n",
        "            for param in network.all_params:\r\n",
        "                if hasattr(tf, 'summary') and hasattr(tf.summary, 'histogram'):\r\n",
        "                    print('Param name ', param.name)\r\n",
        "                    tf.summary.histogram(param.name, param)\r\n",
        "\r\n",
        "        if hasattr(tf, 'summary') and hasattr(tf.summary, 'histogram'):\r\n",
        "            tf.summary.scalar('cost', cost)\r\n",
        "\r\n",
        "        merged = tf.summary.merge_all()\r\n",
        "\r\n",
        "        #Initalize all variables and summaries\r\n",
        "        tl.layers.initialize_global_variables(sess)\r\n",
        "        print(\"Finished! use $tensorboard --logdir=logs/ to start server\")\r\n",
        "\r\n",
        "    print(\"Start training the network ...\")\r\n",
        "    start_time_begin = time.time()\r\n",
        "    tensorboard_train_index, tensorboard_val_index = 0, 0\r\n",
        "    for epoch in range(n_epoch):\r\n",
        "        start_time = time.time()\r\n",
        "        loss_ep = 0; n_step = 0\r\n",
        "        for X_train_a, y_train_a in iterate.minibatches(X_train, y_train,\r\n",
        "                                                    batch_size, shuffle=True):\r\n",
        "            feed_dict = {x: X_train_a, y_: y_train_a}\r\n",
        "            feed_dict.update( network.all_drop )    # enable noise layers\r\n",
        "            loss, _ = sess.run([cost, train_op], feed_dict=feed_dict)\r\n",
        "            loss_ep += loss\r\n",
        "            n_step += 1\r\n",
        "        loss_ep = loss_ep/ n_step\r\n",
        "\r\n",
        "        if tensorboard and hasattr(tf, 'summary'):\r\n",
        "            if epoch+1 == 1 or (epoch+1) % tensorboard_epoch_freq == 0:\r\n",
        "                for X_train_a, y_train_a in iterate.minibatches(\r\n",
        "                                        X_train, y_train, batch_size, shuffle=True):\r\n",
        "                    dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "                    feed_dict = {x: X_train_a, y_: y_train_a}\r\n",
        "                    feed_dict.update(dp_dict)\r\n",
        "                    result = sess.run(merged, feed_dict=feed_dict)\r\n",
        "                    train_writer.add_summary(result, tensorboard_train_index)\r\n",
        "                    tensorboard_train_index += 1\r\n",
        "\r\n",
        "                for X_val_a, y_val_a in iterate.minibatches(\r\n",
        "                                        X_val, y_val, batch_size, shuffle=True):\r\n",
        "                    dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "                    feed_dict = {x: X_val_a, y_: y_val_a}\r\n",
        "                    feed_dict.update(dp_dict)\r\n",
        "                    result = sess.run(merged, feed_dict=feed_dict)\r\n",
        "                    val_writer.add_summary(result, tensorboard_val_index)\r\n",
        "                    tensorboard_val_index += 1\r\n",
        "\r\n",
        "        if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\r\n",
        "            if (X_val is not None) and (y_val is not None):\r\n",
        "                print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, time.time() - start_time))\r\n",
        "                if eval_train is True:\r\n",
        "                    train_loss, train_acc, n_batch = 0, 0, 0\r\n",
        "                    for X_train_a, y_train_a in iterate.minibatches(\r\n",
        "                                            X_train, y_train, batch_size, shuffle=True):\r\n",
        "                        dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "                        feed_dict = {x: X_train_a, y_: y_train_a}\r\n",
        "                        feed_dict.update(dp_dict)\r\n",
        "                        if acc is not None:\r\n",
        "                            err, ac = sess.run([cost, acc], feed_dict=feed_dict)\r\n",
        "                            train_acc += ac\r\n",
        "                        else:\r\n",
        "                            err = sess.run(cost, feed_dict=feed_dict)\r\n",
        "                        train_loss += err;  n_batch += 1\r\n",
        "                    print(\"   train loss: %f\" % (train_loss/ n_batch))\r\n",
        "                    if acc is not None:\r\n",
        "                        print(\"   train acc: %f\" % (train_acc/ n_batch))\r\n",
        "                val_loss, val_acc, n_batch = 0, 0, 0\r\n",
        "                for X_val_a, y_val_a in iterate.minibatches(\r\n",
        "                                            X_val, y_val, batch_size, shuffle=True):\r\n",
        "                    dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "                    feed_dict = {x: X_val_a, y_: y_val_a}\r\n",
        "                    feed_dict.update(dp_dict)\r\n",
        "                    if acc is not None:\r\n",
        "                        err, ac = sess.run([cost, acc], feed_dict=feed_dict)\r\n",
        "                        val_acc += ac\r\n",
        "                    else:\r\n",
        "                        err = sess.run(cost, feed_dict=feed_dict)\r\n",
        "                    val_loss += err; n_batch += 1\r\n",
        "                print(\"   val loss: %f\" % (val_loss/ n_batch))\r\n",
        "                if acc is not None:\r\n",
        "                    print(\"   val acc: %f\" % (val_acc/ n_batch))\r\n",
        "            else:\r\n",
        "                print(\"Epoch %d of %d took %fs, loss %f\" % (epoch + 1, n_epoch, time.time() - start_time, loss_ep))\r\n",
        "    print(\"Total training time: %fs\" % (time.time() - start_time_begin))\r\n",
        "\r\n",
        "\r\n",
        "def test(sess, network, acc, X_test, y_test, x, y_, batch_size, cost=None):\r\n",
        "    \"\"\"\r\n",
        "    Test a given non time-series network by the given test data and metric.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : TensorFlow session\r\n",
        "        sess = tf.InteractiveSession()\r\n",
        "    network : a TensorLayer layer\r\n",
        "        the network will be trained\r\n",
        "    acc : the TensorFlow expression of accuracy (or other metric) or None\r\n",
        "        if None, would not display the metric\r\n",
        "    X_test : numpy array\r\n",
        "        the input of test data\r\n",
        "    y_test : numpy array\r\n",
        "        the target of test data\r\n",
        "    x : placeholder\r\n",
        "        for inputs\r\n",
        "    y_ : placeholder\r\n",
        "        for targets\r\n",
        "    batch_size : int or None\r\n",
        "        batch size for testing, when dataset is large, we should use minibatche for testing.\r\n",
        "        when dataset is small, we can set it to None.\r\n",
        "    cost : the TensorFlow expression of cost or None\r\n",
        "        if None, would not display the cost\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see tutorial_mnist_simple.py\r\n",
        "    >>> tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)\r\n",
        "    \"\"\"\r\n",
        "    print('Start testing the network ...')\r\n",
        "    if batch_size is None:\r\n",
        "        dp_dict = dict_to_one( network.all_drop )\r\n",
        "        feed_dict = {x: X_test, y_: y_test}\r\n",
        "        feed_dict.update(dp_dict)\r\n",
        "        if cost is not None:\r\n",
        "            print(\"   test loss: %f\" % sess.run(cost, feed_dict=feed_dict))\r\n",
        "        print(\"   test acc: %f\" % sess.run(acc, feed_dict=feed_dict))\r\n",
        "            # print(\"   test acc: %f\" % np.mean(y_test == sess.run(y_op,\r\n",
        "            #                                           feed_dict=feed_dict)))\r\n",
        "    else:\r\n",
        "        test_loss, test_acc, n_batch = 0, 0, 0\r\n",
        "        for X_test_a, y_test_a in iterate.minibatches(\r\n",
        "                                    X_test, y_test, batch_size, shuffle=True):\r\n",
        "            dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "            feed_dict = {x: X_test_a, y_: y_test_a}\r\n",
        "            feed_dict.update(dp_dict)\r\n",
        "            if cost is not None:\r\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\r\n",
        "                test_loss += err\r\n",
        "            else:\r\n",
        "                ac = sess.run(acc, feed_dict=feed_dict)\r\n",
        "            test_acc += ac; n_batch += 1\r\n",
        "        if cost is not None:\r\n",
        "            print(\"   test loss: %f\" % (test_loss/ n_batch))\r\n",
        "        print(\"   test acc: %f\" % (test_acc/ n_batch))\r\n",
        "\r\n",
        "\r\n",
        "def predict(sess, network, X, x, y_op):\r\n",
        "    \"\"\"\r\n",
        "    Return the predict results of given non time-series network.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    sess : TensorFlow session\r\n",
        "        sess = tf.InteractiveSession()\r\n",
        "    network : a TensorLayer layer\r\n",
        "        the network will be trained\r\n",
        "    X : numpy array\r\n",
        "        the input\r\n",
        "    x : placeholder\r\n",
        "        for inputs\r\n",
        "    y_op : placeholder\r\n",
        "        the argmax expression of softmax outputs\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see tutorial_mnist_simple.py\r\n",
        "    >>> y = network.outputs\r\n",
        "    >>> y_op = tf.argmax(tf.nn.softmax(y), 1)\r\n",
        "    >>> print(tl.utils.predict(sess, network, X_test, x, y_op))\r\n",
        "    \"\"\"\r\n",
        "    dp_dict = dict_to_one( network.all_drop )    # disable noise layers\r\n",
        "    feed_dict = {x: X,}\r\n",
        "    feed_dict.update(dp_dict)\r\n",
        "    return sess.run(y_op, feed_dict=feed_dict)\r\n",
        "\r\n",
        "## Evaluation\r\n",
        "def evaluation(y_test=None, y_predict=None, n_classes=None):\r\n",
        "    \"\"\"\r\n",
        "    Input the predicted results, targets results and\r\n",
        "    the number of class, return the confusion matrix, F1-score of each class,\r\n",
        "    accuracy and macro F1-score.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    y_test : numpy.array or list\r\n",
        "        target results\r\n",
        "    y_predict : numpy.array or list\r\n",
        "        predicted results\r\n",
        "    n_classes : int\r\n",
        "        number of classes\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> c_mat, f1, acc, f1_macro = evaluation(y_test, y_predict, n_classes)\r\n",
        "    \"\"\"\r\n",
        "    from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\r\n",
        "    c_mat = confusion_matrix(y_test, y_predict, labels = [x for x in range(n_classes)])\r\n",
        "    f1    = f1_score(y_test, y_predict, average = None, labels = [x for x in range(n_classes)])\r\n",
        "    f1_macro = f1_score(y_test, y_predict, average='macro')\r\n",
        "    acc   = accuracy_score(y_test, y_predict)\r\n",
        "    print('confusion matrix: \\n',c_mat)\r\n",
        "    print('f1-score:',f1)\r\n",
        "    print('f1-score(macro):',f1_macro)   # same output with > f1_score(y_true, y_pred, average='macro')\r\n",
        "    print('accuracy-score:', acc)\r\n",
        "    return c_mat, f1, acc, f1_macro\r\n",
        "\r\n",
        "def dict_to_one(dp_dict={}):\r\n",
        "    \"\"\"\r\n",
        "    Input a dictionary, return a dictionary that all items are set to one,\r\n",
        "    use for disable dropout, dropconnect layer and so on.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    dp_dict : dictionary\r\n",
        "        keeping probabilities\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> dp_dict = dict_to_one( network.all_drop )\r\n",
        "    >>> dp_dict = dict_to_one( network.all_drop )\r\n",
        "    >>> feed_dict.update(dp_dict)\r\n",
        "    \"\"\"\r\n",
        "    return {x: 1 for x in dp_dict}\r\n",
        "\r\n",
        "def flatten_list(list_of_list=[[],[]]):\r\n",
        "    \"\"\"\r\n",
        "    Input a list of list, return a list that all items are in a list.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    list_of_list : a list of list\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> tl.utils.flatten_list([[1, 2, 3],[4, 5],[6]])\r\n",
        "    ... [1, 2, 3, 4, 5, 6]\r\n",
        "    \"\"\"\r\n",
        "    return sum(list_of_list, [])\r\n",
        "\r\n",
        "\r\n",
        "def class_balancing_oversample(X_train=None, y_train=None, printable=True):\r\n",
        "    \"\"\"Input the features and labels, return the features and labels after oversampling.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    X_train : numpy.array\r\n",
        "        Features, each row is an example\r\n",
        "    y_train : numpy.array\r\n",
        "        Labels\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    - One X\r\n",
        "    >>> X_train, y_train = class_balancing_oversample(X_train, y_train, printable=True)\r\n",
        "    - Two X\r\n",
        "    >>> X, y = tl.utils.class_balancing_oversample(X_train=np.hstack((X1, X2)), y_train=y, printable=False)\r\n",
        "    >>> X1 = X[:, 0:5]\r\n",
        "    >>> X2 = X[:, 5:]\r\n",
        "    \"\"\"\r\n",
        "    # ======== Classes balancing\r\n",
        "    if printable:\r\n",
        "        print(\"Classes balancing for training examples...\")\r\n",
        "    from collections import Counter\r\n",
        "    c = Counter(y_train)\r\n",
        "    if printable:\r\n",
        "        print('the occurrence number of each stage: %s' % c.most_common())\r\n",
        "        print('the least stage is Label %s have %s instances' % c.most_common()[-1])\r\n",
        "        print('the most stage is  Label %s have %s instances' % c.most_common(1)[0])\r\n",
        "    most_num = c.most_common(1)[0][1]\r\n",
        "    if printable:\r\n",
        "        print('most num is %d, all classes tend to be this num' % most_num)\r\n",
        "\r\n",
        "    locations = {}\r\n",
        "    number = {}\r\n",
        "\r\n",
        "    for lab, num in c.most_common():    # find the index from y_train\r\n",
        "        number[lab] = num\r\n",
        "        locations[lab] = np.where(np.array(y_train)==lab)[0]\r\n",
        "    if printable:\r\n",
        "        print('convert list(np.array) to dict format')\r\n",
        "    X = {}  # convert list to dict\r\n",
        "    for lab, num in number.items():\r\n",
        "        X[lab] = X_train[locations[lab]]\r\n",
        "\r\n",
        "    # oversampling\r\n",
        "    if printable:\r\n",
        "        print('start oversampling')\r\n",
        "    for key in X:\r\n",
        "        temp = X[key]\r\n",
        "        while True:\r\n",
        "            if len(X[key]) >= most_num:\r\n",
        "                break\r\n",
        "            X[key] = np.vstack((X[key], temp))\r\n",
        "    if printable:\r\n",
        "        print('first features of label 0 >', len(X[0][0]))\r\n",
        "        print('the occurrence num of each stage after oversampling')\r\n",
        "    for key in X:\r\n",
        "        print(key, len(X[key]))\r\n",
        "    if printable:\r\n",
        "        print('make each stage have same num of instances')\r\n",
        "    for key in X:\r\n",
        "        X[key] = X[key][0:most_num,:]\r\n",
        "        print(key, len(X[key]))\r\n",
        "\r\n",
        "    # convert dict to list\r\n",
        "    if printable:\r\n",
        "        print('convert from dict to list format')\r\n",
        "    y_train = []\r\n",
        "    X_train = np.empty(shape=(0,len(X[0][0])))\r\n",
        "    for key in X:\r\n",
        "        X_train = np.vstack( (X_train, X[key] ) )\r\n",
        "        y_train.extend([key for i in range(len(X[key]))])\r\n",
        "    # print(len(X_train), len(y_train))\r\n",
        "    c = Counter(y_train)\r\n",
        "    if printable:\r\n",
        "        print('the occurrence number of each stage after oversampling: %s' % c.most_common())\r\n",
        "    # ================ End of Classes balancing\r\n",
        "    return X_train, y_train\r\n",
        "\r\n",
        "## Random\r\n",
        "def get_random_int(min=0, max=10, number=5, seed=None):\r\n",
        "    \"\"\"Return a list of random integer by the given range and quantity.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> r = get_random_int(min=0, max=10, number=5)\r\n",
        "    ... [10, 2, 3, 3, 7]\r\n",
        "    \"\"\"\r\n",
        "    rnd = random.Random()\r\n",
        "    if seed:\r\n",
        "        rnd = random.Random(seed)\r\n",
        "    # return [random.randint(min,max) for p in range(0, number)]\r\n",
        "    return [rnd.randint(min,max) for p in range(0, number)]\r\n",
        "\r\n",
        "#\r\n",
        "# def class_balancing_sequence_4D(X_train, y_train, sequence_length, model='downsampling' ,printable=True):\r\n",
        "#     ''' 输入、输出都是sequence format\r\n",
        "#         oversampling or downsampling\r\n",
        "#     '''\r\n",
        "#     n_features = X_train.shape[2]\r\n",
        "#     # ======== Classes balancing for sequence\r\n",
        "#     if printable:\r\n",
        "#         print(\"Classes balancing for 4D sequence training examples...\")\r\n",
        "#     from collections import Counter\r\n",
        "#     c = Counter(y_train)    # Counter({2: 454, 4: 267, 3: 124, 1: 57, 0: 48})\r\n",
        "#     if printable:\r\n",
        "#         print('the occurrence number of each stage: %s' % c.most_common())\r\n",
        "#         print('the least Label %s have %s instances' % c.most_common()[-1])\r\n",
        "#         print('the most  Label %s have %s instances' % c.most_common(1)[0])\r\n",
        "#     # print(c.most_common()) # [(2, 454), (4, 267), (3, 124), (1, 57), (0, 48)]\r\n",
        "#     most_num = c.most_common(1)[0][1]\r\n",
        "#     less_num = c.most_common()[-1][1]\r\n",
        "#\r\n",
        "#     locations = {}\r\n",
        "#     number = {}\r\n",
        "#     for lab, num in c.most_common():\r\n",
        "#         number[lab] = num\r\n",
        "#         locations[lab] = np.where(np.array(y_train)==lab)[0]\r\n",
        "#     # print(locations)\r\n",
        "#     # print(number)\r\n",
        "#     if printable:\r\n",
        "#         print('  convert list to dict')\r\n",
        "#     X = {}  # convert list to dict\r\n",
        "#     ### a sequence\r\n",
        "#     for lab, _ in number.items():\r\n",
        "#         X[lab] = np.empty(shape=(0,1,n_features,1)) # 4D\r\n",
        "#     for lab, _ in number.items():\r\n",
        "#         #X[lab] = X_train[locations[lab]\r\n",
        "#         for l in locations[lab]:\r\n",
        "#             X[lab] = np.vstack((X[lab], X_train[l*sequence_length : (l+1)*(sequence_length)]))\r\n",
        "#         # X[lab] = X_train[locations[lab]*sequence_length : locations[lab]*(sequence_length+1)]    # a sequence\r\n",
        "#     # print(X)\r\n",
        "#\r\n",
        "#     if model=='oversampling':\r\n",
        "#         if printable:\r\n",
        "#             print('  oversampling -- most num is %d, all classes tend to be this num\\nshuffle applied' % most_num)\r\n",
        "#         for key in X:\r\n",
        "#             temp = X[key]\r\n",
        "#             while True:\r\n",
        "#                 if len(X[key]) >= most_num * sequence_length:   # sequence\r\n",
        "#                     break\r\n",
        "#                 X[key] = np.vstack((X[key], temp))\r\n",
        "#             # print(key, len(X[key]))\r\n",
        "#         if printable:\r\n",
        "#             print('  make each stage have same num of instances')\r\n",
        "#         for key in X:\r\n",
        "#             X[key] = X[key][0:most_num*sequence_length,:]   # sequence\r\n",
        "#             if printable:\r\n",
        "#                 print(key, len(X[key]))\r\n",
        "#     elif model=='downsampling':\r\n",
        "#         import random\r\n",
        "#         if printable:\r\n",
        "#             print('  downsampling -- less num is %d, all classes tend to be this num by randomly choice without replacement\\nshuffle applied' % less_num)\r\n",
        "#         for key in X:\r\n",
        "#             # print(key, len(X[key]))#, len(X[key])/sequence_length)\r\n",
        "#             s_idx = [ i for i in range(int(len(X[key])/sequence_length))]\r\n",
        "#             s_idx = np.asarray(s_idx)*sequence_length   # start index of sequnce in X[key]\r\n",
        "#             # print('s_idx',s_idx)\r\n",
        "#             r_idx = np.random.choice(s_idx, less_num, replace=False)    # random choice less_num of s_idx\r\n",
        "#             # print('r_idx',r_idx)\r\n",
        "#             temp = X[key]\r\n",
        "#             X[key] = np.empty(shape=(0,1,n_features,1)) # 4D\r\n",
        "#             for idx in r_idx:\r\n",
        "#                 X[key] = np.vstack((X[key], temp[idx:idx+sequence_length]))\r\n",
        "#             # print(key, X[key])\r\n",
        "#             # np.random.choice(l, len(l), replace=False)\r\n",
        "#     else:\r\n",
        "#         raise Exception('  model should be oversampling or downsampling')\r\n",
        "#\r\n",
        "#     # convert dict to list\r\n",
        "#     if printable:\r\n",
        "#         print('  convert dict to list')\r\n",
        "#     y_train = []\r\n",
        "#     # X_train = np.empty(shape=(0,len(X[0][0])))\r\n",
        "#     # X_train = np.empty(shape=(0,len(X[1][0])))    # 2D\r\n",
        "#     X_train = np.empty(shape=(0,1,n_features,1))    # 4D\r\n",
        "#     l_key = list(X.keys())  # shuffle\r\n",
        "#     random.shuffle(l_key)   # shuffle\r\n",
        "#     # for key in X:     # no shuffle\r\n",
        "#     for key in l_key:   # shuffle\r\n",
        "#         X_train = np.vstack( (X_train, X[key] ) )\r\n",
        "#         # print(len(X[key]))\r\n",
        "#         y_train.extend([key for i in range(int(len(X[key])/sequence_length))])\r\n",
        "#     # print(X_train,y_train, type(X_train), type(y_train))\r\n",
        "#     # ================ End of Classes balancing for sequence\r\n",
        "#     # print(X_train.shape, len(y_train))\r\n",
        "#     return X_train, np.asarray(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dbb1098dc0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorlayer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwgLz7SPfHnz"
      },
      "source": [
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "## Save images\r\n",
        "import scipy.misc\r\n",
        "def save_images(images, size, image_path):\r\n",
        "    \"\"\"Save mutiple images into one single image.\r\n",
        "    Parameters\r\n",
        "    -----------\r\n",
        "    images : numpy array [batch, w, h, c]\r\n",
        "    size : list of two int, row and column number.\r\n",
        "        number of images should be equal or less than size[0] * size[1]\r\n",
        "    image_path : string.\r\n",
        "    Examples\r\n",
        "    ---------\r\n",
        "    >>> images = np.random.rand(64, 100, 100, 3)\r\n",
        "    >>> tl.visualize.save_images(images, [8, 8], 'temp.png')\r\n",
        "    \"\"\"\r\n",
        "    def merge(images, size):\r\n",
        "        h, w = images.shape[1], images.shape[2]\r\n",
        "        img = np.zeros((h * size[0], w * size[1], 3))\r\n",
        "        for idx, image in enumerate(images):\r\n",
        "            i = idx % size[1]\r\n",
        "            j = idx // size[1]\r\n",
        "            img[j*h:j*h+h, i*w:i*w+w, :] = image\r\n",
        "        return img\r\n",
        "\r\n",
        "    def imsave(images, size, path):\r\n",
        "        return scipy.misc.imsave(path, merge(images, size))\r\n",
        "\r\n",
        "    assert len(images) <= size[0] * size[1], \"number of images should be equal or less than size[0] * size[1] {}\".format(len(images))\r\n",
        "    return imsave(images, size, image_path)\r\n",
        "\r\n",
        "def W(W=None, second=10, saveable=True, shape=[28,28], name='mnist', fig_idx=2396512):\r\n",
        "    \"\"\"Visualize every columns of the weight matrix to a group of Greyscale img.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    W : numpy.array\r\n",
        "        The weight matrix\r\n",
        "    second : int\r\n",
        "        The display second(s) for the image(s), if saveable is False.\r\n",
        "    saveable : boolean\r\n",
        "        Save or plot the figure.\r\n",
        "    shape : a list with 2 int\r\n",
        "        The shape of feature image, MNIST is [28, 80].\r\n",
        "    name : a string\r\n",
        "        A name to save the image, if saveable is True.\r\n",
        "    fig_idx : int\r\n",
        "        matplotlib figure index.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> tl.visualize.W(network.all_params[0].eval(), second=10, saveable=True, name='weight_of_1st_layer', fig_idx=2012)\r\n",
        "    \"\"\"\r\n",
        "    if saveable is False:\r\n",
        "        plt.ion()\r\n",
        "    fig = plt.figure(fig_idx)      # show all feature images\r\n",
        "    size = W.shape[0]\r\n",
        "    n_units = W.shape[1]\r\n",
        "\r\n",
        "    num_r = int(np.sqrt(n_units))  # 每行显示的个数   若25个hidden unit -> 每行显示5个\r\n",
        "    num_c = int(np.ceil(n_units/num_r))\r\n",
        "    count = int(1)\r\n",
        "    for row in range(1, num_r+1):\r\n",
        "        for col in range(1, num_c+1):\r\n",
        "            if count > n_units:\r\n",
        "                break\r\n",
        "            a = fig.add_subplot(num_r, num_c, count)\r\n",
        "            # ------------------------------------------------------------\r\n",
        "            # plt.imshow(np.reshape(W[:,count-1],(28,28)), cmap='gray')\r\n",
        "            # ------------------------------------------------------------\r\n",
        "            feature = W[:,count-1] / np.sqrt( (W[:,count-1]**2).sum())\r\n",
        "            # feature[feature<0.0001] = 0   # value threshold\r\n",
        "            # if count == 1 or count == 2:\r\n",
        "            #     print(np.mean(feature))\r\n",
        "            # if np.std(feature) < 0.03:      # condition threshold\r\n",
        "            #     feature = np.zeros_like(feature)\r\n",
        "            # if np.mean(feature) < -0.015:      # condition threshold\r\n",
        "            #     feature = np.zeros_like(feature)\r\n",
        "            plt.imshow(np.reshape(feature ,(shape[0],shape[1])),\r\n",
        "                    cmap='gray', interpolation=\"nearest\")#, vmin=np.min(feature), vmax=np.max(feature))\r\n",
        "            # plt.title(name)\r\n",
        "            # ------------------------------------------------------------\r\n",
        "            # plt.imshow(np.reshape(W[:,count-1] ,(np.sqrt(size),np.sqrt(size))), cmap='gray', interpolation=\"nearest\")\r\n",
        "            plt.gca().xaxis.set_major_locator(plt.NullLocator())    # distable tick\r\n",
        "            plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "            count = count + 1\r\n",
        "    if saveable:\r\n",
        "        plt.savefig(name+'.pdf',format='pdf')\r\n",
        "    else:\r\n",
        "        plt.draw()\r\n",
        "        plt.pause(second)\r\n",
        "\r\n",
        "def frame(I=None, second=5, saveable=True, name='frame', cmap=None, fig_idx=12836):\r\n",
        "    \"\"\"Display a frame(image). Make sure OpenAI Gym render() is disable before using it.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    I : numpy.array\r\n",
        "        The image\r\n",
        "    second : int\r\n",
        "        The display second(s) for the image(s), if saveable is False.\r\n",
        "    saveable : boolean\r\n",
        "        Save or plot the figure.\r\n",
        "    name : a string\r\n",
        "        A name to save the image, if saveable is True.\r\n",
        "    cmap : None or string\r\n",
        "        'gray' for greyscale, None for default, etc.\r\n",
        "    fig_idx : int\r\n",
        "        matplotlib figure index.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> env = gym.make(\"Pong-v0\")\r\n",
        "    >>> observation = env.reset()\r\n",
        "    >>> tl.visualize.frame(observation)\r\n",
        "    \"\"\"\r\n",
        "    if saveable is False:\r\n",
        "        plt.ion()\r\n",
        "    fig = plt.figure(fig_idx)      # show all feature images\r\n",
        "\r\n",
        "    if len(I.shape) and I.shape[-1]==1:     # (10,10,1) --> (10,10)\r\n",
        "        I = I[:,:,0]\r\n",
        "\r\n",
        "    plt.imshow(I, cmap)\r\n",
        "    plt.title(name)\r\n",
        "    # plt.gca().xaxis.set_major_locator(plt.NullLocator())    # distable tick\r\n",
        "    # plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "\r\n",
        "    if saveable:\r\n",
        "        plt.savefig(name+'.pdf',format='pdf')\r\n",
        "    else:\r\n",
        "        plt.draw()\r\n",
        "        plt.pause(second)\r\n",
        "\r\n",
        "def CNN2d(CNN=None, second=10, saveable=True, name='cnn', fig_idx=3119362):\r\n",
        "    \"\"\"Display a group of RGB or Greyscale CNN masks.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    CNN : numpy.array\r\n",
        "        The image. e.g: 64 5x5 RGB images can be (5, 5, 3, 64).\r\n",
        "    second : int\r\n",
        "        The display second(s) for the image(s), if saveable is False.\r\n",
        "    saveable : boolean\r\n",
        "        Save or plot the figure.\r\n",
        "    name : a string\r\n",
        "        A name to save the image, if saveable is True.\r\n",
        "    fig_idx : int\r\n",
        "        matplotlib figure index.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> tl.visualize.CNN2d(network.all_params[0].eval(), second=10, saveable=True, name='cnn1_mnist', fig_idx=2012)\r\n",
        "    \"\"\"\r\n",
        "    # print(CNN.shape)    # (5, 5, 3, 64)\r\n",
        "    # exit()\r\n",
        "    n_mask = CNN.shape[3]\r\n",
        "    n_row = CNN.shape[0]\r\n",
        "    n_col = CNN.shape[1]\r\n",
        "    n_color = CNN.shape[2]\r\n",
        "    row = int(np.sqrt(n_mask))\r\n",
        "    col = int(np.ceil(n_mask/row))\r\n",
        "    plt.ion()   # active mode\r\n",
        "    fig = plt.figure(fig_idx)\r\n",
        "    count = 1\r\n",
        "    for ir in range(1, row+1):\r\n",
        "        for ic in range(1, col+1):\r\n",
        "            if count > n_mask:\r\n",
        "                break\r\n",
        "            a = fig.add_subplot(col, row, count)\r\n",
        "            # print(CNN[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5\r\n",
        "            # exit()\r\n",
        "            # plt.imshow(\r\n",
        "            #         np.reshape(CNN[count-1,:,:,:], (n_row, n_col)),\r\n",
        "            #         cmap='gray', interpolation=\"nearest\")     # theano\r\n",
        "            if n_color == 1:\r\n",
        "                plt.imshow(\r\n",
        "                        np.reshape(CNN[:,:,:,count-1], (n_row, n_col)),\r\n",
        "                        cmap='gray', interpolation=\"nearest\")\r\n",
        "            elif n_color == 3:\r\n",
        "                plt.imshow(\r\n",
        "                        np.reshape(CNN[:,:,:,count-1], (n_row, n_col, n_color)),\r\n",
        "                        cmap='gray', interpolation=\"nearest\")\r\n",
        "            else:\r\n",
        "                raise Exception(\"Unknown n_color\")\r\n",
        "            plt.gca().xaxis.set_major_locator(plt.NullLocator())    # distable tick\r\n",
        "            plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "            count = count + 1\r\n",
        "    if saveable:\r\n",
        "        plt.savefig(name+'.pdf',format='pdf')\r\n",
        "    else:\r\n",
        "        plt.draw()\r\n",
        "        plt.pause(second)\r\n",
        "\r\n",
        "\r\n",
        "def images2d(images=None, second=10, saveable=True, name='images', dtype=None,\r\n",
        "                                                            fig_idx=3119362):\r\n",
        "    \"\"\"Display a group of RGB or Greyscale images.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    images : numpy.array\r\n",
        "        The images.\r\n",
        "    second : int\r\n",
        "        The display second(s) for the image(s), if saveable is False.\r\n",
        "    saveable : boolean\r\n",
        "        Save or plot the figure.\r\n",
        "    name : a string\r\n",
        "        A name to save the image, if saveable is True.\r\n",
        "    dtype : None or numpy data type\r\n",
        "        The data type for displaying the images.\r\n",
        "    fig_idx : int\r\n",
        "        matplotlib figure index.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\r\n",
        "    >>> tl.visualize.images2d(X_train[0:100,:,:,:], second=10, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\r\n",
        "    \"\"\"\r\n",
        "    # print(images.shape)    # (50000, 32, 32, 3)\r\n",
        "    # exit()\r\n",
        "    if dtype:\r\n",
        "        images = np.asarray(images, dtype=dtype)\r\n",
        "    n_mask = images.shape[0]\r\n",
        "    n_row = images.shape[1]\r\n",
        "    n_col = images.shape[2]\r\n",
        "    n_color = images.shape[3]\r\n",
        "    row = int(np.sqrt(n_mask))\r\n",
        "    col = int(np.ceil(n_mask/row))\r\n",
        "    plt.ion()   # active mode\r\n",
        "    fig = plt.figure(fig_idx)\r\n",
        "    count = 1\r\n",
        "    for ir in range(1, row+1):\r\n",
        "        for ic in range(1, col+1):\r\n",
        "            if count > n_mask:\r\n",
        "                break\r\n",
        "            a = fig.add_subplot(col, row, count)\r\n",
        "            # print(images[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5\r\n",
        "            # plt.imshow(\r\n",
        "            #         np.reshape(images[count-1,:,:,:], (n_row, n_col)),\r\n",
        "            #         cmap='gray', interpolation=\"nearest\")     # theano\r\n",
        "            if n_color == 1:\r\n",
        "                plt.imshow(\r\n",
        "                        np.reshape(images[count-1,:,:], (n_row, n_col)),\r\n",
        "                        cmap='gray', interpolation=\"nearest\")\r\n",
        "                # plt.title(name)\r\n",
        "            elif n_color == 3:\r\n",
        "                plt.imshow(images[count-1,:,:],\r\n",
        "                        cmap='gray', interpolation=\"nearest\")\r\n",
        "                # plt.title(name)\r\n",
        "            else:\r\n",
        "                raise Exception(\"Unknown n_color\")\r\n",
        "            plt.gca().xaxis.set_major_locator(plt.NullLocator())    # distable tick\r\n",
        "            plt.gca().yaxis.set_major_locator(plt.NullLocator())\r\n",
        "            count = count + 1\r\n",
        "    if saveable:\r\n",
        "        plt.savefig(name+'.pdf',format='pdf')\r\n",
        "    else:\r\n",
        "        plt.draw()\r\n",
        "        plt.pause(second)\r\n",
        "\r\n",
        "def tsne_embedding(embeddings, reverse_dictionary, plot_only=500,\r\n",
        "                        second=5, saveable=False, name='tsne', fig_idx=9862):\r\n",
        "    \"\"\"Visualize the embeddings by using t-SNE.\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    embeddings : a matrix\r\n",
        "        The images.\r\n",
        "    reverse_dictionary : a dictionary\r\n",
        "        id_to_word, mapping id to unique word.\r\n",
        "    plot_only : int\r\n",
        "        The number of examples to plot, choice the most common words.\r\n",
        "    second : int\r\n",
        "        The display second(s) for the image(s), if saveable is False.\r\n",
        "    saveable : boolean\r\n",
        "        Save or plot the figure.\r\n",
        "    name : a string\r\n",
        "        A name to save the image, if saveable is True.\r\n",
        "    fig_idx : int\r\n",
        "        matplotlib figure index.\r\n",
        "    Examples\r\n",
        "    --------\r\n",
        "    >>> see 'tutorial_word2vec_basic.py'\r\n",
        "    >>> final_embeddings = normalized_embeddings.eval()\r\n",
        "    >>> tl.visualize.tsne_embedding(final_embeddings, labels, reverse_dictionary,\r\n",
        "    ...                   plot_only=500, second=5, saveable=False, name='tsne')\r\n",
        "    \"\"\"\r\n",
        "    def plot_with_labels(low_dim_embs, labels, figsize=(18, 18), second=5,\r\n",
        "                                    saveable=True, name='tsne', fig_idx=9862):\r\n",
        "        assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\r\n",
        "        if saveable is False:\r\n",
        "            plt.ion()\r\n",
        "            plt.figure(fig_idx)\r\n",
        "        plt.figure(figsize=figsize)  #in inches\r\n",
        "        for i, label in enumerate(labels):\r\n",
        "            x, y = low_dim_embs[i,:]\r\n",
        "            plt.scatter(x, y)\r\n",
        "            plt.annotate(label,\r\n",
        "                     xy=(x, y),\r\n",
        "                     xytext=(5, 2),\r\n",
        "                     textcoords='offset points',\r\n",
        "                     ha='right',\r\n",
        "                     va='bottom')\r\n",
        "        if saveable:\r\n",
        "            plt.savefig(name+'.pdf',format='pdf')\r\n",
        "        else:\r\n",
        "            plt.draw()\r\n",
        "            plt.pause(second)\r\n",
        "\r\n",
        "    try:\r\n",
        "        from sklearn.manifold import TSNE\r\n",
        "        import matplotlib.pyplot as plt\r\n",
        "        from six.moves import xrange\r\n",
        "\r\n",
        "        tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\r\n",
        "        # plot_only = 500\r\n",
        "        low_dim_embs = tsne.fit_transform(embeddings[:plot_only,:])\r\n",
        "        labels = [reverse_dictionary[i] for i in xrange(plot_only)]\r\n",
        "        plot_with_labels(low_dim_embs, labels, second=second, saveable=saveable, \\\r\n",
        "                                                    name=name, fig_idx=fig_idx)\r\n",
        "    except ImportError:\r\n",
        "        print(\"Please install sklearn and matplotlib to visualize embeddings.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}